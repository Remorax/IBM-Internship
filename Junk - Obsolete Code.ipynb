{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from xml.dom import minidom\n",
    "\n",
    "all_ontologies = list(set([item + \".owl\" for sublist in [f.split(\".\")[0].split(\"-\") for  f in os.listdir(alignment_folder)] for item in sublist]))\n",
    "ontologies_folder = \"conference_ontologies/\"\n",
    "\n",
    "def parse_classes(ontology):\n",
    "    prefix = \"http://\" + ontology.split(\".\")[0] + \"#\"\n",
    "    doc = minidom.parse(ontology)\n",
    "    curr_classes = [el.getAttribute(\"rdf:ID\") for el in doc.getElementsByTagName('owl:Class')]\n",
    "    classes = [prefix + el for el in curr_classes if el]\n",
    "    return classes\n",
    "\n",
    "def parse_properties(ontology):\n",
    "    properties = []\n",
    "    for onto in ontologies:\n",
    "        prefix = \"http://\" + onto.split(\".\")[0] + \"#\"\n",
    "        doc = minidom.parse(folder + onto)\n",
    "        root = doc.documentElement\n",
    "        curr_properties = [el.getAttribute(\"rdf:ID\") for el in doc.getElementsByTagName('ObjectProperty')]\n",
    "        properties.extend([prefix + el for el in curr_properties if el])\n",
    "    return properties\n",
    "\n",
    "classes, properties = [], []\n",
    "for ontology in all_ontologies:\n",
    "    classes.extend(parse_classes(ontologies_folder + ontology))\n",
    "    properties.extend(parse_properties(ontologies_folder + ontology))\n",
    "properties = load_properties(ontologies_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_hyphen(ontology, replaced_props):\n",
    "    onto_str = open(ontology).read()\n",
    "    for (a,b) in replaced_props:\n",
    "        onto_str = onto_str.replace(a,b)\n",
    "    ontology_temp = ontology.split(\".\")[0] + \"_temp.owl\"\n",
    "    open(ontology_temp, \"w+\").write(onto_str)\n",
    "    return ontology_temp\n",
    "\n",
    "replaced_props = [(str(prop).split(\".\")[1], str(prop).split(\".\")[1].replace(\"-\", \"_\")) for prop in list(onto.properties()) if \"-\" in str(prop)]\n",
    "replaced_ontology = replace_hyphen(ontology, replaced_props)\n",
    "replaced_onto = get_ontology(replaced_ontology).load()\n",
    "# os.remove(replaced_ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"http://\" + ontology.split(\".\")[0] + \"#\"\n",
    "doc = minidom.parse(ontology)\n",
    "root = doc.documentElement\n",
    "curr_properties = [el.getAttribute(\"rdf:ID\") for el in doc.getElementsByTagName('Class')]\n",
    "# properties.extend([prefix + el for el in curr_properties if el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = [el for el in root.childNodes if type(el) == minidom.Element and el._get_tagName() == 'owl:ObjectProperty'] \n",
    "prop_ids = [prop.getAttribute('rdf:ID') for prop in props if prop.getAttribute('rdf:ID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = minidom.parse(ontology)\n",
    "object_props = [el.getAttribute(\"rdf:ID\") for el in doc.getElementsByTagName('owl:ObjectProperty')]\n",
    "filt = [[e for e in el._get_childNodes() if type(e)==minidom.Element and e._get_tagName() == \"rdf:type\"] for el in doc.getElementsByTagName('owl:FunctionalProperty')]\n",
    "[el[0].getAttribute(\"rdf:resource\") for el in filt if el]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear search with USE, no greedy\n",
    "\n",
    "opt_threshold, optimum_metrics = -1000, [-1000 for i in range(3)]\n",
    "t = time.time()\n",
    "for j,threshold in enumerate(np.arange(0.15, 1.0005, 0.01)):\n",
    "    print (\"threshold =\", threshold, \"Time = \", time.time()-t) \n",
    "    pred = [\"F\" for key in train_data]\n",
    "    mapped = []\n",
    "    for i,key in enumerate(train_data):\n",
    "        if train_data[key][0] > threshold:\n",
    "            pred[i] = \"T\"\n",
    "        mapped.extend(list(key))\n",
    "    gt = [l[1] for l in train_data.values()]\n",
    "    f1score = f1_score(gt, pred, pos_label=\"T\")\n",
    "    if f1score > optimum_metrics[-1]:\n",
    "        optimum_metrics = [precision_score(gt, pred, pos_label=\"T\"), recall_score(gt, pred, pos_label=\"T\"), f1score]\n",
    "        opt_threshold = threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = opt_threshold\n",
    "pred = [\"F\" for key in test_data]\n",
    "mapped = []\n",
    "for i,key in enumerate(test_data):\n",
    "    if test_data[key][0] > threshold:\n",
    "        pred[i] = \"T\"\n",
    "    mapped.extend(list(key))\n",
    "gt = [l[1] for l in test_data.values()]\n",
    "f1score = f1_score(gt, pred, pos_label=\"T\")\n",
    "metrics = [precision_score(gt, pred, pos_label=\"T\"), recall_score(gt, pred, pos_label=\"T\"), f1score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation for RotatE embeddings from OpenKE\n",
    "\n",
    "ontologies_in_alignment = [l.split(\".\")[0].split(\"-\") for l in os.listdir(\"reference-alignment/\")]\n",
    "\n",
    "def generate(ontology, concept_prefix, id_prefix=[0,0]):\n",
    "    ont = Ontology(ontology)\n",
    "    classes_dict = {concept_prefix+\"#\"+elem : str(id_prefix[0] + i) for i,elem in enumerate(ont.get_classes())} \n",
    "    props = ont.get_object_properties() + ont.get_data_properties() + [\"subclass_of\"]\n",
    "    prop_dict = {concept_prefix+\"#\"+elem : str(id_prefix[1] + i) for i,elem in enumerate(props)} \n",
    "    triplets = [\"\\t\".join((classes_dict[concept_prefix+\"#\"+el[0]], classes_dict[concept_prefix+\"#\"+el[1]], prop_dict[concept_prefix+\"#\"+el[2]]))\n",
    "                for el in ont.get_triples()]\n",
    "    return classes_dict, prop_dict, triplets\n",
    "\n",
    "    \n",
    "for l in ontologies_in_alignment:\n",
    "    ont1 = \"conference_ontologies/\" + l[0] + \".owl\"\n",
    "    ont2 = \"conference_ontologies/\" + l[1] + \".owl\"\n",
    "    \n",
    "    benchmark_dir = \"OpenKE/benchmarks/\" + l[0] + \"-\" + l[1]\n",
    "    if not os.path.isdir(benchmark_dir):\n",
    "        os.mkdir(benchmark_dir)\n",
    "    \n",
    "    c1, p1, t1 = generate(ont1, l[0])\n",
    "    c2, p2, t2 = generate(ont2, l[1], [len(c1), len(p1)])\n",
    "    \n",
    "    classes_dict = {**c1, **c2}\n",
    "    prop_dict = {**p1, **p2}\n",
    "    triplets = t1 + t2\n",
    "    \n",
    "    entity_str = str(len(classes_dict)) + \"\\n\" + \"\\n\".join([\"\\t\".join(elem) for elem in classes_dict.items()])\n",
    "    prop_str = str(len(prop_dict)) + \"\\n\" + \"\\n\".join([\"\\t\".join(elem) for elem in prop_dict.items()])\n",
    "    triplets_str = str(len(triplets)) + \"\\n\" + \"\\n\".join(triplets)\n",
    "\n",
    "    open(benchmark_dir + \"/entity2id.txt\", \"w+\").write(entity_str)\n",
    "    open(benchmark_dir + \"/relation2id.txt\", \"w+\").write(prop_str)\n",
    "    open(benchmark_dir + \"/train2id.txt\", \"w+\").write(triplets_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AML test\n",
    "results = []\n",
    "for i in list(range(0, len(all_ont_pairs), 3)):\n",
    "    test_onto = all_ont_pairs[i:i+3]\n",
    "    for ont_pair in test_onto:\n",
    "        a, b, c = ont_pair[0], ont_pair[1], ont_pair[0] + \"-\" + ont_pair[1]\n",
    "        java_command = \"java -jar AML_v3.1/AgreementMakerLight.jar -s conference_ontologies/\" + a + \".owl\" + \\\n",
    "                            \" -t conference_ontologies/\" + b + \".owl -o AML-test-results/\" + c + \".rdf -a\"\n",
    "    #     print (java_command)\n",
    "        process = subprocess.Popen(java_command.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "    #     print (a,b,c)\n",
    "\n",
    "    pred_aml = load_alignments(\"AML-test-results/\")\n",
    "    pred_aml = [tuple([el.split(\"/\")[-1] for el in key]) for key in pred_aml]\n",
    "    tp = len([elem for elem in pred_aml if data[elem][1] == \"T\"])\n",
    "    fn = len([key for key in gt_mappings if key not in set(pred_aml) and not is_valid(test_onto, key)])\n",
    "    fp = len([elem for elem in pred_aml if data[elem][1] == \"F\"])\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1score = 2 * precision * recall / (precision + recall)\n",
    "    f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "    print (precision, recall, f1score, f2score, f0_5score)\n",
    "    \n",
    "    metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "    results.append(metrics)\n",
    "    \n",
    "    rm_command = \"rm -rf AML-test-results/*\"\n",
    "    process = subprocess.Popen(rm_command.split(), stdout=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "    \n",
    "print (\"Final Results:\", np.mean(results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "relations = []\n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    triple_pairs = [list(itertools.product(el[0].split(\"###\"), el[1].split(\"###\"))) for el in ont.get_triples()]\n",
    "    triple_pairs = [tuple([ont_name + \"#\" + concept for concept in triple]) for triple in flatten(triple_pairs)]\n",
    "    relations.extend(triple_pairs)\n",
    "\n",
    "relations = list(set(relations))\n",
    "entities = list(set(flatten(relations)))\n",
    "\n",
    "emb_indexer = {word: i for i, word in enumerate(list(embeddings.keys()))}\n",
    "emb_vals = list(embeddings.values())\n",
    "\n",
    "def generate_data(onto):\n",
    "#     print (onto)\n",
    "    relations_sub = [elem for elem in relations if elem[0].split(\"#\")[0] == onto]\n",
    "    entities_sub = [elem for elem in entities if elem.split(\"#\")[0] == onto]\n",
    "    entity_idx = {elem: (i, emb_indexer[elem.split(\"#\")[1]]) for (i,elem) in enumerate(entities_sub) }\n",
    "    \n",
    "    edges = np.array([(entity_idx[a][0], entity_idx[b][0]) for (a,b) in relations_sub])\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), \n",
    "                        shape=(len(entities_sub), len(entities_sub)), dtype=np.float32)\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    adj = np.array(adj.todense())\n",
    "    return (entity_idx, adj)\n",
    "\n",
    "def generate_input_tensors(elem_tuple):\n",
    "    data = []\n",
    "    for elem in elem_tuple:\n",
    "        entity_idx, adj = generate_data(elem.split(\"#\")[0])\n",
    "        emb_idx = torch.LongTensor([[entity_idx[elem][1]]])\n",
    "        adj = torch.FloatTensor(adj)\n",
    "        data.append((emb_idx, adj))\n",
    "    return data\n",
    "        \n",
    "data_ontologies = {ont: generate_data(ont) for ont in list(set(flatten(ontologies_in_alignment)))}\n",
    "entities_set = set(entities)\n",
    "nn_data_true = [key for key in data if data[key][-1] == \"T\" and key[0] in entities_set and key[1] in entities_set]\n",
    "nn_data_false = [key for key in data if data[key][-1] == \"F\" and key[0] in entities_set and key[1] in entities_set]\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "weight_decay = 0.0001\n",
    "batch_size = 10\n",
    "batch_size = min(batch_size, len(nn_data_true))\n",
    "num_batches = int(ceil(len(nn_data_true)/batch_size))\n",
    "\n",
    "model = SiameseNetwork()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(nn_data_true)\n",
    "    np.random.shuffle(nn_data_false)\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx+1) * batch_size\n",
    "            \n",
    "        pos_elems = np.array(nn_data_true)[batch_start:batch_end]\n",
    "        neg_elems = np.array(nn_data_false)[batch_start:batch_end]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pos_data = [(torch.LongTensor([1]), generate_input_tensors(pos_elem)) for pos_elem in pos_elems]\n",
    "        neg_data = [(torch.LongTensor([0]), generate_input_tensors(neg_elem)) for neg_elem in neg_elems]\n",
    "        \n",
    "        dat = pos_data + neg_data\n",
    "        np.random.shuffle(dat)\n",
    "        targets, inputs = list(zip(*dat))\n",
    "        np.array(inputs).reshape\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print (\"Epoch: {} Idx: {} Loss: {}\".format(epoch, i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GraphAttentionLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.zeros(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, inp, adj):\n",
    "        print (inp.shape, self.W.shape)\n",
    "        h = torch.mm(inp, self.W)\n",
    "        N = h.size()[0] \n",
    "\n",
    "        a_input = torch.cat([h.repeat(1, N).view(N * N, -1), h.repeat(N, 1)], dim=1).view(N, -1, 2 * self.out_features)\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "\n",
    "        zero_vec = -9e15*torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime = torch.matmul(attention, h)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, nfeat=512, nhid=100, dropout=0.3, alpha=0.001, nheads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.name_embedding = nn.Embedding(len(embeddings), 512)\n",
    "        self.name_embedding.load_state_dict({'weight': torch.from_numpy(np.array(emb_vals))})\n",
    "        \n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
    "        for i, attention in enumerate(self.attentions):\n",
    "            self.add_module('attention_{}'.format(i), attention)\n",
    "\n",
    "        self.out_att = GraphAttentionLayer(nhid * nheads, 2, dropout=dropout, alpha=alpha, concat=False)\n",
    "\n",
    "    def forward(self, emb_indices, adj_mats):\n",
    "        results = []\n",
    "        for i in range(2):\n",
    "            x = torch.flatten(self.name_embedding(emb_indices))\n",
    "            print (x.shape)\n",
    "            adj = data[i][1]\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
    "            x = F.leaky_relu(F.dropout(x, self.dropout, training=self.training))\n",
    "            results.append(x)\n",
    "        x = torch.abs(results[1] - results[0])\n",
    "        x = F.elu(self.out_att(x, adj))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "nn_data_true = [key for key in data if data[key][-1] == \"T\" and key[0] in entities_set and key[1] in entities_set]\n",
    "nn_data_false = [key for key in data if data[key][-1] == \"F\" and key[0] in entities_set and key[1] in entities_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "relations = []\n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    triple_pairs = [list(itertools.product(el[0].split(\"###\"), el[1].split(\"###\"))) for el in ont.get_triples()]\n",
    "    triple_pairs = [tuple([ont_name + \"#\" + concept for concept in triple]) for triple in flatten(triple_pairs)]\n",
    "    relations.extend(triple_pairs)\n",
    "\n",
    "relations = list(set(relations))\n",
    "entities = list(set(flatten(relations)))\n",
    "\n",
    "emb_indexer = {word: i for i, word in enumerate(list(embeddings.keys()))}\n",
    "emb_vals = list(embeddings.values())\n",
    "\n",
    "def generate_data(onto):\n",
    "#     print (onto)\n",
    "    relations_sub = [elem for elem in relations if elem[0].split(\"#\")[0] == onto]\n",
    "    entities_sub = [elem for elem in entities if elem.split(\"#\")[0] == onto]\n",
    "    entity_idx = {elem: (i, emb_indexer[elem.split(\"#\")[1]]) for (i,elem) in enumerate(entities_sub) }\n",
    "    \n",
    "    edges = np.array([(entity_idx[a][0], entity_idx[b][0]) for (a,b) in relations_sub])\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), \n",
    "                        shape=(len(entities_sub), len(entities_sub)), dtype=np.float32)\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    adj = np.array(adj.todense())\n",
    "    return (entity_idx, adj)\n",
    "\n",
    "def generate_input_tensors(elem_tuple):\n",
    "    data = []\n",
    "    for elem in elem_tuple:\n",
    "        entity_idx, adj = generate_data(elem.split(\"#\")[0])\n",
    "        emb_idx = entity_idx[elem][1]\n",
    "        data.append((emb_idx, adj))\n",
    "    return data\n",
    "        \n",
    "data_ontologies = {ont: generate_data(ont) for ont in list(set(flatten(ontologies_in_alignment)))}\n",
    "entities_set = set(entities)\n",
    "nn_data_true = [key for key in data if data[key][-1] == \"T\" and key[0] in entities_set and key[1] in entities_set]\n",
    "nn_data_false = [key for key in data if data[key][-1] == \"F\" and key[0] in entities_set and key[1] in entities_set]\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "weight_decay = 0.0001\n",
    "batch_size = 10\n",
    "batch_size = min(batch_size, len(nn_data_true))\n",
    "num_batches = int(ceil(len(nn_data_true)/batch_size))\n",
    "\n",
    "model = SiameseNetwork()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(nn_data_true)\n",
    "    np.random.shuffle(nn_data_false)\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx+1) * batch_size\n",
    "            \n",
    "        pos_elems = np.array(nn_data_true)[batch_start:batch_end]\n",
    "        neg_elems = np.array(nn_data_false)[batch_start:batch_end]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pos_data = [(torch.LongTensor([1]), generate_input_tensors(pos_elem)) for pos_elem in pos_elems]\n",
    "        neg_data = [(torch.LongTensor([0]), generate_input_tensors(neg_elem)) for neg_elem in neg_elems]\n",
    "        \n",
    "        dat = pos_data + neg_data\n",
    "        np.random.shuffle(dat)\n",
    "        targets, inputs = list(zip(*dat))\n",
    "        emb_indices, adj_mats = np.array(inputs).reshape(2,-1)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = F.cross_entropy(outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print (\"Epoch: {} Idx: {} Loss: {}\".format(epoch, i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_indexer = {word: i for i, word in enumerate(list(embeddings.keys()))}\n",
    "emb_indexer_inv = {i: word for i, word in enumerate(list(embeddings.keys()))}\n",
    "emb_vals = list(embeddings.values())\n",
    "\n",
    "def is_valid(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) not in test_onto\n",
    "\n",
    "def generate_data(elem_tuple):\n",
    "    return np.array([emb_indexer[elem] for elem in elem_tuple])\n",
    "\n",
    "def generate_input(elems, target):\n",
    "    inputs = np.array([generate_data(elem) for elem in list(elems)])\n",
    "    targets = np.array([target for i in range(len(elems))])\n",
    "\n",
    "    indices = np.random.permutation(inputs.shape[0])\n",
    "    inputs, targets = inputs[indices], targets[indices]\n",
    "    inputs = torch.LongTensor(list(zip(*inputs)))\n",
    "    targets = torch.LongTensor(targets)\n",
    "    \n",
    "    return inputs, targets\n",
    "    \n",
    "data = OrderedDict(sorted(data.items(),  key=lambda x:x[1][0], reverse=True))\n",
    "all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "all_results = []\n",
    "for i in list(range(0, len(all_ont_pairs), 3)):\n",
    "    test_onto = all_ont_pairs[i:i+3]\n",
    "    \n",
    "    train_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) not in test_onto}\n",
    "    test_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) in test_onto}\n",
    "\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "    train_test_split = 0.9\n",
    "\n",
    "    train_data_t = [key for key in train_data if data[key][-1] == \"T\"]\n",
    "    train_data_f = [key for key in train_data if data[key][-1] == \"F\"]\n",
    "    \n",
    "    lr = 0.001\n",
    "    num_epochs = 50\n",
    "    weight_decay = 0.001\n",
    "    batch_size = 10\n",
    "    dropout = 0.3\n",
    "    batch_size = min(batch_size, len(train_data_t))\n",
    "    num_batches = int(ceil(len(train_data_t)/batch_size))\n",
    "    \n",
    "    model = SiameseNetwork()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        np.random.shuffle(train_data_t)\n",
    "        np.random.shuffle(train_data_f)\n",
    "        train_data_f = train_data_f[:len(train_data_t)]\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            pos_elems = np.array(train_data_t)[batch_start:batch_end]\n",
    "            neg_elems = np.array(train_data_f)[batch_start:batch_end]\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            inputs_pos, targets_pos = generate_input(pos_elems, 1)\n",
    "            inputs_neg, targets_neg = generate_input(neg_elems, 0)\n",
    "            \n",
    "            outputs_pos = model(inputs_pos)\n",
    "            loss_pos = F.cross_entropy(outputs_pos, targets_pos)\n",
    "            \n",
    "            outputs_neg = model(inputs_neg)\n",
    "            loss_neg = F.cross_entropy(outputs_neg, targets_neg)\n",
    "            \n",
    "            loss = loss_pos + loss_neg\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx%10 == 0:\n",
    "                print (\"Epoch: {} Idx: {} Loss: {}\".format(epoch, batch_idx, loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    test_data_t = [key for key in test_data if data[key][-1] == \"T\"]\n",
    "    test_data_f = [key for key in test_data if data[key][-1] == \"F\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        batch_size = min(batch_size, len(test_data_t))\n",
    "        num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "\n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "        test_data_f = test_data_f[:len(test_data_t)]\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            pos_elems = np.array(test_data_t)[batch_start:batch_end]\n",
    "            neg_elems = np.array(test_data_f)[batch_start:batch_end]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = np.array([generate_data(elem) for elem in list(pos_elems) + list(neg_elems)])\n",
    "            targets = np.array([1 for i in range(len(pos_elems))] + [0 for i in range(len(neg_elems))])\n",
    "\n",
    "            indices = np.random.permutation(inputs.shape[0])\n",
    "            inputs, targets = inputs[indices], targets[indices]\n",
    "            inputs = torch.LongTensor(list(zip(*inputs)))\n",
    "            targets = torch.LongTensor(targets)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predicted = [el.item() for el in predicted]\n",
    "            \n",
    "            targets = [el.item() for el in targets]\n",
    "\n",
    "            for idx, pred_elem in enumerate(predicted):\n",
    "                if pred_elem == 1:\n",
    "                    ent1 = emb_indexer_inv[inputs.numpy()[0][idx]]\n",
    "                    ent2 = emb_indexer_inv[inputs.numpy()[1][idx]]\n",
    "                    all_pred.append((ent1, ent2))\n",
    "        \n",
    "        \n",
    "        tp = len([elem for elem in all_pred if test_data[elem][1] == \"T\"])\n",
    "        fn = len([key for key in gt_mappings if key not in set(all_pred) and is_valid(test_onto, key)])\n",
    "        fp = len([elem for elem in all_pred if test_data[elem][1] == \"F\"])\n",
    "\n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        \n",
    "        print (\"Precision: {} Recall: {} F1-Score: {} F2-Score: {} F0.5-Score: {}\".format(\n",
    "            precision, recall, f1score, f2score, f0_5score))\n",
    "        all_results.append((precision, recall, f1score, f2score, f0_5score))\n",
    "\n",
    "print (\"Final Results: \", np.mean(all_results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics\n",
    "    all_results = []\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        batch_size = min(batch_size, len(test_data_t))\n",
    "        num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "        batch_size_f = int(ceil(len(test_data_f)/num_batches))\n",
    "        \n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            batch_start_f = batch_idx * batch_size_f\n",
    "            batch_end_f = (batch_idx+1) * batch_size_f\n",
    "            \n",
    "            pos_elems = np.array(test_data_t)[batch_start:batch_end]\n",
    "            neg_elems = np.array(test_data_f)[batch_start_f:batch_end_f]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = np.array([generate_data(elem) for elem in list(pos_elems) + list(neg_elems)])\n",
    "            targets = np.array([1 for i in range(len(pos_elems))] + [0 for i in range(len(neg_elems))])\n",
    "\n",
    "            indices = np.random.permutation(inputs.shape[0])\n",
    "            inputs, targets = inputs[indices], targets[indices]\n",
    "            inputs = torch.LongTensor(list(zip(*inputs)))\n",
    "            targets = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            outputs /= torch.sum(outputs, dim=1).view(-1, 1)\n",
    "#             outputs = 1 - outputs\n",
    "\n",
    "            values, predicted = torch.max(outputs, 1)\n",
    "            predicted = [el.item() for el in predicted]\n",
    "            \n",
    "            targets = [el.item() for el in targets]\n",
    "            \n",
    "            write ((\"Outputs:\", [str(s) for s in list(outputs.numpy())]))\n",
    "            write ((\"Targets:\", [str(s) for s in targets]))\n",
    "            for idx, pred_elem in enumerate(predicted):\n",
    "                if pred_elem == 1:\n",
    "                    ent1 = emb_indexer_inv[inputs.numpy()[0][idx]]\n",
    "                    ent2 = emb_indexer_inv[inputs.numpy()[1][idx]]\n",
    "                    all_pred.append((ent1, ent2))\n",
    "        \n",
    "        \n",
    "        tp = len([elem for elem in all_pred if test_data[elem][1] == \"T\"])\n",
    "        fn = len([key for key in gt_mappings if key not in set(all_pred) and not is_valid(test_onto, key)])\n",
    "        fp = len([elem for elem in all_pred if test_data[elem][1] == \"F\"])\n",
    "\n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            return\n",
    "        \n",
    "        print (\"Precision: {} Recall: {} F1-Score: {} F2-Score: {} F0.5-Score: {}\".format(\n",
    "            precision, recall, f1score, f2score, f0_5score))\n",
    "        all_results.append((precision, recall, f1score, f2score, f0_5score))\n",
    "\n",
    "    print (\"Final Results: \", np.mean(all_results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0688, 23.0000],\n",
       "        [ 1.0000,  4.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_misclassified(input_list, feat):\n",
    "#     print (input_list, feat)\n",
    "    return [el for el in input_list if features_dict[el[0].split(\"#\")[1]][\"type\"] in feat]\n",
    "\n",
    "\n",
    "#     for i,key in enumerate(all_results):\n",
    "#         if all_results[key][0] > opt_threshold:\n",
    "#             res.append(key)\n",
    "\n",
    "#     fn_list = [key for key in gt_mappings if key not in set(res) and not is_valid(test_onto, key)]\n",
    "#     fp_list = [elem for elem in res if all_results[elem][1] == \"F\"]\n",
    "#     tp_list = [elem for elem in res if all_results[elem][1] == \"T\"]\n",
    "            \n",
    "            \n",
    "#     fn_prop, fn_entity = get_misclassified(fn_list, [\"property\", \"triple\"]), get_misclassified(fn_list, [\"entity\"])\n",
    "#     fp_prop, fp_entity = get_misclassified(fp_list, [\"property\", \"triple\"]), get_misclassified(fp_list, [\"entity\"])\n",
    "\n",
    "#     write((\"False negative props: \", \"\\n\".join([str(s) for s in fn_prop]), \"False negative entities: \", \"\\n\".join([str(s) for s in fn_entity])))\n",
    "#     write((\"False positive props: \", \"\\n\".join([str(s) for s in fp_prop]), \"False positive entities: \", \"\\n\".join([str(s) for s in fp_entity])))\n",
    "\n",
    "#     write (\"Fn prop: {} Fn entity: {} Prop misclassification Percentage: {}\".format(len(fn_prop), len(fn_entity), float(len(fn_prop)/(len(fn_entity)+len(fn_prop)))))\n",
    "    \n",
    "#     tot_prop, tot_ent = get_misclassified(test_data, [\"property\", \"triple\"]), get_misclassified(test_data, [\"entity\"])\n",
    "#     write(\"Total proportion of props: \" + str(float(len(tot_prop)/(len(tot_ent)+len(tot_prop)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Greedy\n",
    "\n",
    "def is_valid(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) not in test_onto\n",
    "\n",
    "data = OrderedDict(sorted(data.items(),  key=lambda x:x[1][0], reverse=True))\n",
    "all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "results = []\n",
    "failed = []\n",
    "for i in list(range(0, len(all_ont_pairs), 3)):\n",
    "    test_onto = all_ont_pairs[i:i+3]\n",
    "    \n",
    "    train_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) not in test_onto}\n",
    "    test_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) in test_onto}\n",
    "\n",
    "    opt_threshold, optimum_metrics = -1000, [-1000 for i in range(5)]\n",
    "    t = time.time()\n",
    "    for j,threshold in enumerate(np.arange(0.15, 1.0005, 0.01)):\n",
    "        print (\"threshold =\", threshold, \"Time = \", time.time()-t) \n",
    "        pred = []\n",
    "        for i,key in enumerate(train_data):\n",
    "            if train_data[key][0] > threshold:\n",
    "                pred.append(key)\n",
    "\n",
    "        tp = len([elem for elem in pred if train_data[elem][1] == \"T\"])\n",
    "        fn = len([key for key in gt_mappings if key not in set(pred) and is_valid(test_onto, key)])\n",
    "        fp = len([elem for elem in pred if train_data[elem][1] == \"F\"])\n",
    "        precision, recall, f1score, f2score, f0_5score = [None for i in range(5)] \n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        print (precision, recall, f1score, f2score, f0_5score)\n",
    "\n",
    "        if f1score > optimum_metrics[2]:\n",
    "            optimum_metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "            opt_threshold = threshold\n",
    "    \n",
    "    threshold = opt_threshold\n",
    "    pred = []\n",
    "    for i,key in enumerate(test_data):\n",
    "        if test_data[key][0] > threshold:\n",
    "            pred.append(key)\n",
    "\n",
    "    curr = dict()\n",
    "    \n",
    "    curr[\"fn\"] = [key for key in gt_mappings if key not in set(pred) and not is_valid(test_onto, key)]\n",
    "    curr[\"fp\"] = [elem for elem in pred if test_data[elem][1] == \"F\"]\n",
    "    tp = len([elem for elem in pred if test_data[elem][1] == \"T\"])\n",
    "    fn = len(curr[\"fn\"])\n",
    "    fp = len(curr[\"fp\"])\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        f1score = 2 * precision * recall / (precision + recall)\n",
    "        f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "        f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        pass\n",
    "            \n",
    "    metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "    failed.append(curr)\n",
    "    results.append(metrics)\n",
    "\n",
    "print (\"Final Results:\", np.mean(results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RotatE - complete\n",
    "\n",
    "# Data Generation for RotatE embeddings from OpenKE\n",
    "\n",
    "ontologies_in_alignment = list(set(flatten([l.split(\".\")[0].split(\"-\") for l in os.listdir(\"reference-alignment/\")])))\n",
    "\n",
    "def generate(ontology):\n",
    "    ont = Ontology(ontology)\n",
    "    classes_dict = {elem : str(i) for i,elem in enumerate(ont.get_classes())} \n",
    "    props = ont.get_object_properties() + ont.get_data_properties() + [\"subclass_of\"]\n",
    "    prop_dict = {elem : str(i) for i,elem in enumerate(props)} \n",
    "    triplets = [\"\\t\".join((classes_dict[el[0]], classes_dict[el[1]], prop_dict[el[2]])) for el in ont.get_triples()]\n",
    "    return classes_dict, prop_dict, triplets\n",
    "\n",
    "all_elems = {}\n",
    "\n",
    "for ont_name in ontologies_in_alignment:\n",
    "    ont = \"conference_ontologies/\" + ont_name + \".owl\"\n",
    "    \n",
    "    benchmark_dir = \"OpenKE/benchmarks/\" + ont_name\n",
    "    if not os.path.isdir(benchmark_dir):\n",
    "        os.mkdir(benchmark_dir)\n",
    "    \n",
    "    classes_dict, prop_dict, triplets = generate(ont)\n",
    "    \n",
    "    entity_str = str(len(classes_dict)) + \"\\n\" + \"\\n\".join([\"\\t\".join(elem) for elem in classes_dict.items()])\n",
    "    prop_str = str(len(prop_dict)) + \"\\n\" + \"\\n\".join([\"\\t\".join(elem) for elem in prop_dict.items()])\n",
    "    triplets_str = str(len(triplets)) + \"\\n\" + \"\\n\".join(triplets)\n",
    "    print(classes_dict)\n",
    "    print (ont_name, len(classes_dict.keys()), \n",
    "           len([el for el in classes_dict if el.split(\"#\")[0] == \"cmt\"]))\n",
    "    for key in classes_dict.keys():\n",
    "        all_elems[ont_name+\"#ENT@@\"+key] = {\"type\": \"entity\"}\n",
    "        \n",
    "    for key in prop_dict.keys():\n",
    "        all_elems[ont_name+\"#PROP@@\"+key] = {\"type\": \"property\"}\n",
    "    \n",
    "    open(benchmark_dir + \"/entity2id.txt\", \"w+\").write(entity_str)\n",
    "    open(benchmark_dir + \"/relation2id.txt\", \"w+\").write(prop_str)\n",
    "    open(benchmark_dir + \"/train2id.txt\", \"w+\").write(triplets_str)\n",
    "\n",
    "# print (le)\n",
    "openke_embeds = extractUSEEmbeddings([\" \".join(parse(elem.split(\"@@\")[1])) for elem in all_elems.keys()])\n",
    "openke_embeds_dict = {key: {\"type\": all_elems[key][\"type\"], \"embeds\": openke_embeds[i]} for i,key in enumerate(all_elems)}\n",
    "\n",
    "\n",
    "for ont_name in ontologies_in_alignment:\n",
    "    benchmark_dir = \"OpenKE/benchmarks/\" + ont_name + \"/\"\n",
    "    f = open(benchmark_dir + \"embeddings.pkl\", \"wb\")\n",
    "    entity_embeds = {el.split(\"@@\")[1]: np.concatenate((openke_embeds_dict[el][\"embeds\"], \n",
    "                                                      openke_embeds_dict[el][\"embeds\"]))\n",
    "                     for el in openke_embeds_dict \n",
    "                     if el.split(\"#\")[0] == ont_name and openke_embeds_dict[el][\"type\"] == \"entity\"}\n",
    "    print (entity_embeds.keys())\n",
    "    prop_embeds = {el.split(\"@@\")[1]: openke_embeds_dict[el][\"embeds\"] for el in openke_embeds_dict \n",
    "     if el.split(\"#\")[0] == ont_name and openke_embeds_dict[el][\"type\"] == \"property\"}\n",
    "    \n",
    "    pickle.dump([list(entity_embeds.values()),list(prop_embeds.values())], f)\n",
    "\n",
    "# Processing results\n",
    "ent_embeddings, rel_embeddings = {}, {}\n",
    "for d in os.listdir(\"OpenKE/benchmarks/\"):\n",
    "    f = open(\"OpenKE/benchmarks/\" + d + \"/embeddings_final.pkl\", \"rb\")\n",
    "    ent_emb, rel_emb = pickle.load(f)\n",
    "    entities = [d+\"#\"+l.rsplit(\"\\t\", 1)[0] for l in open(\"OpenKE/benchmarks/\" + d + \"/entity2id.txt\", \"r\").read().split(\"\\n\")[1:]]\n",
    "    relations = [d+\"#\"+l.rsplit(\"\\t\", 1)[0] for l in open(\"OpenKE/benchmarks/\" + d + \"/relation2id.txt\", \"r\").read().split(\"\\n\")[1:]]\n",
    "    if len(entities) != len(ent_emb):\n",
    "        print (\"Entity legnth mismatch\")\n",
    "        break\n",
    "    if len(relations) != len(rel_emb):\n",
    "        print (\"relation legnth mismatch\")\n",
    "        break\n",
    "    ent_embeddings = {**ent_embeddings, **dict(zip(entities, ent_emb.numpy()))}\n",
    "    rel_embeddings = {**rel_embeddings, **dict(zip(relations, rel_emb.numpy()))}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_property_features(ont_name, triple):\n",
    "\n",
    "    weight = np.sum([get_tfidf_score(word, triple[-1]) for word in parse(triple[-1])])\n",
    "    feats = []\n",
    "    feats.append(weight*embeddings[ont_name + \"#\" + triple[-1]]) # Property name\n",
    "    feats.append([embeddings[ont_name + \"#\" + el] for el in triple[0].split(\"###\")]) # Domain \n",
    "    feats.append([embeddings[ont_name + \"#\" + el] for el in triple[1].split(\"###\")]) # Range\n",
    "    return feats\n",
    "    \n",
    "def get_entity_features(ont_name, entity):\n",
    "    feats = []\n",
    "    weight = np.sum([get_tfidf_score(word, entity) for word in parse(entity)])\n",
    "    feats.append(weight * embeddings[ont_name + \"#\" + entity]) # Entity name\n",
    "#     feats.append(np.sum([get_tfidf_score(word, entity) * embeddings[word] for word in parse(entity)]))\n",
    "    return feats\n",
    "\n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    \n",
    "    triples = ont.get_triples(union_flag=1, subclass_of=False)\n",
    "    entities = ont.get_entities()\n",
    "    props = ont.get_object_properties() + ont.get_data_properties()\n",
    "\n",
    "    for triple in triples:\n",
    "        features_dict[triple[-1]] = {\"type\": \"triple\", \"features\": get_property_features(ont_name, triple)}\n",
    "    for entity in entities:\n",
    "        features_dict[entity] = {\"type\": \"entity\", \"features\": get_entity_features(ont_name, entity)}\n",
    "    for prop in props:\n",
    "        if prop not in features_dict:\n",
    "            features_dict[prop] = {\"type\": \"property\", \"features\": get_entity_features(ont_name, prop)}\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dot product similarity calculation\n",
    "\n",
    "def calc_sim_score(mapping):\n",
    "    features = embedify(mapping)\n",
    "    if features[0][\"type\"] != \"triple\" and features[1][\"type\"] != \"triple\":\n",
    "        return cos_sim(*tuple([el[\"features\"][0] for el in features]))\n",
    "    elif features[0][\"type\"] == \"triple\"  and features[1][\"type\"] == \"triple\":\n",
    "        sim_score = 0\n",
    "        names, domains, ranges = [], [], []\n",
    "        \n",
    "        for elem in [el[\"features\"] for el in features]:\n",
    "            names.append(elem[0])\n",
    "            domains.append(elem[1])\n",
    "            ranges.append(elem[2])\n",
    "        name_score = cos_sim(names[0], names[1])\n",
    "#         domain_score = np.mean([cos_sim(*elem) for elem in itertools.product(domains[0], domains[1])])\n",
    "#         ranges_score = np.mean([cos_sim(*elem) for elem in itertools.product(ranges[0], ranges[1])])\n",
    "#         return ((name_score + domain_score + ranges_score)/(len(domains[0]) + len(ranges[0]) +  ))\n",
    "#         return (name_score + domain_score + ranges_score)/3\n",
    "        return name_score\n",
    "    return cos_sim(*tuple([el[\"features\"][0] for el in features])) \n",
    "        \n",
    "        \n",
    "\n",
    "def embedify(mapping):\n",
    "    removed_hash = tuple([elem.split(\"#\")[1] for elem in mapping])\n",
    "    return (features_dict[removed_hash[0]], features_dict[removed_hash[1]])\n",
    "\n",
    "gt_mappings = [tuple([elem.split(\"/\")[-1] for elem in el]) for el in reference_alignments]\n",
    "\n",
    "data = {}\n",
    "for mapping in all_mappings:\n",
    "    if mapping in gt_mappings:\n",
    "        data[(mapping[0], mapping[1])] = (calc_sim_score(mapping), \"T\")\n",
    "    else:\n",
    "        data[(mapping[0], mapping[1])] = (calc_sim_score(mapping), \"F\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp = [\" \".join(parse(word.split(\"#\")[1])) for word in extracted_elems]\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\S+\")\n",
    "X = vectorizer.fit_transform(inp)\n",
    "word2idx_tfidf = {word: i for (i, word)  in enumerate(vectorizer.get_feature_names())}\n",
    "entity2idx_tfidf = {word.split(\"#\")[1]: i for (i, word)  in enumerate(extracted_elems)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "f = open(\"data.pkl\", \"rb\")\n",
    "data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings, all_ont_pairs = pickle.load(f)\n",
    "\n",
    "def create_embeddings_file(embeds, name):\n",
    "    global extracted_elems, data, gt_mappings, all_ont_pairs, emb_indexer, emb_indexer_inv\n",
    "    embedding_dim = embeds.shape[1]\n",
    "    embeds = np.array([np.zeros(embedding_dim)] + list(embeds))\n",
    "    embeddings = dict(zip(extracted_elems, embeds))\n",
    "\n",
    "    emb_vals = list(embeddings.values())\n",
    "\n",
    "\n",
    "    f = open(\"data_\" + name + \".pkl\", \"wb\")\n",
    "    pickle.dump([data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings, all_ont_pairs], f)\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    embeddings = elmo(x, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        # return average of ELMo features\n",
    "        return sess.run(tf.reduce_mean(embeddings,1))\n",
    "\n",
    "\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)\n",
    "emb = elmo_vectors(inp)\n",
    "create_embeddings_file(emb, \"elmov2\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# roberta_large = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
    "# bert_large = SentenceTransformer(\"bert-large-nli-stsb-mean-tokens\")\n",
    "roberta_large_nli = SentenceTransformer('roberta-large-nli-mean-tokens')\n",
    "bert_large_nli = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "distilbert_large_nli = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "distilbert_large = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
