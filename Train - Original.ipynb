{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "sys.argv = [\"main\", 10, 1, \"../Input/data_german_dataset.pkl\", \"test10_1.pkl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours: 10\n",
      "Number of entities: 130000\n",
      "Training size: 110500 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.22921109024666714\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Training size: 110500 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.2113765065101063\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Training size: 110501 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.11066699154927566\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Training size: 110499 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.06231932412136062\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Training size: 110500 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.20850670316110773\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Training size: 110501 Testing size: 13000\n",
      "Epoch: 0 Idx: 0 Loss: 0.08336651582283303\n",
      "Len (direct inputs):  0\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "Len (direct inputs):  0\n",
      "Performance : (0.725, 0.3799126637554585, 0.498567335243553, 0.4198841698841699, 0.6135401974612129)\n",
      "Performance : (0.8921568627450981, 0.3922413793103448, 0.5449101796407185, 0.441747572815534, 0.7109375)\n",
      "Performance : (0.8913043478260869, 0.354978354978355, 0.5077399380804953, 0.4035433070866142, 0.6844741235392321)\n",
      "Performance : (0.569377990430622, 0.6071428571428571, 0.5876543209876544, 0.5991943605236656, 0.5765503875968992)\n",
      "Performance : (0.7524752475247525, 0.3671497584541063, 0.49350649350649345, 0.40904198062432723, 0.6219312602291325)\n",
      "Performance : (0.7450980392156863, 0.35348837209302325, 0.4794952681388012, 0.39501039501039503, 0.6099518459069021)\n",
      "Final Results: [0.76256875 0.40915223 0.51864559 0.44473696 0.63623089]\n",
      "Threshold:  0.8315654142259747\n"
     ]
    }
   ],
   "source": [
    "import os, itertools, time, pickle, operator\n",
    "import subprocess\n",
    "from xml.dom import minidom\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, sys\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil, exp\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "f = open(sys.argv[3], \"rb\")\n",
    "data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings, neighbours_dicts, ontologies_in_alignment = pickle.load(f)\n",
    "ontologies_in_alignment = [tuple(pair) for pair in ontologies_in_alignment]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "direct_inputs, direct_targets = [], []\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return 1 - spatial.distance.cosine(a,b)\n",
    "\n",
    "all_fn, all_fp = [], []\n",
    "\n",
    "threshold_results = {}\n",
    "\n",
    "def test():\n",
    "    global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics, direct_inputs, direct_targets, threshold_results\n",
    "    all_results = OrderedDict()    \n",
    "    direct_inputs, direct_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        \n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "\n",
    "        inputs_pos, targets_pos = generate_input(test_data_t, 1)\n",
    "        inputs_neg, targets_neg = generate_input(test_data_f, 0)\n",
    "\n",
    "        inputs_all = list(inputs_pos) + list(inputs_neg)\n",
    "        targets_all = list(targets_pos) + list(targets_neg)\n",
    "        \n",
    "        indices_all = np.random.permutation(len(inputs_all))\n",
    "        inputs_all = np.array(inputs_all)[indices_all]\n",
    "        targets_all = np.array(targets_all)[indices_all]\n",
    "\n",
    "        batch_size = min(batch_size, len(inputs_all))\n",
    "        num_batches = int(ceil(len(inputs_all)/batch_size))\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            inputs = inputs_all[batch_start: batch_end]\n",
    "            targets = targets_all[batch_start: batch_end]\n",
    "            \n",
    "            inp = inputs.transpose(1,0,2)\n",
    "            \n",
    "            inp_elems = torch.LongTensor(inputs).to(device)\n",
    "            targ_elems = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inp_elems)\n",
    "            outputs = [el.item() for el in outputs]\n",
    "            targets = [True if el.item() else False for el in targets]\n",
    "\n",
    "            for idx, pred_elem in enumerate(outputs):\n",
    "                ent1 = emb_indexer_inv[inp[0][idx][0]]\n",
    "                ent2 = emb_indexer_inv[inp[1][idx][0]]\n",
    "                if (ent1, ent2) in all_results:\n",
    "                    print (\"Error: \", ent1, ent2, \"already present\")\n",
    "                all_results[(ent1, ent2)] = (pred_elem, targets[idx])\n",
    "        \n",
    "        direct_targets = [True if el else False for el in direct_targets]\n",
    "        \n",
    "        print (\"Len (direct inputs): \", len(direct_inputs))\n",
    "        for idx, direct_input in enumerate(direct_inputs):\n",
    "            ent1 = emb_indexer_inv[direct_input[0]]\n",
    "            ent2 = emb_indexer_inv[direct_input[1]]\n",
    "            sim = cos_sim(emb_vals[direct_input[0]], emb_vals[direct_input[1]])\n",
    "            all_results[(ent1, ent2)] = (sim, direct_targets[idx])\n",
    "    return (test_data_t, all_results)\n",
    "\n",
    "def optimize_threshold():\n",
    "    global batch_size, val_data_t, val_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics, direct_inputs, direct_targets, threshold_results\n",
    "    all_results = OrderedDict()\n",
    "    direct_inputs, direct_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        \n",
    "        np.random.shuffle(val_data_t)\n",
    "        np.random.shuffle(val_data_f)\n",
    "\n",
    "        inputs_pos, targets_pos = generate_input(val_data_t, 1)\n",
    "        inputs_neg, targets_neg = generate_input(val_data_f, 0)\n",
    "\n",
    "        inputs_all = list(inputs_pos) + list(inputs_neg)\n",
    "        targets_all = list(targets_pos) + list(targets_neg)\n",
    "        \n",
    "        indices_all = np.random.permutation(len(inputs_all))\n",
    "        inputs_all = np.array(inputs_all)[indices_all]\n",
    "        targets_all = np.array(targets_all)[indices_all]\n",
    "\n",
    "        batch_size = min(batch_size, len(inputs_all))\n",
    "        num_batches = int(ceil(len(inputs_all)/batch_size))\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            inputs = inputs_all[batch_start: batch_end]\n",
    "            targets = targets_all[batch_start: batch_end]\n",
    "            \n",
    "            inp = inputs.transpose(1,0,2)\n",
    "            \n",
    "            inp_elems = torch.LongTensor(inputs).to(device)\n",
    "            targ_elems = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inp_elems)\n",
    "            outputs = [el.item() for el in outputs]\n",
    "            targets = [True if el.item() else False for el in targets]\n",
    "\n",
    "            for idx, pred_elem in enumerate(outputs):\n",
    "                ent1 = emb_indexer_inv[inp[0][idx][0]]\n",
    "                ent2 = emb_indexer_inv[inp[1][idx][0]]\n",
    "                if (ent1, ent2) in all_results:\n",
    "                    print (\"Error: \", ent1, ent2, \"already present\")\n",
    "                all_results[(ent1, ent2)] = (pred_elem, targets[idx])\n",
    "        \n",
    "        direct_targets = [True if el else False for el in direct_targets]\n",
    "        \n",
    "        print (\"Len (direct inputs): \", len(direct_inputs))\n",
    "        for idx, direct_input in enumerate(direct_inputs):\n",
    "            ent1 = emb_indexer_inv[direct_input[0]]\n",
    "            ent2 = emb_indexer_inv[direct_input[1]]\n",
    "            sim = cos_sim(emb_vals[direct_input[0]], emb_vals[direct_input[1]])\n",
    "            all_results[(ent1, ent2)] = (sim, direct_targets[idx])\n",
    "        \n",
    "        low_threshold = np.min([el[0] for el in all_results.values()]) - 0.02\n",
    "        high_threshold = np.max([el[0] for el in all_results.values()]) + 0.02\n",
    "        threshold = low_threshold\n",
    "        step = 0.001\n",
    "        while threshold < high_threshold:\n",
    "            res = []\n",
    "            for i,key in enumerate(all_results):\n",
    "                if all_results[key][0] > threshold:\n",
    "                    res.append(key)\n",
    "            s = set(res)\n",
    "            fn_list = [(key, all_results[key][0]) for key in val_data_t if key not in s]\n",
    "            fp_list = [(elem, all_results[elem][0]) for elem in res if not all_results[elem][1]]\n",
    "            tp_list = [(elem, all_results[elem][0]) for elem in res if all_results[elem][1]]\n",
    "            \n",
    "            tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "            exception = False\n",
    "            \n",
    "            try:\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1score = 2 * precision * recall / (precision + recall)\n",
    "                f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "                f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                exception = True\n",
    "                step = 0.001\n",
    "                threshold += step\n",
    "                continue\n",
    "            # print (\"Threshold: \", threshold, precision, recall, f1score, f2score, f0_5score)\n",
    "            if threshold in threshold_results:\n",
    "                threshold_results[threshold].append([precision, recall, f1score, f2score, f0_5score])\n",
    "            else:\n",
    "                threshold_results[threshold] = [[precision, recall, f1score, f2score, f0_5score]]\n",
    "\n",
    "            if threshold > 0.98 and not exception:\n",
    "                step = 0.0001\n",
    "            else:\n",
    "                step = 0.001\n",
    "            threshold += step \n",
    "        \n",
    "def calculate_performance():\n",
    "    global final_results\n",
    "    all_metrics, all_fn, all_fp = [], [], []\n",
    "    for (test_data_t, all_results) in final_results:\n",
    "        res = []\n",
    "        for i,key in enumerate(all_results):\n",
    "            if all_results[key][0] > threshold:\n",
    "                res.append(key)\n",
    "        s = set(res)\n",
    "        fn_list = [(key, all_results[key][0]) for key in test_data_t if key not in s]\n",
    "        fp_list = [(elem, all_results[elem][0]) for elem in res if not all_results[elem][1]]\n",
    "        tp_list = [(elem, all_results[elem][0]) for elem in res if all_results[elem][1]]\n",
    "        tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "        \n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        print (\"Performance :\", (precision, recall, f1score, f2score, f0_5score))\n",
    "        all_metrics.append((precision, recall, f1score, f2score, f0_5score))\n",
    "\n",
    "        all_fn.extend(fn_list)\n",
    "        all_fp.extend(fp_list)\n",
    "    return (all_fn, all_fp, all_metrics)\n",
    "\n",
    "\n",
    "def masked_softmax(inp):\n",
    "    inp = inp.double()\n",
    "    mask = ((inp != 0).double() - 1) * 9999  # for -inf\n",
    "    return (inp + mask).softmax(dim=-1)\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.embedding_dim = np.array(emb_vals).shape[1]\n",
    "        \n",
    "        self.name_embedding = nn.Embedding(len(emb_vals), self.embedding_dim)\n",
    "        self.name_embedding.load_state_dict({'weight': torch.from_numpy(np.array(emb_vals))})\n",
    "        self.name_embedding.weight.requires_grad = False\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.cosine_sim_layer = nn.CosineSimilarity(dim=1)\n",
    "        self.output = nn.Linear(2*self.embedding_dim, 300)\n",
    "        n = int(sys.argv[1])\n",
    "        self.v = nn.Parameter(torch.DoubleTensor([1/(n-1) for i in range(n-1)]))\n",
    " \n",
    "    def forward(self, inputs):\n",
    "        results = []\n",
    "        inputs = inputs.permute(1,0,2)\n",
    "        for i in range(2):\n",
    "            x = self.name_embedding(inputs[i])\n",
    "            node = x.permute(1,0,2)[:1].permute(1,0,2) # 3993 * 1 * 512\n",
    "            neighbours = x.permute(1,0,2)[1:].permute(1,0,2) # 3993 * 9 * 512\n",
    "            \n",
    "            att_weights = torch.bmm(neighbours, node.permute(0, 2, 1)).squeeze()\n",
    "            att_weights = masked_softmax(att_weights).unsqueeze(-1)\n",
    "            context = torch.matmul(self.v, att_weights * neighbours)\n",
    "\n",
    "            x = torch.cat((node.reshape(-1, self.embedding_dim), context.reshape(-1, self.embedding_dim)), dim=1)\n",
    "            x = self.output(x)\n",
    "            results.append(x)\n",
    "        x = self.cosine_sim_layer(results[0], results[1])\n",
    "        return x\n",
    "\n",
    "def is_valid(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) not in test_onto\n",
    "\n",
    "def generate_data_neighbourless(elem_tuple):\n",
    "    op = np.array([emb_indexer[elem] for elem in elem_tuple])\n",
    "    return op\n",
    "\n",
    "def generate_data(elem_tuple):\n",
    "    return np.array([[emb_indexer[el] for el in neighbours_dicts[elem.split(\"#\")[0]][elem]] for elem in elem_tuple])\n",
    "\n",
    "def generate_input(elems, target):\n",
    "    inputs, targets = [], []\n",
    "    global direct_inputs, direct_targets\n",
    "    for elem in list(elems):\n",
    "        try:\n",
    "            inputs.append(generate_data(elem))\n",
    "            targets.append(target)\n",
    "        except:\n",
    "            direct_inputs.append(generate_data_neighbourless(elem))\n",
    "            direct_targets.append(target)\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "print(\"Number of neighbours: \" + str(sys.argv[1]))\n",
    "\n",
    "def count_non_unk(elem):\n",
    "    return len([l for l in elem if l!=\"<UNK>\"])\n",
    "\n",
    "neighbours_dicts = {ont: {el: neighbours_dicts[ont][el][:int(sys.argv[1])] for el in neighbours_dicts[ont]\n",
    "       if count_non_unk(neighbours_dicts[ont][el]) > int(sys.argv[2])} for ont in neighbours_dicts}\n",
    "\n",
    "data_items = list(data.items())\n",
    "\n",
    "print (\"Number of entities:\", len(data))\n",
    "\n",
    "all_metrics = []\n",
    "final_results = []\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    test_data = dict(data_items[int(0.15*i*len(data)):int((0.15*i + 0.1)*len(data))])\n",
    "    val_data = dict(data_items[int((0.15*i + 0.1)*len(data)):int((0.15*i + 0.15)*len(data))])\n",
    "    train_data = dict(data_items[:int(0.15*i*len(data))] + data_items[int(0.15*(i+1)*len(data)):])\n",
    "\n",
    "    print (\"Training size:\", len(train_data), \"Testing size:\", len(test_data))\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "\n",
    "    train_data_t = [key for key in train_data if train_data[key]]\n",
    "    train_data_f = [key for key in train_data if not train_data[key]]\n",
    "    np.random.shuffle(train_data_f)\n",
    "    train_data_f = train_data_f[:150000-len(train_data_t)]\n",
    "    train_data_t = np.repeat(train_data_t, ceil(len(train_data_f)/len(train_data_t)), axis=0)\n",
    "    train_data_t = train_data_t[:len(train_data_f)].tolist()\n",
    "\n",
    "    np.random.shuffle(train_data_f)\n",
    "    \n",
    "    lr = 0.001\n",
    "    num_epochs = 1\n",
    "    weight_decay = 0.001\n",
    "    batch_size = 10\n",
    "    dropout = 0.3\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = SiameseNetwork().to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        inputs_pos, targets_pos = generate_input(train_data_t, 1)\n",
    "        inputs_neg, targets_neg = generate_input(train_data_f, 0)\n",
    "        inputs_all = list(inputs_pos) + list(inputs_neg)\n",
    "        targets_all = list(targets_pos) + list(targets_neg)\n",
    "        \n",
    "        indices_all = np.random.permutation(len(inputs_all))\n",
    "        inputs_all = np.array(inputs_all)[indices_all][:10]\n",
    "        targets_all = np.array(targets_all)[indices_all][:10]\n",
    "\n",
    "        batch_size = min(batch_size, len(inputs_all))\n",
    "        num_batches = int(ceil(len(inputs_all)/batch_size))\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "            \n",
    "            inputs = inputs_all[batch_start: batch_end]\n",
    "            targets = targets_all[batch_start: batch_end]\n",
    "            \n",
    "            inp_elems = torch.LongTensor(inputs).to(device)\n",
    "            targ_elems = torch.DoubleTensor(targets).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inp_elems)\n",
    "            loss = F.mse_loss(outputs, targ_elems)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx%5000 == 0:\n",
    "                print (\"Epoch: {} Idx: {} Loss: {}\".format(epoch, batch_idx, loss.item()))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    val_data_t = [key for key in val_data if val_data[key]]\n",
    "    val_data_f = [key for key in val_data if not val_data[key]]\n",
    "    np.random.shuffle(val_data_f)\n",
    "    fval_len = len(val_data_f)\n",
    "    val_data_f = val_data_f[:int(0.3*fval_len)]\n",
    "    \n",
    "    optimize_threshold()\n",
    "\n",
    "    test_data_t = [key for key in test_data if test_data[key]]\n",
    "    test_data_f = [key for key in test_data if not test_data[key]]\n",
    "\n",
    "    final_results.append(test())\n",
    "\n",
    "threshold_results_mean = {el: np.mean(threshold_results[el], axis=0) for el in threshold_results}    \n",
    "threshold = max(threshold_results_mean.keys(), key=(lambda key: threshold_results_mean[key][2]))\n",
    "\n",
    "all_fn, all_fp, all_metrics = calculate_performance()\n",
    "\n",
    "f = open(sys.argv[4], \"wb\")\n",
    "pickle.dump([all_fn, all_fp], f)\n",
    "f.close()\n",
    "\n",
    "print (\"Final Results: \" + str(np.mean(all_metrics, axis=0)))\n",
    "print (\"Threshold: \", threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Supermarkt': 1,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Geschenke': 2,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Ahr': 3,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Kraeuter-Gewuerze': 4,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Honig': 5,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Pfalz': 6,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Nahe': 7,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke': 8,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Tee-Kaffee': 9,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Oesterreichisch': 10,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Home-Service': 11,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten': 12,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Franzoesisch': 13,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Spirituosen_Whisky': 14,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Oekologischer-Weinbau': 15,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Gewuerze-und-Kraeuter': 16,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Italienisch': 17,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Rheingau': 18,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Tabakwaren': 19,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wasser': 20,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Zustellservice': 21,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Schweizer': 22,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Frankreich': 23,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Accessoires': 24,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Franzoesisch': 25,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel': 26,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Kaffee-und-Tee': 27,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Kleinstanbaugebiete': 28,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Mosel': 29,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland': 30,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Spanien': 31,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Kaffee-und-Tee_Tee': 32,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke': 33,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Saale-Unstrut': 34,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Bier_Heimbrauen': 35,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Bier': 36,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Deutsch': 37,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Schweiz': 38,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Fertigprodukte': 39,\n",
       " 'google_lebensmittel#Subclass': 40,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner': 41,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Kaffee-und-Tee_Kaffee': 42,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Suedafrikanisch': 43,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Naturkost': 44,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Cocktails': 45,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Hohenlohe': 46,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Spezialitaeten': 47,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Tiefkuehlkost': 48,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch': 49,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Weinpraesente': 50,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Weltweit': 51,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Ungarn': 52,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Delikatessen': 53,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Spirituosen_Absinth': 54,\n",
       " 'google_lebensmittel#subclass_of': 55,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Oesterreich': 56,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Franken': 57,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Saar': 58,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Portugal': 59,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Griechisch': 60,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Tiefkuehlkost': 61,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Suesswaren': 62,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Kroatien': 63,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Franken': 64,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Rheingau': 65,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Baden': 66,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Oesterreichisch': 67,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Fisch': 68,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Rheinhessen': 69,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Spirituosen': 70,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Wuerttemberg': 71,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Baden': 72,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Mittelrhein': 73,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Fleisch-Wurst': 74,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Vegetarisch_Vegan': 75,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Home-Service_Pizza': 76,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Mosel-Saar-Ruwer': 77,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Champagner': 78,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Spirituosen': 79,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Obst-Gemuese': 80,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Essig-und-Oel_Olivenoel': 81,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Headshops-Hanfprodukte': 82,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch': 83,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Bier': 84,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Essig-und-Oel': 85,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Kaese-Milchprodukte': 86,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Pfalz': 87,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein': 88,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Asiatisch': 89,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Fisch-und-Meeresfruechte': 90,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Spirituosen_Wodka': 91,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Internationale-Kueche': 92,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Vegetarisch': 93,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Bodensee': 94,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch_Spanisch': 95,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Biokost': 96,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops': 97,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Kaese': 98,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Backwaren_Weihnachtsgebaeck': 99,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Italienisch': 100,\n",
       " 'web_lebensmittel#subclass_of': 101,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Deutsch_Rheinhessen': 102,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Sekt': 103,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Europaeisch_Spanisch': 104,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Landwirtschaftliche-Erzeugnisse': 105,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen': 106,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Back-Suesswaren': 107,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Fleisch-und-Wurst': 108,\n",
       " 'web_lebensmittel#Subclass': 109,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken': 110,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Deutschland_Nahe': 111,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Regionale-Spezialitaeten_Europaeisch': 112,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Getraenke_Wein_Biowein': 113,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Wein_Sekt-Champagner_Italien': 114,\n",
       " 'google_lebensmittel#World_Deutsch_Online-Shops_Essen-und-Trinken_Backwaren': 115,\n",
       " 'web_lebensmittel#Verzeichnis_Einkaufen-Sparen_Nahrungs-Genussmittel_Getraenke_Erfrischungsgetraenke': 116}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def calculate_performance():\n",
    "    global final_results\n",
    "    all_metrics, all_fn, all_fp = [], [], []\n",
    "    for (test_onto, test_data_t, all_results) in final_results:\n",
    "        res = []\n",
    "        for i,key in enumerate(all_results):\n",
    "            if all_results[key][0] > threshold:\n",
    "                res.append(key)\n",
    "        fn_list = [(key, all_results[key][0]) for key in test_data_t if key not in set(res)]\n",
    "        fp_list = [(elem, all_results[elem][0]) for elem in res if not all_results[elem][1]]\n",
    "        tp_list = [(elem, all_results[elem][0]) for elem in res if all_results[elem][1]]\n",
    "        tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "        \n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        print (\"Performance for\", test_onto, \"is :\", (precision, recall, f1score, f2score, f0_5score))\n",
    "        all_fn.extend(fn_list)\n",
    "        all_fp.extend(fp_list)\n",
    "        all_metrics.append((precision, recall, f1score, f2score, f0_5score))\n",
    "    return all_metrics, all_fn, all_fp\n",
    "\n",
    "\n",
    "\n",
    "final_results1, threshold_results1 = pickle.load(open(\"Output/conf6_2_part1.pkl\", \"rb\"))\n",
    "final_results2, threshold_results2 = pickle.load(open(\"Output/conf6_2_part2.pkl\", \"rb\"))\n",
    "threshold_results = {}\n",
    "for key in threshold_results1:\n",
    "    threshold_results[key] = threshold_results1[key]\n",
    "    if key in threshold_results2:\n",
    "        threshold_results[key].extend(threshold_results2[key])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_results_mean = {el: np.mean(threshold_results[el], axis=0) for el in threshold_results}    \n",
    "threshold = max(threshold_results_mean.keys(), key=(lambda key: threshold_results_mean[key][2]))\n",
    "final_results = final_results1 + final_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for [('confOf', 'sigkdd')] is : (0.8333333333333334, 0.7142857142857143, 0.7692307692307692, 0.7352941176470589, 0.8064516129032258)\n",
      "Performance for [('iasted', 'sigkdd')] is : (0.8, 0.8, 0.8000000000000002, 0.8, 0.8)\n",
      "Performance for [('cmt', 'ekaw')] is : (0.625, 0.45454545454545453, 0.5263157894736842, 0.4807692307692307, 0.5813953488372092)\n",
      "Performance for [('conference', 'iasted')] is : (0.6666666666666666, 0.2857142857142857, 0.4, 0.3225806451612903, 0.5263157894736842)\n",
      "Performance for [('edas', 'sigkdd')] is : (0.7, 0.4666666666666667, 0.56, 0.5, 0.6363636363636365)\n",
      "Performance for [('ekaw', 'iasted')] is : (1.0, 0.6, 0.7499999999999999, 0.6521739130434783, 0.8823529411764706)\n",
      "Final Results: [0.77083333 0.55353535 0.63425776 0.58180298 0.70547989]\n",
      "Threshold:  0.934\n"
     ]
    }
   ],
   "source": [
    "all_metrics, all_fn, all_fp = calculate_performance()\n",
    "print (\"Final Results: \" + str(np.mean(all_metrics, axis=0)))\n",
    "print (\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conference#Information_for_participants', 'ekaw#Programme_Brochure'),\n",
       " ('conference#Person', 'ekaw#Person'),\n",
       " ('conference#Tutorial', 'ekaw#Tutorial'),\n",
       " ('conference#Review', 'ekaw#Review'),\n",
       " ('conference#has_a_review', 'ekaw#hasReview'),\n",
       " ('conference#Workshop', 'ekaw#Workshop'),\n",
       " ('conference#Late_paid_applicant', 'ekaw#Late-Registered_Participant'),\n",
       " ('conference#Early_paid_applicant', 'ekaw#Early-Registered_Participant'),\n",
       " ('conference#Organization', 'ekaw#Organisation'),\n",
       " ('conference#Track-workshop_chair', 'ekaw#Workshop_Chair'),\n",
       " ('conference#Abstract', 'ekaw#Abstract'),\n",
       " ('conference#Conference_proceedings', 'ekaw#Conference_Proceedings'),\n",
       " ('conference#Conference_volume', 'ekaw#Conference'),\n",
       " ('conference#Rejected_contribution', 'ekaw#Rejected_Paper'),\n",
       " ('conference#Poster', 'ekaw#Poster_Paper'),\n",
       " ('conference#Track', 'ekaw#Track'),\n",
       " ('conference#Topic', 'ekaw#Research_Topic'),\n",
       " ('conference#Conference_www', 'ekaw#Web_Site'),\n",
       " ('conference#Invited_speaker', 'ekaw#Invited_Speaker'),\n",
       " ('conference#contributes', 'ekaw#authorOf'),\n",
       " ('conference#Accepted_contribution', 'ekaw#Accepted_Paper'),\n",
       " ('conference#Conference_document', 'ekaw#Document'),\n",
       " ('conference#Reviewed_contribution', 'ekaw#Evaluated_Paper'),\n",
       " ('conference#Submitted_contribution', 'ekaw#Submitted_Paper'),\n",
       " ('conference#Regular_author', 'ekaw#Paper_Author'),\n",
       " ('confOf#Tutorial', 'ekaw#Tutorial'),\n",
       " ('confOf#Poster', 'ekaw#Poster_Paper'),\n",
       " ('confOf#Social_event', 'ekaw#Social_Event'),\n",
       " ('confOf#Person', 'ekaw#Person'),\n",
       " ('confOf#Working_event', 'ekaw#Scientific_Event'),\n",
       " ('confOf#Conference', 'ekaw#Conference'),\n",
       " ('confOf#Author', 'ekaw#Paper_Author'),\n",
       " ('confOf#Banquet', 'ekaw#Conference_Banquet'),\n",
       " ('confOf#Workshop', 'ekaw#Workshop'),\n",
       " ('confOf#Topic', 'ekaw#Research_Topic'),\n",
       " ('confOf#Contribution', 'ekaw#Paper'),\n",
       " ('confOf#Participant', 'ekaw#Conference_Participant'),\n",
       " ('confOf#Chair_PC', 'ekaw#PC_Chair'),\n",
       " ('confOf#Organization', 'ekaw#Organisation'),\n",
       " ('confOf#Student', 'ekaw#Student'),\n",
       " ('confOf#University', 'ekaw#University'),\n",
       " ('confOf#Trip', 'ekaw#Conference_Trip'),\n",
       " ('confOf#Member_PC', 'ekaw#PC_Member'),\n",
       " ('confOf#Scholar', 'ekaw#Student'),\n",
       " ('confOf#Event', 'ekaw#Event'),\n",
       " ('ekaw#Conference', 'sigkdd#Conference'),\n",
       " ('ekaw#Person', 'sigkdd#Person'),\n",
       " ('ekaw#Paper', 'sigkdd#Paper'),\n",
       " ('ekaw#Review', 'sigkdd#Review'),\n",
       " ('ekaw#Invited_Speaker', 'sigkdd#Invited_Speaker'),\n",
       " ('ekaw#OC_Member', 'sigkdd#Organizing_Committee_member'),\n",
       " ('ekaw#Abstract', 'sigkdd#Abstract'),\n",
       " ('ekaw#PC_Chair', 'sigkdd#Program_Chair'),\n",
       " ('ekaw#Paper_Author', 'sigkdd#Author'),\n",
       " ('ekaw#Document', 'sigkdd#Document'),\n",
       " ('ekaw#Location', 'sigkdd#Place'),\n",
       " ('edas#Place', 'sigkdd#Place'),\n",
       " ('edas#hasCostAmount', 'sigkdd#Price'),\n",
       " ('edas#Person', 'sigkdd#Person'),\n",
       " ('edas#hasName', 'sigkdd#Name_of_conference'),\n",
       " ('edas#ConferenceVenuePlace', 'sigkdd#Conference_hall'),\n",
       " ('edas#Author', 'sigkdd#Author'),\n",
       " ('edas#AccommodationPlace', 'sigkdd#Hotel'),\n",
       " ('edas#startDate', 'sigkdd#Start_of_conference'),\n",
       " ('edas#ConferenceChair', 'sigkdd#General_Chair'),\n",
       " ('edas#Conference', 'sigkdd#Conference'),\n",
       " ('edas#endDate', 'sigkdd#End_of_conference'),\n",
       " ('edas#Review', 'sigkdd#Review'),\n",
       " ('edas#Document', 'sigkdd#Document'),\n",
       " ('edas#Paper', 'sigkdd#Paper'),\n",
       " ('edas#Attendee', 'sigkdd#Listener'),\n",
       " ('confOf#Person', 'sigkdd#Person'),\n",
       " ('confOf#Member_PC', 'sigkdd#Program_Committee_member'),\n",
       " ('confOf#hasEmail', 'sigkdd#E-mail'),\n",
       " ('confOf#Author', 'sigkdd#Author'),\n",
       " ('confOf#Conference', 'sigkdd#Conference'),\n",
       " ('confOf#Chair_PC', 'sigkdd#Program_Chair'),\n",
       " ('confOf#Paper', 'sigkdd#Paper'),\n",
       " ('iasted#Place', 'sigkdd#Place'),\n",
       " ('iasted#Review', 'sigkdd#Review'),\n",
       " ('iasted#Student_registration_fee', 'sigkdd#Registration_Student'),\n",
       " ('iasted#Fee', 'sigkdd#Fee'),\n",
       " ('iasted#Registration_fee', 'sigkdd#Registration_fee'),\n",
       " ('iasted#Sponsor', 'sigkdd#Sponzor'),\n",
       " ('iasted#Deadline_for_notification_of_acceptance',\n",
       "  'sigkdd#Deadline_Author_notification'),\n",
       " ('iasted#Nonmember_registration_fee', 'sigkdd#Registration_Non-Member'),\n",
       " ('iasted#Author', 'sigkdd#Author'),\n",
       " ('iasted#Listener', 'sigkdd#Listener'),\n",
       " ('iasted#Main_office', 'sigkdd#Main_office'),\n",
       " ('iasted#Conference_hall', 'sigkdd#Conference_hall'),\n",
       " ('iasted#Person', 'sigkdd#Person'),\n",
       " ('iasted#Deadline', 'sigkdd#Deadline'),\n",
       " ('iasted#Speaker', 'sigkdd#Speaker'),\n",
       " ('confOf#Event', 'iasted#Activity'),\n",
       " ('confOf#Author', 'iasted#Author'),\n",
       " ('confOf#Person', 'iasted#Person'),\n",
       " ('confOf#Banquet', 'iasted#Dinner_banquet'),\n",
       " ('confOf#Administrative_event', 'iasted#Activity_before_conference'),\n",
       " ('confOf#Reception', 'iasted#Coctail_reception'),\n",
       " ('confOf#City', 'iasted#City'),\n",
       " ('confOf#Tutorial', 'iasted#Tutorial'),\n",
       " ('confOf#Country', 'iasted#State'),\n",
       " ('conference#Passive_conference_participant', 'iasted#Listener'),\n",
       " ('conference#Active_conference_participant', 'iasted#Speaker'),\n",
       " ('conference#Reviewer', 'iasted#Reviewer'),\n",
       " ('conference#Person', 'iasted#Person'),\n",
       " ('conference#Regular_author', 'iasted#Author'),\n",
       " ('conference#Conference_fees', 'iasted#Fee'),\n",
       " ('conference#Tutorial', 'iasted#Tutorial'),\n",
       " ('conference#contributes', 'iasted#write'),\n",
       " ('conference#Review', 'iasted#Review'),\n",
       " ('conference#Conference_document', 'iasted#Document'),\n",
       " ('conference#Conference_part', 'iasted#Conference_activity'),\n",
       " ('conference#Submitted_contribution', 'iasted#Submission'),\n",
       " ('conference#Camera_ready_contribution', 'iasted#Final_manuscript'),\n",
       " ('conference#Conference_proceedings', 'iasted#Publication'),\n",
       " ('confOf#Trip', 'edas#Excursion'),\n",
       " ('confOf#Social_event', 'edas#SocialEvent'),\n",
       " ('confOf#reviewes', 'edas#isReviewing'),\n",
       " ('confOf#Organization', 'edas#Organization'),\n",
       " ('confOf#writtenBy', 'edas#isWrittenBy'),\n",
       " ('confOf#Working_event', 'edas#AcademicEvent'),\n",
       " ('confOf#Reception', 'edas#Reception'),\n",
       " ('confOf#hasSurname', 'edas#hasLastName'),\n",
       " ('confOf#Workshop', 'edas#Workshop'),\n",
       " ('confOf#Author', 'edas#Author'),\n",
       " ('confOf#hasFirstName', 'edas#hasFirstName'),\n",
       " ('confOf#Event', 'edas#ConferenceEvent'),\n",
       " ('confOf#Topic', 'edas#Topic'),\n",
       " ('confOf#Country', 'edas#Country'),\n",
       " ('confOf#Participant', 'edas#Attendee'),\n",
       " ('confOf#Person', 'edas#Person'),\n",
       " ('confOf#Member_PC', 'edas#TPCMember'),\n",
       " ('confOf#Paper', 'edas#Paper'),\n",
       " ('confOf#writes', 'edas#hasRelatedPaper'),\n",
       " ('edas#Place', 'iasted#Place'),\n",
       " ('edas#SessionChair', 'iasted#Session_chair'),\n",
       " ('edas#Author', 'iasted#Author'),\n",
       " ('edas#Document', 'iasted#Document'),\n",
       " ('edas#Country', 'iasted#State'),\n",
       " ('edas#WelcomeTalk', 'iasted#Welcome_address'),\n",
       " ('edas#Sponsorship', 'iasted#Sponzorship'),\n",
       " ('edas#Reviewer', 'iasted#Reviewer'),\n",
       " ('edas#Attendee', 'iasted#Delegate'),\n",
       " ('edas#ConferenceDinner', 'iasted#Dinner_banquet'),\n",
       " ('edas#SocialEvent', 'iasted#Social_program'),\n",
       " ('edas#CoffeeBreak', 'iasted#Coffee_break'),\n",
       " ('edas#Review', 'iasted#Review'),\n",
       " ('edas#Reception', 'iasted#Coctail_reception'),\n",
       " ('edas#ConferenceEvent', 'iasted#Conference_activity'),\n",
       " ('edas#SlideSet', 'iasted#Transparency'),\n",
       " ('edas#Paper', 'iasted#Submission'),\n",
       " ('edas#ConferenceVenuePlace', 'iasted#Conference_building'),\n",
       " ('edas#DiningPlace', 'iasted#Conference_restaurant'),\n",
       " ('conference#Person', 'edas#Person'),\n",
       " ('conference#Conference_participant', 'edas#Attendee'),\n",
       " ('conference#Organization', 'edas#Organization'),\n",
       " ('conference#Reviewer', 'edas#Reviewer'),\n",
       " ('conference#has_the_first_name', 'edas#hasFirstName'),\n",
       " ('conference#Conference_part', 'edas#ConferenceEvent'),\n",
       " ('conference#Workshop', 'edas#Workshop'),\n",
       " ('conference#Conference_document', 'edas#Document'),\n",
       " ('conference#Paper', 'edas#Paper'),\n",
       " ('conference#has_a_review_expertise', 'edas#hasRating'),\n",
       " ('conference#has_the_last_name', 'edas#hasLastName'),\n",
       " ('conference#Review', 'edas#Review'),\n",
       " ('conference#Conference_volume', 'edas#Conference'),\n",
       " ('conference#Rejected_contribution', 'edas#RejectedPaper'),\n",
       " ('conference#Topic', 'edas#Topic'),\n",
       " ('conference#Accepted_contribution', 'edas#AcceptedPaper'),\n",
       " ('conference#Regular_author', 'edas#Author'),\n",
       " ('cmt#Document', 'ekaw#Document'),\n",
       " ('cmt#ConferenceMember', 'ekaw#Conference_Participant'),\n",
       " ('cmt#Author', 'ekaw#Paper_Author'),\n",
       " ('cmt#writtenBy', 'ekaw#reviewWrittenBy'),\n",
       " ('cmt#hasBeenAssigned', 'ekaw#reviewerOfPaper'),\n",
       " ('cmt#Person', 'ekaw#Person'),\n",
       " ('cmt#Conference', 'ekaw#Conference'),\n",
       " ('cmt#assignedTo', 'ekaw#hasReviewer'),\n",
       " ('cmt#Review', 'ekaw#Review'),\n",
       " ('cmt#Paper', 'ekaw#Paper'),\n",
       " ('cmt#PaperFullVersion', 'ekaw#Regular_Paper'),\n",
       " ('cmt#ProgramCommitteeChair', 'confOf#Chair_PC'),\n",
       " ('cmt#writePaper', 'confOf#writes'),\n",
       " ('cmt#Author', 'confOf#Author'),\n",
       " ('cmt#ConferenceMember', 'confOf#Member'),\n",
       " ('cmt#Administrator', 'confOf#Administrator'),\n",
       " ('cmt#title', 'confOf#hasTitle'),\n",
       " ('cmt#SubjectArea', 'confOf#Topic'),\n",
       " ('cmt#PaperFullVersion', 'confOf#Paper'),\n",
       " ('cmt#hasBeenAssigned', 'confOf#reviewes'),\n",
       " ('cmt#hasAuthor', 'confOf#writtenBy'),\n",
       " ('cmt#Conference', 'confOf#Conference'),\n",
       " ('cmt#ProgramCommitteeMember', 'confOf#Member_PC'),\n",
       " ('cmt#hasSubjectArea', 'confOf#dealsWith'),\n",
       " ('cmt#Person', 'confOf#Person'),\n",
       " ('cmt#Paper', 'confOf#Contribution'),\n",
       " ('cmt#email', 'confOf#hasEmail'),\n",
       " ('cmt#Person', 'edas#Person'),\n",
       " ('cmt#Conference', 'edas#Conference'),\n",
       " ('cmt#Author', 'edas#Author'),\n",
       " ('cmt#Reviewer', 'edas#Reviewer'),\n",
       " ('cmt#hasConferenceMember', 'edas#hasMember'),\n",
       " ('cmt#memberOfConference', 'edas#isMemberOf'),\n",
       " ('cmt#ConferenceChair', 'edas#ConferenceChair'),\n",
       " ('cmt#Review', 'edas#Review'),\n",
       " ('cmt#Document', 'edas#Document'),\n",
       " ('cmt#Paper', 'edas#Paper'),\n",
       " ('cmt#hasAuthor', 'edas#isWrittenBy'),\n",
       " ('cmt#hasBeenAssigned', 'edas#isReviewing'),\n",
       " ('cmt#assignedTo', 'edas#isReviewedBy'),\n",
       " ('conference#Abstract', 'sigkdd#Abstract'),\n",
       " ('conference#Invited_speaker', 'sigkdd#Invited_Speaker'),\n",
       " ('conference#Regular_author', 'sigkdd#Author'),\n",
       " ('conference#Review', 'sigkdd#Review'),\n",
       " ('conference#Program_committee', 'sigkdd#Program_Committee'),\n",
       " ('conference#Conference_volume', 'sigkdd#Conference'),\n",
       " ('conference#Conference_fees', 'sigkdd#Fee'),\n",
       " ('conference#has_an_email', 'sigkdd#E-mail'),\n",
       " ('conference#Paper', 'sigkdd#Paper'),\n",
       " ('conference#Organizing_committee', 'sigkdd#Organizing_Committee'),\n",
       " ('conference#Person', 'sigkdd#Person'),\n",
       " ('conference#Committee', 'sigkdd#Committee'),\n",
       " ('conference#is_given_by', 'sigkdd#presentationed_by'),\n",
       " ('conference#gives_presentations', 'sigkdd#presentation'),\n",
       " ('conference#Conference_document', 'sigkdd#Document'),\n",
       " ('cmt#Conference', 'sigkdd#Conference'),\n",
       " ('cmt#Paper', 'sigkdd#Paper'),\n",
       " ('cmt#ProgramCommitteeMember', 'sigkdd#Program_Committee_member'),\n",
       " ('cmt#Document', 'sigkdd#Document'),\n",
       " ('cmt#ConferenceChair', 'sigkdd#General_Chair'),\n",
       " ('cmt#email', 'sigkdd#E-mail'),\n",
       " ('cmt#Review', 'sigkdd#Review'),\n",
       " ('cmt#ProgramCommittee', 'sigkdd#Program_Committee'),\n",
       " ('cmt#ProgramCommitteeChair', 'sigkdd#Program_Chair'),\n",
       " ('cmt#Author', 'sigkdd#Author'),\n",
       " ('cmt#submitPaper', 'sigkdd#submit'),\n",
       " ('cmt#Person', 'sigkdd#Person'),\n",
       " ('conference#Conference_participant', 'confOf#Participant'),\n",
       " ('conference#has_an_email', 'confOf#hasEmail'),\n",
       " ('conference#Poster', 'confOf#Poster'),\n",
       " ('conference#Organization', 'confOf#Organization'),\n",
       " ('conference#Topic', 'confOf#Topic'),\n",
       " ('conference#Workshop', 'confOf#Workshop'),\n",
       " ('conference#Paper', 'confOf#Paper'),\n",
       " ('conference#Person', 'confOf#Person'),\n",
       " ('conference#Conference_contribution', 'confOf#Contribution'),\n",
       " ('conference#Tutorial', 'confOf#Tutorial'),\n",
       " ('conference#Conference_volume', 'confOf#Conference'),\n",
       " ('conference#has_a_track-workshop-tutorial_topic', 'confOf#hasTopic'),\n",
       " ('conference#Regular_author', 'confOf#Author'),\n",
       " ('conference#has_the_last_name', 'confOf#hasSurname'),\n",
       " ('conference#has_the_first_name', 'confOf#hasFirstName'),\n",
       " ('edas#ConferenceDinner', 'ekaw#Conference_Banquet'),\n",
       " ('edas#AcademicEvent', 'ekaw#Scientific_Event'),\n",
       " ('edas#AcceptedPaper', 'ekaw#Accepted_Paper'),\n",
       " ('edas#isReviewedBy', 'ekaw#hasReviewer'),\n",
       " ('edas#Place', 'ekaw#Location'),\n",
       " ('edas#AcademiaOrganization', 'ekaw#Academic_Institution'),\n",
       " ('edas#SocialEvent', 'ekaw#Social_Event'),\n",
       " ('edas#isReviewing', 'ekaw#reviewerOfPaper'),\n",
       " ('edas#Organization', 'ekaw#Organisation'),\n",
       " ('edas#Author', 'ekaw#Paper_Author'),\n",
       " ('edas#isLocationOf', 'ekaw#locationOf'),\n",
       " ('edas#Topic', 'ekaw#Research_Topic'),\n",
       " ('edas#Document', 'ekaw#Document'),\n",
       " ('edas#RejectedPaper', 'ekaw#Rejected_Paper'),\n",
       " ('edas#ConferenceEvent', 'ekaw#Event'),\n",
       " ('edas#SessionChair', 'ekaw#Session_Chair'),\n",
       " ('edas#Person', 'ekaw#Person'),\n",
       " ('edas#Programme', 'ekaw#Programme_Brochure'),\n",
       " ('edas#Review', 'ekaw#Review'),\n",
       " ('edas#Workshop', 'ekaw#Workshop'),\n",
       " ('edas#Paper', 'ekaw#Paper'),\n",
       " ('edas#Attendee', 'ekaw#Conference_Participant'),\n",
       " ('edas#hasLocation', 'ekaw#heldIn'),\n",
       " ('cmt#Conference', 'conference#Conference_volume'),\n",
       " ('cmt#Preference', 'conference#Review_preference'),\n",
       " ('cmt#Author', 'conference#Regular_author'),\n",
       " ('cmt#Person', 'conference#Person'),\n",
       " ('cmt#email', 'conference#has_an_email'),\n",
       " ('cmt#Co-author', 'conference#Contribution_co-author'),\n",
       " ('cmt#PaperAbstract', 'conference#Abstract'),\n",
       " ('cmt#Document', 'conference#Conference_document'),\n",
       " ('cmt#Review', 'conference#Review'),\n",
       " ('cmt#Conference', 'conference#Conference'),\n",
       " ('cmt#ProgramCommittee', 'conference#Program_committee'),\n",
       " ('cmt#Chairman', 'conference#Chair'),\n",
       " ('cmt#SubjectArea', 'conference#Topic'),\n",
       " ('cmt#assignedByReviewer', 'conference#invited_by'),\n",
       " ('cmt#assignExternalReviewer', 'conference#invites_co-reviewers'),\n",
       " ('cmt#Author', 'iasted#Author'),\n",
       " ('cmt#Review', 'iasted#Review'),\n",
       " ('cmt#Person', 'iasted#Person'),\n",
       " ('cmt#Reviewer', 'iasted#Reviewer'),\n",
       " ('ekaw#Location', 'iasted#Place'),\n",
       " ('ekaw#Document', 'iasted#Document'),\n",
       " ('ekaw#Event', 'iasted#Activity'),\n",
       " ('ekaw#Person', 'iasted#Person'),\n",
       " ('ekaw#Paper_Author', 'iasted#Author'),\n",
       " ('ekaw#Session', 'iasted#Session'),\n",
       " ('ekaw#Review', 'iasted#Review'),\n",
       " ('ekaw#Conference_Banquet', 'iasted#Dinner_banquet'),\n",
       " ('ekaw#Tutorial', 'iasted#Tutorial'),\n",
       " ('ekaw#Session_Chair', 'iasted#Session_chair')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el for el in gt_mappings if el[0].split(\"#\")[1].lower() == el[0].split(\"#\")[1].lower()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[['confOf#Participant', 'confOf#Person'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']],\n",
       " \n",
       "        [['confOf#Student', '<UNK>'],\n",
       "         ['confOf#Regular', '<UNK>'],\n",
       "         ['confOf#Member', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']],\n",
       " \n",
       "        [['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']],\n",
       " \n",
       "        [['confOf#boolean', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']]], dtype='<U18'),\n",
       " array([[['ekaw#Conference_Participant', 'ekaw#Person'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']],\n",
       " \n",
       "        [['ekaw#Demo_Chair', '<UNK>'],\n",
       "         ['ekaw#Tutorial_Chair', '<UNK>'],\n",
       "         ['ekaw#Early-Registered_Participant', '<UNK>'],\n",
       "         ['ekaw#Workshop_Chair', '<UNK>'],\n",
       "         ['ekaw#Presenter', '<UNK>'],\n",
       "         ['ekaw#PC_Chair', '<UNK>']],\n",
       " \n",
       "        [['ekaw#Camera_Ready_Paper', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']],\n",
       " \n",
       "        [['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>'],\n",
       "         ['<UNK>', '<UNK>']]], dtype='<U33'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dict['confOf#Participant'], features_dict['ekaw#Conference_Participant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
