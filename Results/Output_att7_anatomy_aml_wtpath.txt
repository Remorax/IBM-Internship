Max number of nodes in a path: Input/data_anatomy_oaei.pkl
Number of entities: 150000
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.22933612944771573
Epoch: 0 Idx: 5000 Loss: 0.020985240990075267
Epoch: 1 Idx: 0 Loss: 0.02257220622384385
Epoch: 1 Idx: 5000 Loss: 0.03517871865352775
Epoch: 2 Idx: 0 Loss: 0.019296147429162497
Epoch: 2 Idx: 5000 Loss: 0.018266215392089034
Epoch: 3 Idx: 0 Loss: 0.02409804186933348
Epoch: 3 Idx: 5000 Loss: 0.024436692283079132
Epoch: 4 Idx: 0 Loss: 0.02484075827888375
Epoch: 4 Idx: 5000 Loss: 0.015861422609450518
Epoch: 5 Idx: 0 Loss: 0.019671509644475484
Epoch: 5 Idx: 5000 Loss: 0.016828872745143376
Epoch: 6 Idx: 0 Loss: 0.0154924428728263
Epoch: 6 Idx: 5000 Loss: 0.026542995441698903
Epoch: 7 Idx: 0 Loss: 0.012007569494789845
Epoch: 7 Idx: 5000 Loss: 0.021838688146919298
Epoch: 8 Idx: 0 Loss: 0.018655011889452594
Epoch: 8 Idx: 5000 Loss: 0.03199523159653351
Epoch: 9 Idx: 0 Loss: 0.015127419089905579
Epoch: 9 Idx: 5000 Loss: 0.0375279151337405
Epoch: 10 Idx: 0 Loss: 0.018419189611508072
Epoch: 10 Idx: 5000 Loss: 0.024536894296763985
Epoch: 11 Idx: 0 Loss: 0.041712969706036246
Epoch: 11 Idx: 5000 Loss: 0.02604407449318165
Epoch: 12 Idx: 0 Loss: 0.013793777769627282
Epoch: 12 Idx: 5000 Loss: 0.025991611720770018
Epoch: 13 Idx: 0 Loss: 0.023988180479568803
Epoch: 13 Idx: 5000 Loss: 0.03314319842439757
Epoch: 14 Idx: 0 Loss: 0.010992577662305951
Epoch: 14 Idx: 5000 Loss: 0.032168790216287706
Epoch: 15 Idx: 0 Loss: 0.03568403338196286
Epoch: 15 Idx: 5000 Loss: 0.018602397582688904
Epoch: 16 Idx: 0 Loss: 0.01082643365030847
Epoch: 16 Idx: 5000 Loss: 0.015476602213796146
Epoch: 17 Idx: 0 Loss: 0.01507027595260777
Epoch: 17 Idx: 5000 Loss: 0.025688188174058317
Epoch: 18 Idx: 0 Loss: 0.014999701023981349
Epoch: 18 Idx: 5000 Loss: 0.025921909067745125
Epoch: 19 Idx: 0 Loss: 0.007183581890073345
Epoch: 19 Idx: 5000 Loss: 0.023021713199382017
Epoch: 20 Idx: 0 Loss: 0.014774887796274457
Epoch: 20 Idx: 5000 Loss: 0.018507705530332555
Epoch: 21 Idx: 0 Loss: 0.016551489971815606
Epoch: 21 Idx: 5000 Loss: 0.015763426307340078
Epoch: 22 Idx: 0 Loss: 0.01810130675940432
Epoch: 22 Idx: 5000 Loss: 0.014997660850185408
Epoch: 23 Idx: 0 Loss: 0.01332486987220241
Epoch: 23 Idx: 5000 Loss: 0.029161992694282584
Epoch: 24 Idx: 0 Loss: 0.015468626496133848
Epoch: 24 Idx: 5000 Loss: 0.017691665829213922
Epoch: 25 Idx: 0 Loss: 0.02224944535833796
Epoch: 25 Idx: 5000 Loss: 0.02708652252707405
Epoch: 26 Idx: 0 Loss: 0.022770459445209168
Epoch: 26 Idx: 5000 Loss: 0.048626620906364645
Epoch: 27 Idx: 0 Loss: 0.023573662461884443
Epoch: 27 Idx: 5000 Loss: 0.024189594988154144
Epoch: 28 Idx: 0 Loss: 0.02151286354064414
Epoch: 28 Idx: 5000 Loss: 0.021910846012517127
Epoch: 29 Idx: 0 Loss: 0.022971406534779838
Epoch: 29 Idx: 5000 Loss: 0.016211157082047116
Epoch: 30 Idx: 0 Loss: 0.013112275449335437
Epoch: 30 Idx: 5000 Loss: 0.01479528680582114
Epoch: 31 Idx: 0 Loss: 0.016555884156629265
Epoch: 31 Idx: 5000 Loss: 0.022975610798428685
Epoch: 32 Idx: 0 Loss: 0.014962604651518548
Epoch: 32 Idx: 5000 Loss: 0.018250847561385425
Epoch: 33 Idx: 0 Loss: 0.010891924304924262
Epoch: 33 Idx: 5000 Loss: 0.018971262684259416
Epoch: 34 Idx: 0 Loss: 0.04617391129984964
Epoch: 34 Idx: 5000 Loss: 0.017980942598544145
Epoch: 35 Idx: 0 Loss: 0.019855916094601703
Epoch: 35 Idx: 5000 Loss: 0.027455715335713487
Epoch: 36 Idx: 0 Loss: 0.011737946334559069
Epoch: 36 Idx: 5000 Loss: 0.013097810533655161
Epoch: 37 Idx: 0 Loss: 0.019528109657524148
Epoch: 37 Idx: 5000 Loss: 0.014438412613859315
Epoch: 38 Idx: 0 Loss: 0.023168230425428475
Epoch: 38 Idx: 5000 Loss: 0.021772426926104222
Epoch: 39 Idx: 0 Loss: 0.012533418355345799
Epoch: 39 Idx: 5000 Loss: 0.011842070644769682
Epoch: 40 Idx: 0 Loss: 0.025636237980991815
Epoch: 40 Idx: 5000 Loss: 0.040210012535848015
Epoch: 41 Idx: 0 Loss: 0.015513458981543573
Epoch: 41 Idx: 5000 Loss: 0.02052515581435574
Epoch: 42 Idx: 0 Loss: 0.029251211845683623
Epoch: 42 Idx: 5000 Loss: 0.018715923475395708
Epoch: 43 Idx: 0 Loss: 0.02189931349422465
Epoch: 43 Idx: 5000 Loss: 0.05877598145838393
Epoch: 44 Idx: 0 Loss: 0.02230918836976313
Epoch: 44 Idx: 5000 Loss: 0.025690010261490835
Epoch: 45 Idx: 0 Loss: 0.01392602377411332
Epoch: 45 Idx: 5000 Loss: 0.015711108194241794
Epoch: 46 Idx: 0 Loss: 0.016507684067131958
Epoch: 46 Idx: 5000 Loss: 0.020408482767499375
Epoch: 47 Idx: 0 Loss: 0.02665843738267102
Epoch: 47 Idx: 5000 Loss: 0.04189643362377146
Epoch: 48 Idx: 0 Loss: 0.028826574417369258
Epoch: 48 Idx: 5000 Loss: 0.03635633507762087
Epoch: 49 Idx: 0 Loss: 0.028898399872890956
Epoch: 49 Idx: 5000 Loss: 0.03716165880038651
Len (direct inputs):  104
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division bTraining size: TrainiTraining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.2269715038487298
Epoch: 0 Idx: 5000 Loss: 0.017956827113608062
Epoch: 1 Idx: 0 Loss: 0.017645177958148937
Epoch: 1 Idx: 5000 Loss: 0.0288762032608323
Epoch: 2 Idx: 0 Loss: 0.029681324570184978
Epoch: 2 Idx: 5000 Loss: 0.013969961456737451
Epoch: 3 Idx: 0 Loss: 0.02656936190993077
Epoch: 3 Idx: 5000 Loss: 0.020031132005828442
Epoch: 4 Idx: 0 Loss: 0.031130434199922192
Epoch: 4 Idx: 5000 Loss: 0.01450599700189548
Epoch: 5 Idx: 0 Loss: 0.023676885430768353
Epoch: 5 Idx: 5000 Loss: 0.030524613499486732
Epoch: 6 Idx: 0 Loss: 0.0314479705471162
Epoch: 6 Idx: 5000 Loss: 0.021509412890809914
Epoch: 7 Idx: 0 Loss: 0.02029720495869311
Epoch: 7 Idx: 5000 Loss: 0.019636333542208555
Epoch: 8 Idx: 0 Loss: 0.018036957423252634
Epoch: 8 Idx: 5000 Loss: 0.016245155280730558
Epoch: 9 Idx: 0 Loss: 0.018439957926746846
Epoch: 9 Idx: 5000 Loss: 0.016662722439745207
Epoch: 10 Idx: 0 Loss: 0.016133891940731712
Epoch: 10 Idx: 5000 Loss: 0.015415953320222218
Epoch: 11 Idx: 0 Loss: 0.011248636157713444
Epoch: 11 Idx: 5000 Loss: 0.020859023288109395
Epoch: 12 Idx: 0 Loss: 0.015099874747822262
Epoch: 12 Idx: 5000 Loss: 0.014171373775892688
Epoch: 13 Idx: 0 Loss: 0.01861243399176297
Epoch: 13 Idx: 5000 Loss: 0.027199353868610696
Epoch: 14 Idx: 0 Loss: 0.0404573765815252
Epoch: 14 Idx: 5000 Loss: 0.031725076256376064
Epoch: 15 Idx: 0 Loss: 0.03234739745074347
Epoch: 15 Idx: 5000 Loss: 0.015135607577927663
Epoch: 16 Idx: 0 Loss: 0.03690114649501072
Epoch: 16 Idx: 5000 Loss: 0.014443967443131676
Epoch: 17 Idx: 0 Loss: 0.02329509003921212
Epoch: 17 Idx: 5000 Loss: 0.02226464743730629
Epoch: 18 Idx: 0 Loss: 0.017107210459559877
Epoch: 18 Idx: 5000 Loss: 0.025916460880024916
Epoch: 19 Idx: 0 Loss: 0.009249641229555771
Epoch: 19 Idx: 5000 Loss: 0.019835758908816156
Epoch: 20 Idx: 0 Loss: 0.04050487037044895
Epoch: 20 Idx: 5000 Loss: 0.014441158647299656
Epoch: 21 Idx: 0 Loss: 0.036644184355760695
Epoch: 21 Idx: 5000 Loss: 0.04771415809642106
Epoch: 22 Idx: 0 Loss: 0.016036161937467933
Epoch: 22 Idx: 5000 Loss: 0.008412879844998385
Epoch: 23 Idx: 0 Loss: 0.024988829602645396
Epoch: 23 Idx: 5000 Loss: 0.02331698439977852
Epoch: 24 Idx: 0 Loss: 0.023100060641902277
Epoch: 24 Idx: 5000 Loss: 0.03272927928883358
Epoch: 25 Idx: 0 Loss: 0.02303565832415563
Epoch: 25 Idx: 5000 Loss: 0.021508249101220595
Epoch: 26 Idx: 0 Loss: 0.03222899635256948
Epoch: 26 Idx: 5000 Loss: 0.02313583438525571
Epoch: 27 Idx: 0 Loss: 0.024479719015164082
Epoch: 27 Idx: 5000 Loss: 0.017874295461798584
Epoch: 28 Idx: 0 Loss: 0.021905986671847094
Epoch: 28 Idx: 5000 Loss: 0.015220598702538737
Epoch: 29 Idx: 0 Loss: 0.015803055116209004
Epoch: 29 Idx: 5000 Loss: 0.013920981715834906
Epoch: 30 Idx: 0 Loss: 0.01771046227598985
Epoch: 30 Idx: 5000 Loss: 0.0160516488606795
Epoch: 31 Idx: 0 Loss: 0.0301811445678481
Epoch: 31 Idx: 5000 Loss: 0.017279087010513727
Epoch: 32 Idx: 0 Loss: 0.028190550995332905
Epoch: 32 Idx: 5000 Loss: 0.01360196917538404
Epoch: 33 Idx: 0 Loss: 0.013359901174247658
Epoch: 33 Idx: 5000 Loss: 0.012326081513953336
Epoch: 34 Idx: 0 Loss: 0.02020147345455692
Epoch: 34 Idx: 5000 Loss: 0.030588192348719363
Epoch: 35 Idx: 0 Loss: 0.02050915679145146
Epoch: 35 Idx: 5000 Loss: 0.02275462479021047
Epoch: 36 Idx: 0 Loss: 0.015011037406715017
Epoch: 36 Idx: 5000 Loss: 0.016011788123096334
Epoch: 37 Idx: 0 Loss: 0.03119463624286639
Epoch: 37 Idx: 5000 Loss: 0.020878998721768738
Epoch: 38 Idx: 0 Loss: 0.022554081218287638
Epoch: 38 Idx: 5000 Loss: 0.02065721498355503
Epoch: 39 Idx: 0 Loss: 0.03474061933922008
Epoch: 39 Idx: 5000 Loss: 0.0292849342647506
Epoch: 40 Idx: 0 Loss: 0.01801597582171584
Epoch: 40 Idx: 5000 Loss: 0.024131233124675938
Epoch: 41 Idx: 0 Loss: 0.024653134742847804
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 388, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "Attention_anatomy_aml_weighted.py", line 315, in to_feature
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml_weighted.py", line 315, in <listcomp>
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml_weighted.py", line 314, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml_weighted.py", line 314, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml_weighted.py", line 313, in <listcomp>
    for i in range(max_paths - len(nbr_type))]
  File "Attention_anatomy_aml_weighted.py", line 312, in <listcomp>
    inputs_pathpadded = [[[nbr_type + [[0 for j in range(max_pathlen)]
KeyboardInterrupt
n by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
divisioTerminated
raining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.21824011359274897
Epoch: 0 Idx: 5000 Loss: 0.024370562983916984
Epoch: 1 Idx: 0 Loss: 0.02170519142326121
Epoch: 1 Idx: 5000 Loss: 0.016816501913266044
Epoch: 2 Idx: 0 Loss: 0.013504395928888649
Epoch: 2 Idx: 5000 Loss: 0.020522737907548994
Epoch: 3 Idx: 0 Loss: 0.01582182351711224
Epoch: 3 Idx: 5000 Loss: 0.015293296422224904
Epoch: 4 Idx: 0 Loss: 0.035236946598515353
Epoch: 4 Idx: 5000 Loss: 0.035338998230861424
Epoch: 5 Idx: 0 Loss: 0.02397226539568292
Epoch: 5 Idx: 5000 Loss: 0.01831327408686082
Epoch: 6 Idx: 0 Loss: 0.03839172245824104
Epoch: 6 Idx: 5000 Loss: 0.027836434592331316
Epoch: 7 Idx: 0 Loss: 0.03349261356384479
Epoch: 7 Idx: 5000 Loss: 0.014693135470815572
Epoch: 8 Idx: 0 Loss: 0.02184217052370825
Epoch: 8 Idx: 5000 Loss: 0.026474288707091426
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 388, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "Attention_anatomy_aml_weighted.py", line 315, in to_feature
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml_weighted.py", line 315, in <listcomp>
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml_weighted.py", line 314, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml_weighted.py", line 314, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml_weighted.py", line 313, in <listcomp>
    for i in range(max_paths - len(nbr_type))]
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc264>
Subject: Job 3290202: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:09 2020
Job was executed on host(s) <dccxc264>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:34:12 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:34:12 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   13442.04 sec.
    Max Memory :                                 2645 MB
    Average Memory :                             2544.84 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40772.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   13496 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc237>
Subject: Job 3290196: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:09 2020
Job was executed on host(s) <dccxc237>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:29:34 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:29:34 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   13726.00 sec.
    Max Memory :                                 2639 MB
    Average Memory :                             2553.64 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40778.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   13754 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc273>
Subject: Job 3290210: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:10 2020
Job was executed on host(s) <dccxc273>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 09:04:24 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 09:04:24 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11660.74 sec.
    Max Memory :                                 2633 MB
    Average Memory :                             2535.57 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40784.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   11664 sec.
    Turnaround time :                            80678 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc276>
Subject: Job 3290194: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:09 2020
Job was executed on host(s) <dccxc276>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:22:48 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:22:48 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   14155.82 sec.
    Max Memory :                                 2640 MB
    Average Memory :                             2561.46 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40777.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   14160 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc231>
Subject: Job 3290200: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:09 2020
Job was executed on host(s) <dccxc231>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:32:08 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:32:08 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   13597.61 sec.
    Max Memory :                                 2641 MB
    Average Memory :                             2559.17 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40776.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   13627 sec.
    Turnaround time :                            80680 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 3290208: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:10 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 09:02:46 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 09:02:46 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11737.35 sec.
    Max Memory :                                 2637 MB
    Average Memory :                             2546.07 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40780.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   11763 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc259>
Subject: Job 3290212: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:10 2020
Job was executed on host(s) <dccxc259>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 09:05:10 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 09:05:10 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11612.09 sec.
    Max Memory :                                 2639 MB
    Average Memory :                             2535.64 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40778.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   11621 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc259>
Subject: Job 3290206: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:10 2020
Job was executed on host(s) <dccxc259>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:48:51 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:48:51 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   12593.69 sec.
    Max Memory :                                 2640 MB
    Average Memory :                             2546.09 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40777.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   12598 sec.
    Turnaround time :                            80679 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc212>
Subject: Job 3290198: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:09 2020
Job was executed on host(s) <dccxc212>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 08:30:19 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 08:30:19 2020
Terminated at Wed Sep  2 12:18:54 2020
Results reported at Wed Sep  2 12:18:54 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei.pkl 15 7 Output/test_anatomy_aml_wtpath15_7.pkl Models/anatomy_aml_wtpath15_7.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   13709.63 sec.
    Max Memory :                                 2650 MB
    Average Memory :                             2562.75 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40767.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   13715 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.

