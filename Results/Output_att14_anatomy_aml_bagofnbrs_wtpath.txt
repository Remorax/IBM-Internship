Max number of nodes in a path: Input/data_anatomy_oaei_bagofnbrs.pkl
Number of entities: 150000
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.14439931618052176
Epoch: 0 Idx: 5000 Loss: 0.02295868003953445
Epoch: 1 Idx: 0 Loss: 0.03425617521463023
Epoch: 1 Idx: 5000 Loss: 0.03633309865953159
Epoch: 2 Idx: 0 Loss: 0.023390079580306637
Epoch: 2 Idx: 5000 Loss: 0.03813273505931607
Epoch: 3 Idx: 0 Loss: 0.02782382470509983
Epoch: 3 Idx: 5000 Loss: 0.01044883459113528
Epoch: 4 Idx: 0 Loss: 0.01337724607051928
Epoch: 4 Idx: 5000 Loss: 0.018122140320416206
Epoch: 5 Idx: 0 Loss: 0.015510064469176084
Epoch: 5 Idx: 5000 Loss: 0.0320118411551831
Epoch: 6 Idx: 0 Loss: 0.027465609685545688
Epoch: 6 Idx: 5000 Loss: 0.016345384923013836
Epoch: 7 Idx: 0 Loss: 0.012469756069014631
Epoch: 7 Idx: 5000 Loss: 0.036297500540680296
Epoch: 8 Idx: 0 Loss: 0.024884215247984908
Epoch: 8 Idx: 5000 Loss: 0.017443866224185024
Epoch: 9 Idx: 0 Loss: 0.016699423030265323
Epoch: 9 Idx: 5000 Loss: 0.018474774432765732
Epoch: 10 Idx: 0 Loss: 0.024805009707599572
Epoch: 10 Idx: 5000 Loss: 0.008426386138390989
Epoch: 11 Idx: 0 Loss: 0.022751000084732322
Epoch: 11 Idx: 5000 Loss: 0.016248076868346797
Epoch: 12 Idx: 0 Loss: 0.023134701710349977
Epoch: 12 Idx: 5000 Loss: 0.02695679227279455
Epoch: 13 Idx: 0 Loss: 0.021061341652581084
Epoch: 13 Idx: 5000 Loss: 0.02496549785861589
Epoch: 14 Idx: 0 Loss: 0.017309370316666697
Epoch: 14 Idx: 5000 Loss: 0.022557059606742102
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 388, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
KeyboardInterrupt
7 Idx: 0 Loss: 0.014956393258493813
Epoch: 17 Idx: 5000 Loss: 0.016909853088173634
Epoch: 18 Idx: 0 Loss: 0.016471726106175852
Epoch: 18 Idx: 5000 Loss: 0.016081645333418115
Epoch: 19 Idx: 0 Loss: 0.026574877669787392
Epoch: 19 Idx: 5000 Loss: 0.028183035991743877
Epoch: 20 Idx: 0 Loss: 0.016936345284837014
Epoch: 20 Idx: 5000 Loss: 0.01995161634060965
Epoch: 21 Idx: 0 Loss: 0.026886696756582597
Epoch: 21 Idx: 5000 Loss: 0.012689955076442602
Epoch: 22 Idx: 0 Loss: 0.03171602980587266
Epoch: 22 Idx: 5000 Loss: 0.0123466678231221
Epoch: 23 Idx: 0 Loss: 0.019385749860573828
Epoch: 23 Idx: 5000 Loss: 0.011599658503588347
Epoch: 24 Idx: 0 Loss: 0.03452867348836212
Epoch: 24 Idx: 5000 Loss: 0.017060386912647864
Epoch: 25 Idx: 0 Loss: 0.02408120154727124
Epoch: 25 Idx: 5000 Loss: 0.03421434316486553
Epoch: 26 Idx: 0 Loss: 0.033256671573989316
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
och: 30 Idx: 5000 Loss: 0.03950164138948544
Epoch: 31 Idx: 0 Loss: 0.019117251892610713
Epoch: 31 Idx: 5000 Loss: 0.03414136604359429
Epoch: 32 Idx: 0 Loss: 0.02041888072548072
Epoch: 32 Idx: 5000 Loss: 0.043111328260292694
Epoch: 33 Idx: 0 Loss: 0.02644330934514032
Epoch: 33 Idx: 5000 Loss: 0.01563029042835609
Epoch: 34 Idx: 0 Loss: 0.017677178525409523
Epoch: 34 Idx: 5000 Loss: 0.017121122810579772
Epoch: 35 Idx: 0 Loss: 0.033969509013511555
Epoch: 35 Idx: 5000 Loss: 0.030073151060468244
Epoch: 36 Idx: 0 Loss: 0.00886039852880268
Epoch: 36 Idx: 5000 Loss: 0.01934727703756115
Epoch: 37 Idx: 0 Loss: 0.020828618693219177
Epoch: 37 Idx: 5000 Loss: 0.006621664761038548
Epoch: 38 Idx: 0 Loss: 0.021455053258765944
Epoch: 38 Idx: 5000 Loss: 0.020590887757244294
Epoch: 39 Idx: 0 Loss: 0.032242421889417686
Epoch: 39 Idx: 5000 Loss: 0.013714534880929666
Epoch: 40 Idx: 0 Loss: 0.015085457363624984
Epoch: 40 Idx: 5000 Loss: 0.016754154347449687
Epoch: 41 Idx: 0 Loss: 0.031181062654959305
Epoch: 41 Idx: 5000 Loss: 0.03355547138911395
Epoch: 42 Idx: 0 Loss: 0.015563198780017051
Epoch: 42 Idx: 5000 Loss: 0.012269656097427566
Epoch: 43 Idx: 0 Loss: 0.02315212654464263
Epoch: 43 Idx: 5000 Loss: 0.019915976226433433
Epoch: 44 Idx: 0 Loss: 0.017182878401029937
Epoch: 44 Idx: 5000 Loss: 0.017606025543184033
Epoch: 45 Idx: 0 Loss: 0.02683465299338486
Epoch: 45 Idx: 5000 Loss: 0.007968177907066928
Epoch: 46 Idx: 0 Loss: 0.014468736515401127
Epoch: 46 Idx: 5000 Loss: 0.02072245912222641
Epoch: 47 Idx: 0 Loss: 0.011153971427479963
Epoch: 47 Idx: 5000 Loss: 0.017828642031052142
Epoch: 48 Idx: 0 Loss: 0.018468524348897307
Epoch: 48 Idx: 5000 Loss: 0.03424078389922773
Epoch: 49 Idx: 0 Loss: 0.021811253112233087
Epoch: 49 Idx: 5000 Loss: 0.016840880588230737
Len (direct inputs):  99
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
divTraTerminated
 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.1738509090506022
Epoch: 0 Idx: 5000 Loss: 0.014056280996512153
Epoch: 1 Idx: 0 Loss: 0.03198510754216991
Epoch: 1 Idx: 5000 Loss: 0.009403872101287134
Epoch: 2 Idx: 0 Loss: 0.030865076833002346
Epoch: 2 Idx: 5000 Loss: 0.025835897083287256
Epoch: 3 Idx: 0 Loss: 0.026558652876944297
Epoch: 3 Idx: 5000 Loss: 0.034658397680426535
Epoch: 4 Idx: 0 Loss: 0.02097072838251163
Epoch: 4 Idx: 5000 Loss: 0.03482019146587467
Epoch: 5 Idx: 0 Loss: 0.01604487195920807
Epoch: 5 Idx: 5000 Loss: 0.018407613896933725
Epoch: 6 Idx: 0 Loss: 0.0305920468771112
Epoch: 6 Idx: 5000 Loss: 0.051203519128408946
Epoch: 7 Idx: 0 Loss: 0.03800624861481369
Epoch: 7 Idx: 5000 Loss: 0.026450386224419968
Epoch: 8 Idx: 0 Loss: 0.029202944014207925
Epoch: 8 Idx: 5000 Loss: 0.006564715943976653
Epoch: 9 Idx: 0 Loss: 0.026758655630549546
Epoch: 9 Idx: 5000 Loss: 0.02438983159362125
Epoch: 10 Idx: 0 Loss: 0.014729450235519723
Epoch: 10 Idx: 5000 Loss: 0.03195039558066408
Epoch: 11 Idx: 0 Loss: 0.03667017655613814
Epoch: 11 Idx: 5000 Loss: 0.026029756810033233
Epoch: 12 Idx: 0 Loss: 0.020589331615229817
Epoch: 12 Idx: 5000 Loss: 0.022193285388964323
Epoch: 13 Idx: 0 Loss: 0.030598927549434364
Epoch: 13 Idx: 5000 Loss: 0.02603180205908985
Epoch: 14 Idx: 0 Loss: 0.005926191178380525
Epoch: 14 Idx: 5000 Loss: 0.022500876598867382
Epoch: 15 Idx: 0 Loss: 0.028638878470678756
Epoch: 15 Idx: 5000 Loss: 0.023591541947580702
Epoch: 16 Idx: 0 Loss: 0.02497244852719421
Epoch: 16 Idx: 5000 Loss: 0.02210083884166613
Epoch: 17 Idx: 0 Loss: 0.017095055063218796
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
h: 21 Idx: 5000 Loss: 0.035248771775067966
Epoch: 22 Idx: 0 Loss: 0.0142910945394533
Epoch: 22 Idx: 5000 Loss: 0.01822282665226823
Epoch: 23 Idx: 0 Loss: 0.026472981628771496
Epoch: 23 Idx: 5000 Loss: 0.02170819110027107
Epoch: 24 Idx: 0 Loss: 0.03299051470136678
Epoch: 24 Idx: 5000 Loss: 0.03843148984662576
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
11965389
Epoch: 29 Idx: 0 Loss: 0.018530953043608623
Epoch: 29 Idx: 5000 Loss: 0.009275755221511332
Epoch: 30 Idx: 0 Loss: 0.041865533516779886
Epoch: 30 Idx: 5000 Loss: 0.014765777606395239
Epoch: 31 Idx: 0 Loss: 0.016106976513513064
Epoch: 31 Idx: 5000 Loss: 0.012048702384444394
Epoch: 32 Idx: 0 Loss: 0.03307732689376216
Epoch: 32 Idx: 5000 Loss: 0.014247000586258524
Epoch: 33 Idx: 0 Loss: 0.006746535854778947
Epoch: 33 Idx: 5000 Loss: 0.012791441060245632
Epoch: 34 Idx: 0 Loss: 0.014538766413282212
Epoch: 34 Idx: 5000 Loss: 0.02022619922270137
Epoch: 35 Idx: 0 Loss: 0.021254818754540793
Epoch: 35 Idx: 5000 Loss: 0.02167949435247049
Epoch: 36 Idx: 0 Loss: 0.015738752606172936
Epoch: 36 Idx: 5000 Loss: 0.020113423097180148
Epoch: 37 Idx: 0 Loss: 0.024339531057468323
Epoch: 37 Idx: 5000 Loss: 0.0149766264745813
Epoch: 38 Idx: 0 Loss: 0.019257767561100824
Epoch: 38 Idx: 5000 Loss: 0.024498443506996273
Epoch: 39 Idx: 0 Loss: 0.017622064718114543
Epoch: 39 Idx: 5000 Loss: 0.021939849659144826
Epoch: 40 Idx: 0 Loss: 0.016472460489681227
Epoch: 40 Idx: 5000 Loss: 0.01758653558303748
Epoch: 41 Idx: 0 Loss: 0.01926209144938392
Epoch: 41 Idx: 5000 Loss: 0.012227352619491738
Epoch: 42 Idx: 0 Loss: 0.007634473711979121
Epoch: 42 Idx: 5000 Loss: 0.014979569567282337
Epoch: 43 Idx: 0 Loss: 0.008907671815392851
Epoch: 43 Idx: 5000 Loss: 0.025593479935076845
Epoch: 44 Idx: 0 Loss: 0.017519878435125924
Epoch: 44 Idx: 5000 Loss: 0.016092428293708633
Epoch: 45 Idx: 0 Loss: 0.019080700274864793
Epoch: 45 Idx: 5000 Loss: 0.035643737546022486
Epoch: 46 Idx: 0 Loss: 0.01878890000685147
Epoch: 46 Idx: 5000 Loss: 0.016734258296464626
Epoch: 47 Idx: 0 Loss: 0.025753381924188506
Epoch: 47 Idx: 5000 Loss: 0.023870697549661722
Epoch: 48 Idx: 0 Loss: 0.014112349097570667
Epoch: 48 Idx: 5000 Loss: 0.031650549086234325
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
sion by zero
division by zero
division by zero
division by zero
division by zero
division bTrainingTraining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.22868935331038792
Epoch: 0 Idx: 5000 Loss: 0.022781513713260905
Epoch: 1 Idx: 0 Loss: 0.029002422233622465
Epoch: 1 Idx: 5000 Loss: 0.0336526096589073
Epoch: 2 Idx: 0 Loss: 0.02381212309958618
Epoch: 2 Idx: 5000 Loss: 0.02785538879973372
Epoch: 3 Idx: 0 Loss: 0.020143371131960037
Epoch: 3 Idx: 5000 Loss: 0.02963567740217118
Epoch: 4 Idx: 0 Loss: 0.017589917260709416
Epoch: 4 Idx: 5000 Loss: 0.017660672880481624
Epoch: 5 Idx: 0 Loss: 0.032954597958096264
Epoch: 5 Idx: 5000 Loss: 0.0274943943769105
Epoch: 6 Idx: 0 Loss: 0.028816270891936994
Epoch: 6 Idx: 5000 Loss: 0.012009007832370558
Epoch: 7 Idx: 0 Loss: 0.022699753288570046
Epoch: 7 Idx: 5000 Loss: 0.01569491323951106
Epoch: 8 Idx: 0 Loss: 0.016037637627270042
Epoch: 8 Idx: 5000 Loss: 0.014576289966647298
Epoch: 9 Idx: 0 Loss: 0.02091457837158884
Epoch: 9 Idx: 5000 Loss: 0.017542159892995422
Epoch: 10 Idx: 0 Loss: 0.017542106736591054
Epoch: 10 Idx: 5000 Loss: 0.018651739077202207
Epoch: 11 Idx: 0 Loss: 0.017602190149207567
Epoch: 11 Idx: 5000 Loss: 0.03456358148698883
Epoch: 12 Idx: 0 Loss: 0.013847838590027075
Epoch: 12 Idx: 5000 Loss: 0.026381975508080566
Epoch: 13 Idx: 0 Loss: 0.01780975680057184
Epoch: 13 Idx: 5000 Loss: 0.016051290098704048
Epoch: 14 Idx: 0 Loss: 0.01156741352703956
Epoch: 14 Idx: 5000 Loss: 0.01733877196517883
Epoch: 15 Idx: 0 Loss: 0.031093591664802207
Epoch: 15 Idx: 5000 Loss: 0.025941857805017766
Epoch: 16 Idx: 0 Loss: 0.01461213125728093
Epoch: 16 Idx: 5000 Loss: 0.02194772090001034
Epoch: 17 Idx: 0 Loss: 0.022620296442451823
Epoch: 17 Idx: 5000 Loss: 0.022446082765115175
Epoch: 18 Idx: 0 Loss: 0.021575282567560396
Epoch: 18 Idx: 5000 Loss: 0.025550504945580976
Epoch: 19 Idx: 0 Loss: 0.012534440921871053
Epoch: 19 Idx: 5000 Loss: 0.015474784826802163
Epoch: 20 Idx: 0 Loss: 0.026752199070183235
Epoch: 20 Idx: 5000 Loss: 0.017640081377257553
Epoch: 21 Idx: 0 Loss: 0.01543460325146156
Epoch: 21 Idx: 5000 Loss: 0.03896660346607132
Epoch: 22 Idx: 0 Loss: 0.02561954674254152
Epoch: 22 Idx: 5000 Loss: 0.015326722753078333
Epoch: 23 Idx: 0 Loss: 0.018085809904303467
Epoch: 23 Idx: 5000 Loss: 0.011337581656201409
Epoch: 24 Idx: 0 Loss: 0.021650888759317557
Epoch: 24 Idx: 5000 Loss: 0.016657945535665797
Epoch: 25 Idx: 0 Loss: 0.018312950590849895
Epoch: 25 Idx: 5000 Loss: 0.036870264804440764
Epoch: 26 Idx: 0 Loss: 0.012755693124306784
Epoch: 26 Idx: 5000 Loss: 0.028857090453990854
Epoch: 27 Idx: 0 Loss: 0.03336707808391773
Epoch: 27 Idx: 5000 Loss: 0.013877885416802054
Epoch: 28 Idx: 0 Loss: 0.016987454302374694
Epoch: 28 Idx: 5000 Loss: 0.018549567325735546
Epoch: 29 Idx: 0 Loss: 0.02060874181963956
Epoch: 29 Idx: 5000 Loss: 0.024383255309542856
Epoch: 30 Idx: 0 Loss: 0.022040383293676337
Epoch: 30 Idx: 5000 Loss: 0.01622059195390565
Epoch: 31 Idx: 0 Loss: 0.016600877235406493
Epoch: 31 Idx: 5000 Loss: 0.02828682879928176
Epoch: 32 Idx: 0 Loss: 0.009899003563876196
Epoch: 32 Idx: 5000 Loss: 0.033344356376521715
Epoch: 33 Idx: 0 Loss: 0.027626140782081178
Epoch: 33 Idx: 5000 Loss: 0.020398807096365296
Epoch: 34 Idx: 0 Loss: 0.032119630097245666
Epoch: 34 Idx: 5000 Loss: 0.024382049192177117
Epoch: 35 Idx: 0 Loss: 0.019796767285238458
Epoch: 35 Idx: 5000 Loss: 0.040576198799419774
Epoch: 36 Idx: 0 Loss: 0.02397914742410112
Epoch: 36 Idx: 5000 Loss: 0.016359577042001996
Epoch: 37 Idx: 0 Loss: 0.010284619872828365
Epoch: 37 Idx: 5000 Loss: 0.022353410464037476
Epoch: 38 Idx: 0 Loss: 0.028419326164487814
Epoch: 38 Idx: 5000 Loss: 0.03763440741377426
Epoch: 39 Idx: 0 Loss: 0.029486821579218808
Epoch: 39 Idx: 5000 Loss: 0.033544134207785
Epoch: 40 Idx: 0 Loss: 0.024071227808707022
Epoch: 40 Idx: 5000 Loss: 0.01957448398841824
Epoch: 41 Idx: 0 Loss: 0.02449268639415833
Epoch: 41 Idx: 5000 Loss: 0.022587036100142673
Epoch: 42 Idx: 0 Loss: 0.022422354595323192
Epoch: 42 Idx: 5000 Loss: 0.0348286733349055
Epoch: 43 Idx: 0 Loss: 0.025167338715284683
Epoch: 43 Idx: 5000 Loss: 0.022640931437644632
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 400, in <module>
    loss.backward()
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/tensor.py", line 118, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
0.009392598924361159
Epoch: 49 Idx: 5000 Loss: 0.02602044525964501
Len (direct inputs):  100
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zeroTTraining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.2205534960177568
Epoch: 0 Idx: 5000 Loss: 0.028028972105529255
Epoch: 1 Idx: 0 Loss: 0.011424412230115422
Epoch: 1 Idx: 5000 Loss: 0.020433406543067273
Epoch: 2 Idx: 0 Loss: 0.027653000798690798
Epoch: 2 Idx: 5000 Loss: 0.013164606860479341
Epoch: 3 Idx: 0 Loss: 0.03399486452698131
Epoch: 3 Idx: 5000 Loss: 0.02275208479377494
Epoch: 4 Idx: 0 Loss: 0.023377282426573307
Epoch: 4 Idx: 5000 Loss: 0.02139734794838333
Epoch: 5 Idx: 0 Loss: 0.01663611962585107
Epoch: 5 Idx: 5000 Loss: 0.014944976205790802
Epoch: 6 Idx: 0 Loss: 0.03750708796959376
Epoch: 6 Idx: 5000 Loss: 0.011985547744688421
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
: 11 Idx: 0 Loss: 0.023732246633763773
Epoch: 11 Idx: 5000 Loss: 0.02244499050879739
Epoch: 12 Idx: 0 Loss: 0.028274725655031686
Epoch: 12 Idx: 5000 Loss: 0.012309728445390238
Epoch: 13 Idx: 0 Loss: 0.0357137525700754
Epoch: 13 Idx: 5000 Loss: 0.010144863509808581
Epoch: 14 Idx: 0 Loss: 0.009569169868001383
Epoch: 14 Idx: 5000 Loss: 0.018932613008749287
Epoch: 15 Idx: 0 Loss: 0.02444808814989566
Epoch: 15 Idx: 5000 Loss: 0.03877488432269822
Epoch: 16 Idx: 0 Loss: 0.017224943513118776
Epoch: 16 Idx: 5000 Loss: 0.03140109523697952
Epoch: 17 Idx: 0 Loss: 0.016272121082541717
Epoch: 17 Idx: 5000 Loss: 0.01706024147322438
Epoch: 18 Idx: 0 Loss: 0.014778239824834737
Epoch: 18 Idx: 5000 Loss: 0.014239405035866336
Epoch: 19 Idx: 0 Loss: 0.013822022888145439
Epoch: 19 Idx: 5000 Loss: 0.02434101400779185
Epoch: 20 Idx: 0 Loss: 0.019347637620544415
Epoch: 20 Idx: 5000 Loss: 0.020242454590873933
Epoch: 21 Idx: 0 Loss: 0.02851896698556362
Epoch: 21 Idx: 5000 Loss: 0.01710941468766481
Epoch: 22 Idx: 0 Loss: 0.026643703607760343
Epoch: 22 Idx: 5000 Loss: 0.02582078908600842
Epoch: 23 Idx: 0 Loss: 0.023654611346128823
Epoch: 23 Idx: 5000 Loss: 0.01887053481474726
Epoch: 24 Idx: 0 Loss: 0.014429333038267154
Epoch: 24 Idx: 5000 Loss: 0.021424270330616717
Epoch: 25 Idx: 0 Loss: 0.018549353043747923
Epoch: 25 Idx: 5000 Loss: 0.017801956839242013
Epoch: 26 Idx: 0 Loss: 0.018207805571011752
Epoch: 26 Idx: 5000 Loss: 0.028957057283643797
Epoch: 27 Idx: 0 Loss: 0.019677858210025823
Epoch: 27 Idx: 5000 Loss: 0.020637688128819238
Epoch: 28 Idx: 0 Loss: 0.013444607116530581
Epoch: 28 Idx: 5000 Loss: 0.012697423492281534
Epoch: 29 Idx: 0 Loss: 0.019793222149196866
Epoch: 29 Idx: 5000 Loss: 0.02597780556553131
Epoch: 30 Idx: 0 Loss: 0.012061144729775769
Epoch: 30 Idx: 5000 Loss: 0.020424553362127756
Epoch: 31 Idx: 0 Loss: 0.027450168755451452
Epoch: 31 Idx: 5000 Loss: 0.016998264018343978
Epoch: 32 Idx: 0 Loss: 0.025194724518603336
Epoch: 32 Idx: 5000 Loss: 0.015291256722206768
Epoch: 33 Idx: 0 Loss: 0.02362418853454988
Epoch: 33 Idx: 5000 Loss: 0.019856491591077035
Epoch: 34 Idx: 0 Loss: 0.012739870951333023
Epoch: 34 Idx: 5000 Loss: 0.028633644676662198
Epoch: 35 Idx: 0 Loss: 0.019267322852154857
Epoch: 35 Idx: 5000 Loss: 0.01389558062988941
Epoch: 36 Idx: 0 Loss: 0.032919279956324564
Epoch: 36 Idx: 5000 Loss: 0.026490129192936154
Epoch: 37 Idx: 0 Loss: 0.014461449803792175
Epoch: 37 Idx: 5000 Loss: 0.020912978512142445
Epoch: 38 Idx: 0 Loss: 0.026599146651051103
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 400, in <module>
    loss.backward()
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/tensor.py", line 118, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt
5000 Loss: 0.01522006564717946
Epoch: 44 Idx: 0 Loss: 0.014719182161032601
Epoch: 44 Idx: 5000 Loss: 0.030175346790058045
Epoch: 45 Idx: 0 Loss: 0.009542271712643153
Epoch: 45 Idx: 5000 Loss: 0.03061190690646662
Epoch: 46 Idx: 0 Loss: 0.015854015710408672
Epoch: 46 Idx: 5000 Loss: 0.024028453058213012
Epoch: 47 Idx: 0 Loss: 0.019754752127400743
Epoch: 47 Idx: 5000 Loss: 0.011360761479798476
Epoch: 48 Idx: 0 Loss: 0.04005399578145595
Epoch: 48 Idx: 5000 Loss: 0.013215234745389007
Epoch: 49 Idx: 0 Loss: 0.02874086451536492
Epoch: 49 Idx: 5000 Loss: 0.01658303362098107
Len (direct inputs):  116
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.1984981907147617
Epoch: 0 Idx: 5000 Loss: 0.0231522544184733
Epoch: 1 Idx: 0 Loss: 0.018230080174669237
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 388, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc202>
Subject: Job 3290108: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs_wtpath40_14.pkl Models/anatomy_aml_bagofnbrs_wtpath40_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs_wtpath40_14.pkl Models/anatomy_aml_bagofnbrs_wtpath40_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc202>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:48:43 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:48:43 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs_wtpath40_14.pkl Models/anatomy_aml_bagofnbrs_wtpath40_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   26945.11 sec.
    Max Memory :                                 2705 MB
    Average Memory :                             2599.45 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40712.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27032 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 3290088: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs_wtpath10_14.pkl Models/anatomy_aml_bagofnbrs_wtpath10_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs_wtpath10_14.pkl Models/anatomy_aml_bagofnbrs_wtpath10_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:33:33 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:33:33 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs_wtpath10_14.pkl Models/anatomy_aml_bagofnbrs_wtpath10_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   31504.53 sec.
    Max Memory :                                 2735 MB
    Average Memory :                             2660.86 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40682.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   31515 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc275>
Subject: Job 3290104: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs_wtpath30_14.pkl Models/anatomy_aml_bagofnbrs_wtpath30_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs_wtpath30_14.pkl Models/anatomy_aml_bagofnbrs_wtpath30_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc275>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:39:19 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:39:19 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs_wtpath30_14.pkl Models/anatomy_aml_bagofnbrs_wtpath30_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27581.63 sec.
    Max Memory :                                 2718 MB
    Average Memory :                             2607.74 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40699.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                10
    Run time :                                   27569 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc210>
Subject: Job 3290086: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 8 14 Output/test_anatomy_aml_bagofnbrs_wtpath8_14.pkl Models/anatomy_aml_bagofnbrs_wtpath8_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 8 14 Output/test_anatomy_aml_bagofnbrs_wtpath8_14.pkl Models/anatomy_aml_bagofnbrs_wtpath8_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc210>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:22:30 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:22:30 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 8 14 Output/test_anatomy_aml_bagofnbrs_wtpath8_14.pkl Models/anatomy_aml_bagofnbrs_wtpath8_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   31905.06 sec.
    Max Memory :                                 2733 MB
    Average Memory :                             2664.71 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40684.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   32178 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc258>
Subject: Job 3290100: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs_wtpath24_14.pkl Models/anatomy_aml_bagofnbrs_wtpath24_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs_wtpath24_14.pkl Models/anatomy_aml_bagofnbrs_wtpath24_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc258>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:27:22 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:27:22 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs_wtpath24_14.pkl Models/anatomy_aml_bagofnbrs_wtpath24_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   28283.04 sec.
    Max Memory :                                 2715 MB
    Average Memory :                             2627.09 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40702.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   28286 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc257>
Subject: Job 3290112: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs_wtpath152_14.pkl Models/anatomy_aml_bagofnbrs_wtpath152_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs_wtpath152_14.pkl Models/anatomy_aml_bagofnbrs_wtpath152_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:04 2020
Job was executed on host(s) <dccxc257>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 05:04:29 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 05:04:29 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs_wtpath152_14.pkl Models/anatomy_aml_bagofnbrs_wtpath152_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   26027.24 sec.
    Max Memory :                                 2657 MB
    Average Memory :                             2475.62 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40760.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   26059 sec.
    Turnaround time :                            80684 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc202>
Subject: Job 3290106: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs_wtpath32_14.pkl Models/anatomy_aml_bagofnbrs_wtpath32_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs_wtpath32_14.pkl Models/anatomy_aml_bagofnbrs_wtpath32_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc202>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:42:12 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:42:12 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs_wtpath32_14.pkl Models/anatomy_aml_bagofnbrs_wtpath32_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27394.66 sec.
    Max Memory :                                 2722 MB
    Average Memory :                             2603.99 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40695.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27396 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc234>
Subject: Job 3290102: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs_wtpath26_14.pkl Models/anatomy_aml_bagofnbrs_wtpath26_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs_wtpath26_14.pkl Models/anatomy_aml_bagofnbrs_wtpath26_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc234>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:36:16 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:36:16 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs_wtpath26_14.pkl Models/anatomy_aml_bagofnbrs_wtpath26_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27687.73 sec.
    Max Memory :                                 2723 MB
    Average Memory :                             2621.84 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40694.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27752 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc215>
Subject: Job 3290092: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs_wtpath15_14.pkl Models/anatomy_aml_bagofnbrs_wtpath15_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs_wtpath15_14.pkl Models/anatomy_aml_bagofnbrs_wtpath15_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc215>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:52:07 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:52:07 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs_wtpath15_14.pkl Models/anatomy_aml_bagofnbrs_wtpath15_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30146.07 sec.
    Max Memory :                                 2731 MB
    Average Memory :                             2643.97 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40686.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   30401 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc260>
Subject: Job 3290090: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs_wtpath12_14.pkl Models/anatomy_aml_bagofnbrs_wtpath12_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs_wtpath12_14.pkl Models/anatomy_aml_bagofnbrs_wtpath12_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc260>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:36:45 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:36:45 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs_wtpath12_14.pkl Models/anatomy_aml_bagofnbrs_wtpath12_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   31248.18 sec.
    Max Memory :                                 2737 MB
    Average Memory :                             2658.64 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40680.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   31324 sec.
    Turnaround time :                            80687 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc206>
Subject: Job 3290094: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs_wtpath18_14.pkl Models/anatomy_aml_bagofnbrs_wtpath18_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs_wtpath18_14.pkl Models/anatomy_aml_bagofnbrs_wtpath18_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc206>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:53:26 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:53:26 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs_wtpath18_14.pkl Models/anatomy_aml_bagofnbrs_wtpath18_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30252.05 sec.
    Max Memory :                                 2729 MB
    Average Memory :                             2640.36 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40688.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   30347 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc270>
Subject: Job 3290110: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs_wtpath80_14.pkl Models/anatomy_aml_bagofnbrs_wtpath80_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs_wtpath80_14.pkl Models/anatomy_aml_bagofnbrs_wtpath80_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:04 2020
Job was executed on host(s) <dccxc270>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:55:41 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:55:41 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs_wtpath80_14.pkl Models/anatomy_aml_bagofnbrs_wtpath80_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   26561.32 sec.
    Max Memory :                                 2676 MB
    Average Memory :                             2543.93 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40741.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   26587 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc241>
Subject: Job 3290084: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 7 14 Output/test_anatomy_aml_bagofnbrs_wtpath7_14.pkl Models/anatomy_aml_bagofnbrs_wtpath7_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 7 14 Output/test_anatomy_aml_bagofnbrs_wtpath7_14.pkl Models/anatomy_aml_bagofnbrs_wtpath7_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc241>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:20:23 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:20:23 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 7 14 Output/test_anatomy_aml_bagofnbrs_wtpath7_14.pkl Models/anatomy_aml_bagofnbrs_wtpath7_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   32251.59 sec.
    Max Memory :                                 2739 MB
    Average Memory :                             2673.35 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40678.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   32305 sec.
    Turnaround time :                            80687 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc274>
Subject: Job 3290096: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs_wtpath20_14.pkl Models/anatomy_aml_bagofnbrs_wtpath20_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs_wtpath20_14.pkl Models/anatomy_aml_bagofnbrs_wtpath20_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc274>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:59:30 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:59:30 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs_wtpath20_14.pkl Models/anatomy_aml_bagofnbrs_wtpath20_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   29887.08 sec.
    Max Memory :                                 2725 MB
    Average Memory :                             2643.08 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40692.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   29959 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc238>
Subject: Job 3290098: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs_wtpath22_14.pkl Models/anatomy_aml_bagofnbrs_wtpath22_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs_wtpath22_14.pkl Models/anatomy_aml_bagofnbrs_wtpath22_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc238>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:07:20 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:07:20 2020
Terminated at Wed Sep  2 12:18:54 2020
Results reported at Wed Sep  2 12:18:54 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs_wtpath22_14.pkl Models/anatomy_aml_bagofnbrs_wtpath22_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 143.

Resource usage summary:

    CPU time :                                   29411.19 sec.
    Max Memory :                                 2726 MB
    Average Memory :                             2638.51 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40691.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   29494 sec.
    Turnaround time :                            80691 sec.

The output (if any) is above this job summary.

