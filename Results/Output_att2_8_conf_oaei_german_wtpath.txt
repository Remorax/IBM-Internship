Number of neighbours: Input/data_conf_oaei_german.pkl
Number of entities: 130000
Training size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.17699800828192425
Epoch: 1 Idx: 0 Loss: 0.008373129361750102
Epoch: 2 Idx: 0 Loss: 0.047099417191365206
Epoch: 3 Idx: 0 Loss: 0.014511511648831748
Epoch: 4 Idx: 0 Loss: 0.016363971579891234
Epoch: 5 Idx: 0 Loss: 0.011430455251269588
Epoch: 6 Idx: 0 Loss: 0.018498401711835064
Epoch: 7 Idx: 0 Loss: 0.010730394592657351
Epoch: 8 Idx: 0 Loss: 0.03188224848850818
Epoch: 9 Idx: 0 Loss: 0.013425081894571263
Epoch: 10 Idx: 0 Loss: 0.02736128464787698
Epoch: 11 Idx: 0 Loss: 0.01860973793818961
Epoch: 12 Idx: 0 Loss: 0.016107060278152747
Epoch: 13 Idx: 0 Loss: 0.006612163118187112
Epoch: 14 Idx: 0 Loss: 0.017631549702981288
Epoch: 15 Idx: 0 Loss: 0.05337210107447285
Epoch: 16 Idx: 0 Loss: 0.014826826620147789
Epoch: 17 Idx: 0 Loss: 0.010796552851243545
Epoch: 18 Idx: 0 Loss: 0.047576188491421235
Epoch: 19 Idx: 0 Loss: 0.01903661734515822
Epoch: 20 Idx: 0 Loss: 0.009138627737146368
Epoch: 21 Idx: 0 Loss: 0.023874544587416155
Epoch: 22 Idx: 0 Loss: 0.02319064104237994
Epoch: 23 Idx: 0 Loss: 0.021517133633488474
Epoch: 24 Idx: 0 Loss: 0.016332428353816843
Epoch: 25 Idx: 0 Loss: 0.041370111177895914
Epoch: 26 Idx: 0 Loss: 0.041209088541741996
Epoch: 27 Idx: 0 Loss: 0.0192535045014451
Epoch: 28 Idx: 0 Loss: 0.028379282610560087
Epoch: 29 Idx: 0 Loss: 0.025864601215113983
Epoch: 30 Idx: 0 Loss: 0.029317745492886876
Epoch: 31 Idx: 0 Loss: 0.031925706969830187
Epoch: 32 Idx: 0 Loss: 0.019778648733468934
Epoch: 33 Idx: 0 Loss: 0.03278130959623577
Epoch: 34 Idx: 0 Loss: 0.013857577001269408
Epoch: 35 Idx: 0 Loss: 0.02155966252194578
Epoch: 36 Idx: 0 Loss: 0.045761399345997905
Epoch: 37 Idx: 0 Loss: 0.04584315505629684
Epoch: 38 Idx: 0 Loss: 0.012780855346525294
Epoch: 39 Idx: 0 Loss: 0.005023525625660974
Epoch: 40 Idx: 0 Loss: 0.012855595443780819
Epoch: 41 Idx: 0 Loss: 0.027841256099192524
Epoch: 42 Idx: 0 Loss: 0.014754766628456623
Epoch: 43 Idx: 0 Loss: 0.012985948758659799
Epoch: 44 Idx: 0 Loss: 0.011403912283498649
Epoch: 45 Idx: 0 Loss: 0.014129674915633172
Epoch: 46 Idx: 0 Loss: 0.027136465235216442
Epoch: 47 Idx: 0 Loss: 0.015772266177584027
Epoch: 48 Idx: 0 Loss: 0.015545535695375071
Epoch: 49 Idx: 0 Loss: 0.033837139749592654
Len (direct inputs):  3897
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
divisiTraTraTrainTraining size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.17832214560483542
Epoch: 1 Idx: 0 Loss: 0.04261859019874134
Epoch: 2 Idx: 0 Loss: 0.03353368750148923
Epoch: 3 Idx: 0 Loss: 0.021655056497807586
Epoch: 4 Idx: 0 Loss: 0.041321442105411235
Epoch: 5 Idx: 0 Loss: 0.011771641985161422
Epoch: 6 Idx: 0 Loss: 0.03163907880674743
Epoch: 7 Idx: 0 Loss: 0.009673070728839661
Epoch: 8 Idx: 0 Loss: 0.016265546448456583
Epoch: 9 Idx: 0 Loss: 0.0276953052069204
Epoch: 10 Idx: 0 Loss: 0.008477293849465583
Epoch: 11 Idx: 0 Loss: 0.01786766603497091
Epoch: 12 Idx: 0 Loss: 0.05387211100750018
Epoch: 13 Idx: 0 Loss: 0.015716695316808835
Epoch: 14 Idx: 0 Loss: 0.02126388279131296
Epoch: 15 Idx: 0 Loss: 0.04203002226862154
Epoch: 16 Idx: 0 Loss: 0.013764134026755095
Epoch: 17 Idx: 0 Loss: 0.04665050540248619
Epoch: 18 Idx: 0 Loss: 0.010854426979794454
Epoch: 19 Idx: 0 Loss: 0.010719366704686723
Epoch: 20 Idx: 0 Loss: 0.015246479290068757
Epoch: 21 Idx: 0 Loss: 0.014948833475608332
Epoch: 22 Idx: 0 Loss: 0.005802112353980608
Epoch: 23 Idx: 0 Loss: 0.015657979791678076
Epoch: 24 Idx: 0 Loss: 0.012622779376209241
Epoch: 25 Idx: 0 Loss: 0.00867221092405393
Epoch: 26 Idx: 0 Loss: 0.035920088205034124
Epoch: 27 Idx: 0 Loss: 0.060348862023586844
Epoch: 28 Idx: 0 Loss: 0.022394962926091524
Epoch: 29 Idx: 0 Loss: 0.012757651365786861
Epoch: 30 Idx: 0 Loss: 0.021150022445424133
Epoch: 31 Idx: 0 Loss: 0.009616537986582734
Epoch: 32 Idx: 0 Loss: 0.010216527065924817
Epoch: 33 Idx: 0 Loss: 0.012614353527923861
Epoch: 34 Idx: 0 Loss: 0.011855890686460613
Epoch: 35 Idx: 0 Loss: 0.009127058423909023
Epoch: 36 Idx: 0 Loss: 0.010438418833919638
Epoch: 37 Idx: 0 Loss: 0.00798409757121729
Epoch: 38 Idx: 0 Loss: 0.007076983556288979
Epoch: 39 Idx: 0 Loss: 0.035570755223440005
Epoch: 40 Idx: 0 Loss: 0.02274978545281662
Epoch: 41 Idx: 0 Loss: 0.023923519181904294
Epoch: 42 Idx: 0 Loss: 0.014604659981441923
Epoch: 43 Idx: 0 Loss: 0.015135222962889024
Epoch: 44 Idx: 0 Loss: 0.020058214198926744
Epoch: 45 Idx: 0 Loss: 0.01206166812195995
Epoch: 46 Idx: 0 Loss: 0.03750381926745104
Epoch: 47 Idx: 0 Loss: 0.01728859310766716
Epoch: 48 Idx: 0 Loss: 0.009603705350188086
Epoch: 49 Idx: 0 Loss: 0.01519403030248753
Len (direct inputs):  3858
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
divisTraining sTrTraining size: 110501 Val size: 19499
Epoch: 0 Idx: 0 Loss: 0.14321977928308077
Epoch: 1 Idx: 0 Loss: 0.029081009454995733
Epoch: 2 Idx: 0 Loss: 0.015488889151423673
Epoch: 3 Idx: 0 Loss: 0.03275522948308486
Epoch: 4 Idx: 0 Loss: 0.01510946027480577
Epoch: 5 Idx: 0 Loss: 0.021421608974897338
Epoch: 6 Idx: 0 Loss: 0.03734925774026637
Epoch: 7 Idx: 0 Loss: 0.034671268409306344
Epoch: 8 Idx: 0 Loss: 0.008038196858706752
Epoch: 9 Idx: 0 Loss: 0.019791938038632533
Epoch: 10 Idx: 0 Loss: 0.00879373648770597
Epoch: 11 Idx: 0 Loss: 0.06182906374169343
Epoch: 12 Idx: 0 Loss: 0.03267627104087163
Epoch: 13 Idx: 0 Loss: 0.015681405736792775
Epoch: 14 Idx: 0 Loss: 0.013823739783702178
Epoch: 15 Idx: 0 Loss: 0.04074742326990832
Epoch: 16 Idx: 0 Loss: 0.02458816921098387
Epoch: 17 Idx: 0 Loss: 0.017470962658509184
Epoch: 18 Idx: 0 Loss: 0.012313756163902194
Epoch: 19 Idx: 0 Loss: 0.040372186703517166
Epoch: 20 Idx: 0 Loss: 0.018509101178670318
Epoch: 21 Idx: 0 Loss: 0.021377799095113306
Epoch: 22 Idx: 0 Loss: 0.011638906908655624
Epoch: 23 Idx: 0 Loss: 0.00887884972228398
Epoch: 24 Idx: 0 Loss: 0.028809037023201582
Epoch: 25 Idx: 0 Loss: 0.011570641786371079
Epoch: 26 Idx: 0 Loss: 0.036065826836900544
Epoch: 27 Idx: 0 Loss: 0.010127010494066547
Epoch: 28 Idx: 0 Loss: 0.011601659820132428
Epoch: 29 Idx: 0 Loss: 0.02955388328398098
Epoch: 30 Idx: 0 Loss: 0.007093388452565892
Epoch: 31 Idx: 0 Loss: 0.024892194413954932
Epoch: 32 Idx: 0 Loss: 0.021033093748256116
Epoch: 33 Idx: 0 Loss: 0.02174421396988813
Epoch: 34 Idx: 0 Loss: 0.011773188321478474
Epoch: 35 Idx: 0 Loss: 0.0316848449172296
Epoch: 36 Idx: 0 Loss: 0.023448068407853274
Epoch: 37 Idx: 0 Loss: 0.029576450587538848
Epoch: 38 Idx: 0 Loss: 0.013661797143632373
Epoch: 39 Idx: 0 Loss: 0.00996754786135825
Epoch: 40 Idx: 0 Loss: 0.009036461114403009
Epoch: 41 Idx: 0 Loss: 0.017034153355855015
Epoch: 42 Idx: 0 Loss: 0.015669232265794066
Epoch: 43 Idx: 0 Loss: 0.016112471377775564
Epoch: 44 Idx: 0 Loss: 0.023315495867119104
Epoch: 45 Idx: 0 Loss: 0.017376841301353585
Epoch: 46 Idx: 0 Loss: 0.010908227085813994
Epoch: 47 Idx: 0 Loss: 0.06195179410312428
Epoch: 48 Idx: 0 Loss: 0.022999563228389173
Epoch: 49 Idx: 0 Loss: 0.016532627771599463
Len (direct inputs):  3983
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
diTrainTraining sTraining size: 110499 Val size: 19501
Epoch: 0 Idx: 0 Loss: 0.1484438636979702
Epoch: 1 Idx: 0 Loss: 0.031116064981355277
Epoch: 2 Idx: 0 Loss: 0.016925034785983385
Epoch: 3 Idx: 0 Loss: 0.0395611211501729
Epoch: 4 Idx: 0 Loss: 0.012277894469351344
Epoch: 5 Idx: 0 Loss: 0.012540797486817896
Epoch: 6 Idx: 0 Loss: 0.0429209815271135
Epoch: 7 Idx: 0 Loss: 0.017147821722679243
Epoch: 8 Idx: 0 Loss: 0.022789708065421937
Epoch: 9 Idx: 0 Loss: 0.009762023986383908
Epoch: 10 Idx: 0 Loss: 0.019565711802297006
Epoch: 11 Idx: 0 Loss: 0.015485971839402703
Epoch: 12 Idx: 0 Loss: 0.015941105887567784
Epoch: 13 Idx: 0 Loss: 0.021154234632530484
Epoch: 14 Idx: 0 Loss: 0.03605404370370073
Epoch: 15 Idx: 0 Loss: 0.04755428509559918
Epoch: 16 Idx: 0 Loss: 0.020481703578387026
Epoch: 17 Idx: 0 Loss: 0.012195220537512392
Epoch: 18 Idx: 0 Loss: 0.029017601575356523
Epoch: 19 Idx: 0 Loss: 0.015797697125887196
Epoch: 20 Idx: 0 Loss: 0.007396722777055888
Epoch: 21 Idx: 0 Loss: 0.02281138727509364
Epoch: 22 Idx: 0 Loss: 0.014388058169097046
Epoch: 23 Idx: 0 Loss: 0.006966449405399456
Epoch: 24 Idx: 0 Loss: 0.010748113548330059
Epoch: 25 Idx: 0 Loss: 0.03667235632030692
Epoch: 26 Idx: 0 Loss: 0.0073073587628348004
Epoch: 27 Idx: 0 Loss: 0.00902578107041643
Epoch: 28 Idx: 0 Loss: 0.015596266629162811
Epoch: 29 Idx: 0 Loss: 0.011922805027725764
Epoch: 30 Idx: 0 Loss: 0.013951374628505781
Epoch: 31 Idx: 0 Loss: 0.023871096910658782
Epoch: 32 Idx: 0 Loss: 0.015431061410890783
Epoch: 33 Idx: 0 Loss: 0.012755211370415763
Epoch: 34 Idx: 0 Loss: 0.013037425216571731
Epoch: 35 Idx: 0 Loss: 0.019668840740073575
Epoch: 36 Idx: 0 Loss: 0.01996628357322027
Epoch: 37 Idx: 0 Loss: 0.01447034630587328
Epoch: 38 Idx: 0 Loss: 0.03816646741979872
Epoch: 39 Idx: 0 Loss: 0.01655961193568444
Epoch: 40 Idx: 0 Loss: 0.01624226943253644
Epoch: 41 Idx: 0 Loss: 0.0166725293530857
Epoch: 42 Idx: 0 Loss: 0.00996838678227065
Epoch: 43 Idx: 0 Loss: 0.012044824793425418
Epoch: 44 Idx: 0 Loss: 0.023936851525438597
Epoch: 45 Idx: 0 Loss: 0.017327630824097932
Epoch: 46 Idx: 0 Loss: 0.038992271203083094
Epoch: 47 Idx: 0 Loss: 0.01230622240429879
Epoch: 48 Idx: 0 Loss: 0.013065308666267693
Epoch: 49 Idx: 0 Loss: 0.027212227861425874
Len (direct inputs):  3862
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
diviTraining sizeTraining size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.13835248050195426
Epoch: 1 Idx: 0 Loss: 0.014445741637781678
Epoch: 2 Idx: 0 Loss: 0.015194957985145238
Epoch: 3 Idx: 0 Loss: 0.019193366822050185
Epoch: 4 Idx: 0 Loss: 0.02013243767864551
Epoch: 5 Idx: 0 Loss: 0.014337208538886835
Epoch: 6 Idx: 0 Loss: 0.007669223634066677
Epoch: 7 Idx: 0 Loss: 0.0181795777160818
Epoch: 8 Idx: 0 Loss: 0.013984222107769936
Epoch: 9 Idx: 0 Loss: 0.005460361330684405
Epoch: 10 Idx: 0 Loss: 0.013681548704858566
Epoch: 11 Idx: 0 Loss: 0.029122924331121642
Epoch: 12 Idx: 0 Loss: 0.026165005335019982
Epoch: 13 Idx: 0 Loss: 0.02880788017758997
Epoch: 14 Idx: 0 Loss: 0.057446625466923924
Epoch: 15 Idx: 0 Loss: 0.0076077024562316835
Epoch: 16 Idx: 0 Loss: 0.016133103419391726
Epoch: 17 Idx: 0 Loss: 0.026457697457327824
Epoch: 18 Idx: 0 Loss: 0.030499650301053807
Epoch: 19 Idx: 0 Loss: 0.021856553058578105
Epoch: 20 Idx: 0 Loss: 0.015556905091894729
Epoch: 21 Idx: 0 Loss: 0.01224708174276873
Epoch: 22 Idx: 0 Loss: 0.013435348002236213
Epoch: 23 Idx: 0 Loss: 0.03855868329303168
Epoch: 24 Idx: 0 Loss: 0.017334041421538788
Epoch: 25 Idx: 0 Loss: 0.00952889664645857
Epoch: 26 Idx: 0 Loss: 0.02092539404506047
Epoch: 27 Idx: 0 Loss: 0.012829293853482956
Epoch: 28 Idx: 0 Loss: 0.013604534104526531
Epoch: 29 Idx: 0 Loss: 0.006801237157444332
Epoch: 30 Idx: 0 Loss: 0.02364853659456325
Epoch: 31 Idx: 0 Loss: 0.015810190553647643
Epoch: 32 Idx: 0 Loss: 0.009464304605741615
Epoch: 33 Idx: 0 Loss: 0.039575052866335864
Epoch: 34 Idx: 0 Loss: 0.011014979303688196
Epoch: 35 Idx: 0 Loss: 0.06336620886030558
Epoch: 36 Idx: 0 Loss: 0.03938098145547615
Epoch: 37 Idx: 0 Loss: 0.00825777891246144
Epoch: 38 Idx: 0 Loss: 0.010640851333080783
Epoch: 39 Idx: 0 Loss: 0.018566898734077058
Epoch: 40 Idx: 0 Loss: 0.019307238652796245
Epoch: 41 Idx: 0 Loss: 0.01791541093850616
Epoch: 42 Idx: 0 Loss: 0.014329790737482275
Epoch: 43 Idx: 0 Loss: 0.05301698829527054
Epoch: 44 Idx: 0 Loss: 0.012869471497562058
Epoch: 45 Idx: 0 Loss: 0.02434708457641351
Epoch: 46 Idx: 0 Loss: 0.007831558145743718
Epoch: 47 Idx: 0 Loss: 0.03669070809680416
Epoch: 48 Idx: 0 Loss: 0.007368397709652525
Epoch: 49 Idx: 0 Loss: 0.030505805252122254
Len (direct inputs):  3914
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zeTraining size: 11050Training size: 110501 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.22659446950064935
Epoch: 1 Idx: 0 Loss: 0.02741221513156969
Epoch: 2 Idx: 0 Loss: 0.038534321368735046
Epoch: 3 Idx: 0 Loss: 0.024611165620334836
Epoch: 4 Idx: 0 Loss: 0.018078173713805913
Epoch: 5 Idx: 0 Loss: 0.02849761474346129
Epoch: 6 Idx: 0 Loss: 0.02759078674064716
Epoch: 7 Idx: 0 Loss: 0.019087712762319603
Epoch: 8 Idx: 0 Loss: 0.010571859446025626
Epoch: 9 Idx: 0 Loss: 0.04211908849824252
Epoch: 10 Idx: 0 Loss: 0.03154919000229475
Epoch: 11 Idx: 0 Loss: 0.012801182832543976
Epoch: 12 Idx: 0 Loss: 0.0127683013913049
Epoch: 13 Idx: 0 Loss: 0.03031872891185094
Epoch: 14 Idx: 0 Loss: 0.01812316760726028
Epoch: 15 Idx: 0 Loss: 0.012001142778449847
Epoch: 16 Idx: 0 Loss: 0.018201442669751502
Epoch: 17 Idx: 0 Loss: 0.013353324308436311
Epoch: 18 Idx: 0 Loss: 0.02718343394734189
Epoch: 19 Idx: 0 Loss: 0.03045321393324176
Epoch: 20 Idx: 0 Loss: 0.028328572391831022
Epoch: 21 Idx: 0 Loss: 0.01968063708147739
Epoch: 22 Idx: 0 Loss: 0.010655138025405356
Epoch: 23 Idx: 0 Loss: 0.012559941696911995
Epoch: 24 Idx: 0 Loss: 0.017450822167153636
Epoch: 25 Idx: 0 Loss: 0.023010865873877222
Epoch: 26 Idx: 0 Loss: 0.02075742662365207
Epoch: 27 Idx: 0 Loss: 0.0327033920318667
Epoch: 28 Idx: 0 Loss: 0.015204049754523068
Epoch: 29 Idx: 0 Loss: 0.03541441814584666
Epoch: 30 Idx: 0 Loss: 0.011492400411366049
Epoch: 31 Idx: 0 Loss: 0.013078974910455845
Epoch: 32 Idx: 0 Loss: 0.053981936995203775
Epoch: 33 Idx: 0 Loss: 0.02987338052407372
Epoch: 34 Idx: 0 Loss: 0.012062671507946886
Epoch: 35 Idx: 0 Loss: 0.02823401006695979
Epoch: 36 Idx: 0 Loss: 0.025126591983957808
Epoch: 37 Idx: 0 Loss: 0.014819366745927022
Epoch: 38 Idx: 0 Loss: 0.04141993608395204
Epoch: 39 Idx: 0 Loss: 0.015303429580562647
Epoch: 40 Idx: 0 Loss: 0.023731435611787616
Epoch: 41 Idx: 0 Loss: 0.032116584907508475
Epoch: 42 Idx: 0 Loss: 0.019377244832786862
Epoch: 43 Idx: 0 Loss: 0.008675010037486306
Epoch: 44 Idx: 0 Loss: 0.03568904493343865
Epoch: 45 Idx: 0 Loss: 0.03632205075251203
Epoch: 46 Idx: 0 Loss: 0.006232856730669108
Epoch: 47 Idx: 0 Loss: 0.010355398685478287
Epoch: 48 Idx: 0 Loss: 0.007654784145308378
Epoch: 49 Idx: 0 Loss: 0.014535214480476394
Len (direct inputs):  3839
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Epoch: 0 Idx: 0 Loss: 0.17694426119350057
Epoch: 1 Idx: 0 Loss: 0.0296175015744073
Epoch: 2 Idx: 0 Loss: 0.02473442632983516
Epoch: 3 Idx: 0 Loss: 0.03925132742028152
Epoch: 4 Idx: 0 Loss: 0.020476495655033972
Epoch: 5 Idx: 0 Loss: 0.014206413233150323
Epoch: 6 Idx: 0 Loss: 0.050336382981196075
Epoch: 7 Idx: 0 Loss: 0.03031170948657477
Epoch: 8 Idx: 0 Loss: 0.041939730103941406
Epoch: 9 Idx: 0 Loss: 0.02145789251163616
Epoch: 10 Idx: 0 Loss: 0.030499803083255447
Epoch: 11 Idx: 0 Loss: 0.023386717743668368
Epoch: 12 Idx: 0 Loss: 0.026878506032125923
Epoch: 13 Idx: 0 Loss: 0.004650063453914011
Epoch: 14 Idx: 0 Loss: 0.026335904994999146
Epoch: 15 Idx: 0 Loss: 0.005698963136819803
Epoch: 16 Idx: 0 Loss: 0.03815893054096133
Epoch: 17 Idx: 0 Loss: 0.05069354136986162
Epoch: 18 Idx: 0 Loss: 0.011367227906390193
Epoch: 19 Idx: 0 Loss: 0.03726484249448255
Epoch: 20 Idx: 0 Loss: 0.015058274264777495
Epoch: 21 Idx: 0 Loss: 0.024677698431029328
Epoch: 22 Idx: 0 Loss: 0.04168080660689005
Epoch: 23 Idx: 0 Loss: 0.02608609686973113
Epoch: 24 Idx: 0 Loss: 0.0348007365388281
Epoch: 25 Idx: 0 Loss: 0.014401884912346534
Epoch: 26 Idx: 0 Loss: 0.011796653371240088
Epoch: 27 Idx: 0 Loss: 0.0130970125861513
Epoch: 28 Idx: 0 Loss: 0.014594751106994661
Epoch: 29 Idx: 0 Loss: 0.02852047363227798
Epoch: 30 Idx: 0 Loss: 0.051994545221061915
Epoch: 31 Idx: 0 Loss: 0.007997271966189627
Epoch: 32 Idx: 0 Loss: 0.01893184082982805
Epoch: 33 Idx: 0 Loss: 0.031812943003440716
Epoch: 34 Idx: 0 Loss: 0.026560160546631788
Epoch: 35 Idx: 0 Loss: 0.02287146103418859
Epoch: 36 Idx: 0 Loss: 0.03779003917577746
Epoch: 37 Idx: 0 Loss: 0.012426312049417569
Epoch: 38 Idx: 0 Loss: 0.015536975528925247
Epoch: 39 Idx: 0 Loss: 0.02170231662596994
Epoch: 40 Idx: 0 Loss: 0.03605909096997562
Epoch: 41 Idx: 0 Loss: 0.009969216171486123
Epoch: 42 Idx: 0 Loss: 0.01751271972366352
Epoch: 43 Idx: 0 Loss: 0.02044135200276866
Epoch: 44 Idx: 0 Loss: 0.014778077574724184
Epoch: 45 Idx: 0 Loss: 0.029940304871780295
Epoch: 46 Idx: 0 Loss: 0.022533196773561876
Epoch: 47 Idx: 0 Loss: 0.02192743440377512
Epoch: 48 Idx: 0 Loss: 0.013640438697254044
Epoch: 49 Idx: 0 Loss: 0.010391390853502309
Len (direct inputs):  2941
Len (direct inputs):  3848
Len (direct inputs):  2814
Len (direct inputs):  5361
Len (direct inputs):  4611
Len (direct inputs):  3971
Len (direct inputs):  4254
Performance for [('confOf', 'sigkdd'), ('iasted', 'sigkdd'), ('cmt', 'ekaw')] is : (0.00549073438572409, 1.0, 0.010921501706484642, 0.026863666890530553, 0.006854009595613434)
Performance for [('confOf', 'iasted'), ('conference', 'edas'), ('cmt', 'sigkdd')] is : (0.005345476143337953, 1.0, 0.010634107916502558, 0.02616786198875751, 0.006672927685235529)
Performance for [('ekaw', 'sigkdd'), ('conference', 'confOf'), ('conference', 'sigkdd')] is : (0.006824925816023739, 1.0, 0.013557323902151489, 0.03321779318313114, 0.008516625934977411)
Performance for [('confOf', 'edas'), ('cmt', 'conference'), ('edas', 'iasted')] is : (0.003183831672203765, 1.0, 0.0063474541189457705, 0.01571897211591033, 0.003976624364604585)
Performance for [('conference', 'iasted'), ('edas', 'sigkdd'), ('ekaw', 'iasted')] is : (0.0026053466243769825, 1.0, 0.005197152864083155, 0.012892376681614349, 0.003254563463987548)
Performance for [('cmt', 'edas'), ('edas', 'ekaw'), ('cmt', 'confOf')] is : (0.005537098560354375, 1.0, 0.011013215859030838, 0.027085590465872156, 0.0069118053635609635)
Performance for [('confOf', 'ekaw'), ('conference', 'ekaw'), ('cmt', 'iasted')] is : (0.006359300476947536, 1.0, 0.01263823064770932, 0.0310077519379845, 0.007936507936507938)
Final Results: [0.00504953 1.         0.01004414 0.02470772 0.00630329]
Threshold:  0.5053991310729679
  0.5093530728733442
037
------------------------------------------------
Sender: LSF System <rer@dccxc241>
Subject: Job 3480289: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:19 2020
Job was executed on host(s) <dccxc241>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 19:00:57 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 19:00:57 2020
Terminated at Sat Sep  5 03:18:00 2020
Results reported at Sat Sep  5 03:18:00 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   29815.21 sec.
    Max Memory :                                 1542 MB
    Average Memory :                             1157.64 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41875.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   29828 sec.
    Turnaround time :                            90581 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc230>
Subject: Job 3480295: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:19 2020
Job was executed on host(s) <dccxc230>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 19:01:44 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 19:01:44 2020
Terminated at Sat Sep  5 03:24:55 2020
Results reported at Sat Sep  5 03:24:55 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   30149.42 sec.
    Max Memory :                                 1529 MB
    Average Memory :                             1160.28 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41888.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   30193 sec.
    Turnaround time :                            90996 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc274>
Subject: Job 3480299: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:19 2020
Job was executed on host(s) <dccxc274>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 19:07:06 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 19:07:06 2020
Terminated at Sat Sep  5 03:25:48 2020
Results reported at Sat Sep  5 03:25:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   29714.22 sec.
    Max Memory :                                 1541 MB
    Average Memory :                             1156.42 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41876.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   29935 sec.
    Turnaround time :                            91049 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc253>
Subject: Job 3480291: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:19 2020
Job was executed on host(s) <dccxc253>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 19:01:14 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 19:01:14 2020
Terminated at Sat Sep  5 03:26:27 2020
Results reported at Sat Sep  5 03:26:27 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 8 Output/test_conf_oaei_german_wtpath2_8.pkl Models/conf_oaei_german_wtpath2_8.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   30294.28 sec.
    Max Memory :                                 1537 MB
    Average Memory :                             1157.67 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41880.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   30319 sec.
    Turnaround time :                            91088 sec.

The output (if any) is above this job summary.

