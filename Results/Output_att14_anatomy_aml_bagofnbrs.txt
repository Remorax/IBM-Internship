Max number of nodes in a path: Input/data_anatomy_oaei_bagofnbrs.pkl
Number of entities: 150000
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.2487561941161049
Epoch: 0 Idx: 5000 Loss: 0.017383654094427943
Epoch: 1 Idx: 0 Loss: 0.019290927739644248
Epoch: 1 Idx: 5000 Loss: 0.02572542416976864
Epoch: 2 Idx: 0 Loss: 0.020514519173337437
Epoch: 2 Idx: 5000 Loss: 0.025279342712678603
Epoch: 3 Idx: 0 Loss: 0.033945020848404575
Epoch: 3 Idx: 5000 Loss: 0.01836347985482048
Epoch: 4 Idx: 0 Loss: 0.03906323499542917
Epoch: 4 Idx: 5000 Loss: 0.037012990721822486
Epoch: 5 Idx: 0 Loss: 0.023362074712738448
Epoch: 5 Idx: 5000 Loss: 0.009488467570968667
Epoch: 6 Idx: 0 Loss: 0.028778710188556884
Epoch: 6 Idx: 5000 Loss: 0.015947935284414506
Epoch: 7 Idx: 0 Loss: 0.01851163876987672
Epoch: 7 Idx: 5000 Loss: 0.019712428154722055
Epoch: 8 Idx: 0 Loss: 0.01798438432612374
Epoch: 8 Idx: 5000 Loss: 0.020445521861274144
Epoch: 9 Idx: 0 Loss: 0.012162384179457444
Epoch: 9 Idx: 5000 Loss: 0.026265003482090786
Epoch: 10 Idx: 0 Loss: 0.016063222574544546
Epoch: 10 Idx: 5000 Loss: 0.021086032518468866
Epoch: 11 Idx: 0 Loss: 0.018752327266490246
Epoch: 11 Idx: 5000 Loss: 0.01886410340805967
Epoch: 12 Idx: 0 Loss: 0.015137493828459761
Epoch: 12 Idx: 5000 Loss: 0.0427007208930671
Epoch: 13 Idx: 0 Loss: 0.023523088526856376
Epoch: 13 Idx: 5000 Loss: 0.02273175838245553
Epoch: 14 Idx: 0 Loss: 0.037826616588907375
Epoch: 14 Idx: 5000 Loss: 0.015254837211691817
Epoch: 15 Idx: 0 Loss: 0.05209352136723401
Epoch: 15 Idx: 5000 Loss: 0.01710892841154301
Epoch: 16 Idx: 0 Loss: 0.023919507365451054
Epoch: 16 Idx: 5000 Loss: 0.03126949624627216
Epoch: 17 Idx: 0 Loss: 0.014244633872822723
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
9769
Epoch: 21 Idx: 5000 Loss: 0.029942690995083104
Epoch: 22 Idx: 0 Loss: 0.03688762015311055
Epoch: 22 Idx: 5000 Loss: 0.017250591108339205
Epoch: 23 Idx: 0 Loss: 0.02007279858911295
Epoch: 23 Idx: 5000 Loss: 0.020552305594234505
Epoch: 24 Idx: 0 Loss: 0.012740006557667277
Epoch: 24 Idx: 5000 Loss: 0.02538060042093908
Epoch: 25 Idx: 0 Loss: 0.0113298754812092
Epoch: 25 Idx: 5000 Loss: 0.02804361785188722
Epoch: 26 Idx: 0 Loss: 0.018596082127430483
Epoch: 26 Idx: 5000 Loss: 0.012391175553931377
Epoch: 27 Idx: 0 Loss: 0.013768703433450531
Epoch: 27 Idx: 5000 Loss: 0.006800291271555487
Epoch: 28 Idx: 0 Loss: 0.024106919982272407
Epoch: 28 Idx: 5000 Loss: 0.026404631228295953
Epoch: 29 Idx: 0 Loss: 0.014999135804999614
Epoch: 29 Idx: 5000 Loss: 0.018998079952939423
Epoch: 30 Idx: 0 Loss: 0.03296847488454621
Epoch: 30 Idx: 5000 Loss: 0.02704155961831422
Epoch: 31 Idx: 0 Loss: 0.032279143594015874
Epoch: 31 Idx: 5000 Loss: 0.03271658982311272
Epoch: 32 Idx: 0 Loss: 0.02247455581819642
Epoch: 32 Idx: 5000 Loss: 0.05394316690568338
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 387, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
  File "Attention_anatomy_aml.py", line 314, in to_feature
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml.py", line 314, in <listcomp>
    for elem in inputs_lenpadded]
  File "Attention_anatomy_aml.py", line 313, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml.py", line 313, in <listcomp>
    for nbr_type in ent] for ent in elem]
  File "Attention_anatomy_aml.py", line 312, in <listcomp>
    for i in range(max_paths - len(nbr_type))]
KeyboardInterrupt
8528
Epoch: 40 Idx: 5000 Loss: 0.03163225693161011
Epoch: 41 Idx: 0 Loss: 0.02944786427285859
Epoch: 41 Idx: 5000 Loss: 0.01616059261951068
Epoch: 42 Idx: 0 Loss: 0.03137122984037345
Epoch: 42 Idx: 5000 Loss: 0.013217430567603418
Epoch: 43 Idx: 0 Loss: 0.03451034212707151
Epoch: 43 Idx: 5000 Loss: 0.021306528672066456
Epoch: 44 Idx: 0 Loss: 0.023074576960982973
Epoch: 44 Idx: 5000 Loss: 0.03670826734931806
Epoch: 45 Idx: 0 Loss: 0.025884556165977603
Epoch: 45 Idx: 5000 Loss: 0.023950776141011723
Epoch: 46 Idx: 0 Loss: 0.010490923417517926
Epoch: 46 Idx: 5000 Loss: 0.01805715943327975
Epoch: 47 Idx: 0 Loss: 0.02195621082081812
Epoch: 47 Idx: 5000 Loss: 0.01591720490881279
Epoch: 48 Idx: 0 Loss: 0.01208650694177283
Epoch: 48 Idx: 5000 Loss: 0.018752068580515195
Epoch: 49 Idx: 0 Loss: 0.021830803857732416
Epoch: 49 Idx: 5000 Loss: 0.016900198118862057
Len (direct inputs):  99
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
divisioTraininTraining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.2243911084442618
Epoch: 0 Idx: 5000 Loss: 0.031188939242436854
Epoch: 1 Idx: 0 Loss: 0.016016557250070822
Epoch: 1 Idx: 5000 Loss: 0.030037658072154447
Epoch: 2 Idx: 0 Loss: 0.019450881238259117
Epoch: 2 Idx: 5000 Loss: 0.017467572924906662
Epoch: 3 Idx: 0 Loss: 0.024393565048571115
Epoch: 3 Idx: 5000 Loss: 0.015305441760289022
Epoch: 4 Idx: 0 Loss: 0.023584893640569416
Epoch: 4 Idx: 5000 Loss: 0.029283137661301403
Epoch: 5 Idx: 0 Loss: 0.018520024217705138
Epoch: 5 Idx: 5000 Loss: 0.0484395735774142
Epoch: 6 Idx: 0 Loss: 0.031012965566980494
Epoch: 6 Idx: 5000 Loss: 0.01891041782408636
Epoch: 7 Idx: 0 Loss: 0.013827250419824815
Epoch: 7 Idx: 5000 Loss: 0.01214298574869527
Epoch: 8 Idx: 0 Loss: 0.02885286345584138
Epoch: 8 Idx: 5000 Loss: 0.036674165592997354
Epoch: 9 Idx: 0 Loss: 0.026664215384651274
Epoch: 9 Idx: 5000 Loss: 0.03304780103552613
Epoch: 10 Idx: 0 Loss: 0.01002487380918126
Epoch: 10 Idx: 5000 Loss: 0.02314182286168189
Epoch: 11 Idx: 0 Loss: 0.0222115109481748
Epoch: 11 Idx: 5000 Loss: 0.00794818931830715
Epoch: 12 Idx: 0 Loss: 0.019462706769763808
Epoch: 12 Idx: 5000 Loss: 0.02945408867665702
Epoch: 13 Idx: 0 Loss: 0.019909050241271396
Epoch: 13 Idx: 5000 Loss: 0.02783743761032837
Epoch: 14 Idx: 0 Loss: 0.030236379761157995
Epoch: 14 Idx: 5000 Loss: 0.027157565899545974
Epoch: 15 Idx: 0 Loss: 0.03698426373254642
Epoch: 15 Idx: 5000 Loss: 0.020978528000529847
Epoch: 16 Idx: 0 Loss: 0.0153364934030827
Epoch: 16 Idx: 5000 Loss: 0.0316801976893173
Epoch: 17 Idx: 0 Loss: 0.02870532032429552
Epoch: 17 Idx: 5000 Loss: 0.022947064564964793
Epoch: 18 Idx: 0 Loss: 0.014494855744144294
Epoch: 18 Idx: 5000 Loss: 0.026971974373487653
Epoch: 19 Idx: 0 Loss: 0.006873557621870463
Epoch: 19 Idx: 5000 Loss: 0.020948796061773765
Epoch: 20 Idx: 0 Loss: 0.020923885201802182
Epoch: 20 Idx: 5000 Loss: 0.02115094121231548
Epoch: 21 Idx: 0 Loss: 0.025087223675296026
Epoch: 21 Idx: 5000 Loss: 0.03430477217348089
Epoch: 22 Idx: 0 Loss: 0.04449364969233243
Epoch: 22 Idx: 5000 Loss: 0.0218662259470362
Epoch: 23 Idx: 0 Loss: 0.017131766306805005
Epoch: 23 Idx: 5000 Loss: 0.025411729439966054
Epoch: 24 Idx: 0 Loss: 0.013853516468409873
Epoch: 24 Idx: 5000 Loss: 0.03549843422492223
Epoch: 25 Idx: 0 Loss: 0.0292862968882299
Epoch: 25 Idx: 5000 Loss: 0.013580609761404114
Epoch: 26 Idx: 0 Loss: 0.04296759988649682
Epoch: 26 Idx: 5000 Loss: 0.023116114152346528
Epoch: 27 Idx: 0 Loss: 0.009807306920646582
Epoch: 27 Idx: 5000 Loss: 0.02155651620379228
Epoch: 28 Idx: 0 Loss: 0.01898870428571666
Epoch: 28 Idx: 5000 Loss: 0.015412580419960239
Epoch: 29 Idx: 0 Loss: 0.02544123258550287
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
x: 5000 Loss: 0.03965114675972806
Epoch: 37 Idx: 0 Loss: 0.025316485807146273
Epoch: 37 Idx: 5000 Loss: 0.012793972201719956
Epoch: 38 Idx: 0 Loss: 0.019678462107101783
Epoch: 38 Idx: 5000 Loss: 0.01861267127414986
Epoch: 39 Idx: 0 Loss: 0.01796110975904754
Epoch: 39 Idx: 5000 Loss: 0.018093353154163924
Epoch: 40 Idx: 0 Loss: 0.014711763094994938
Epoch: 40 Idx: 5000 Loss: 0.013436301111582213
Epoch: 41 Idx: 0 Loss: 0.015368068337248339
Epoch: 41 Idx: 5000 Loss: 0.018134363499197458
Epoch: 42 Idx: 0 Loss: 0.02034059882799319
Epoch: 42 Idx: 5000 Loss: 0.01747085415734971
Epoch: 43 Idx: 0 Loss: 0.023979895011875346
Epoch: 43 Idx: 5000 Loss: 0.026219514441264843
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 400, in <module>
    optimizer.step()
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/optim/adam.py", line 94, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
KeyboardInterrupt
h: 47 Idx: 0 Loss: 0.05206242919887526
Epoch: 47 Idx: 5000 Loss: 0.02093743789678742
Epoch: 48 Idx: 0 Loss: 0.020862618007571762
Epoch: 48 Idx: 5000 Loss: 0.03477370591636388
Epoch: 49 Idx: 0 Loss: 0.02093680311721003
Epoch: 49 Idx: 5000 Loss: 0.012663355369797739
Len (direct inputs):  111
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
TrTraining size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.2810263431068882
Epoch: 0 Idx: 5000 Loss: 0.01625532706988111
Epoch: 1 Idx: 0 Loss: 0.02478920092577551
Epoch: 1 Idx: 5000 Loss: 0.018597906273491106
Epoch: 2 Idx: 0 Loss: 0.010426035873907129
Epoch: 2 Idx: 5000 Loss: 0.02303113543611337
Epoch: 3 Idx: 0 Loss: 0.01880177814141333
Epoch: 3 Idx: 5000 Loss: 0.01832355260832552
Epoch: 4 Idx: 0 Loss: 0.02649307647360286
Epoch: 4 Idx: 5000 Loss: 0.033600629136624274
Epoch: 5 Idx: 0 Loss: 0.020809370790577927
Epoch: 5 Idx: 5000 Loss: 0.017694226333649286
Epoch: 6 Idx: 0 Loss: 0.018753927974601854
Epoch: 6 Idx: 5000 Loss: 0.02669007362351665
Epoch: 7 Idx: 0 Loss: 0.018216518792226428
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
23734136
Epoch: 11 Idx: 5000 Loss: 0.03167314862469291
Epoch: 12 Idx: 0 Loss: 0.01574221361891549
Epoch: 12 Idx: 5000 Loss: 0.02769807096428575
Epoch: 13 Idx: 0 Loss: 0.021075099279921683
Epoch: 13 Idx: 5000 Loss: 0.02403315257923047
Epoch: 14 Idx: 0 Loss: 0.02525565836749533
Epoch: 14 Idx: 5000 Loss: 0.014003401741006715
Epoch: 15 Idx: 0 Loss: 0.01332380728437664
Epoch: 15 Idx: 5000 Loss: 0.017016568738697422
Epoch: 16 Idx: 0 Loss: 0.013892030657864318
Epoch: 16 Idx: 5000 Loss: 0.021938390413223166
Epoch: 17 Idx: 0 Loss: 0.01913720723566411
Epoch: 17 Idx: 5000 Loss: 0.0340028891071775
Epoch: 18 Idx: 0 Loss: 0.026808905923331662
Epoch: 18 Idx: 5000 Loss: 0.022509004069274474
Epoch: 19 Idx: 0 Loss: 0.01783725392815617
Epoch: 19 Idx: 5000 Loss: 0.019480682469529227
Epoch: 20 Idx: 0 Loss: 0.018622058199451674
Epoch: 20 Idx: 5000 Loss: 0.025547154558545275
Epoch: 21 Idx: 0 Loss: 0.016212100966645916
Epoch: 21 Idx: 5000 Loss: 0.02445089555089144
Epoch: 22 Idx: 0 Loss: 0.01359183643755392
Epoch: 22 Idx: 5000 Loss: 0.042180015804054824
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 387, in <module>
    inputs = np.array(to_feature(inputs_all[batch_start: batch_end]))
KeyboardInterrupt
: 25 Idx: 0 Loss: 0.027396541879426962
Epoch: 25 Idx: 5000 Loss: 0.01560534433627802
Epoch: 26 Idx: 0 Loss: 0.02062500038097851
Epoch: 26 Idx: 5000 Loss: 0.021410416526175154
Epoch: 27 Idx: 0 Loss: 0.015760134801007145
Epoch: 27 Idx: 5000 Loss: 0.017848046767215603
Epoch: 28 Idx: 0 Loss: 0.026734513323880462
Epoch: 28 Idx: 5000 Loss: 0.023086468381903973
Epoch: 29 Idx: 0 Loss: 0.025328649929614526
Epoch: 29 Idx: 5000 Loss: 0.015610781827728567
Epoch: 30 Idx: 0 Loss: 0.013239853148694481
Epoch: 30 Idx: 5000 Loss: 0.027207187587021273
Epoch: 31 Idx: 0 Loss: 0.017003565796937896
Epoch: 31 Idx: 5000 Loss: 0.0207257432524336
Epoch: 32 Idx: 0 Loss: 0.016589243317715392
Epoch: 32 Idx: 5000 Loss: 0.026280494204490884
Epoch: 33 Idx: 0 Loss: 0.018224571400989403
Epoch: 33 Idx: 5000 Loss: 0.016564798448218336
Epoch: 34 Idx: 0 Loss: 0.016726855233023273
Epoch: 34 Idx: 5000 Loss: 0.01827222987213656
Epoch: 35 Idx: 0 Loss: 0.02289441163129475
Epoch: 35 Idx: 5000 Loss: 0.024871030152187362
Epoch: 36 Idx: 0 Loss: 0.027302929553715882
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt
581555710732777
Epoch: 40 Idx: 5000 Loss: 0.02407359789382462
Epoch: 41 Idx: 0 Loss: 0.009658078154151623
Epoch: 41 Idx: 5000 Loss: 0.010241344101434454
Epoch: 42 Idx: 0 Loss: 0.01501997065666652
Epoch: 42 Idx: 5000 Loss: 0.02223112580314058
Epoch: 43 Idx: 0 Loss: 0.013296078016759104
Epoch: 43 Idx: 5000 Loss: 0.020761014717307853
Epoch: 44 Idx: 0 Loss: 0.01924314286605757
Epoch: 44 Idx: 5000 Loss: 0.03267532592805897
Epoch: 45 Idx: 0 Loss: 0.01534386157941313
Epoch: 45 Idx: 5000 Loss: 0.018859602775160644
Epoch: 46 Idx: 0 Loss: 0.01808850157132937
Epoch: 46 Idx: 5000 Loss: 0.02496678673050353
Epoch: 47 Idx: 0 Loss: 0.033989937699573515
Epoch: 47 Idx: 5000 Loss: 0.028816204734489023
Epoch: 48 Idx: 0 Loss: 0.01137253589850087
Epoch: 48 Idx: 5000 Loss: 0.01304561444922192
Epoch: 49 Idx: 0 Loss: 0.010818201010092416
Epoch: 49 Idx: 5000 Loss: 0.025460504832038166
Len (direct inputs):  116
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
dTraining size: 1Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.16509847637911756
Epoch: 0 Idx: 5000 Loss: 0.03046308150551226
Epoch: 1 Idx: 0 Loss: 0.023185354249719896
Epoch: 1 Idx: 5000 Loss: 0.03663208890946474
Epoch: 2 Idx: 0 Loss: 0.0245194986855758
Epoch: 2 Idx: 5000 Loss: 0.012086764563563952
Epoch: 3 Idx: 0 Loss: 0.010688825233467944
Epoch: 3 Idx: 5000 Loss: 0.031195182774004154
Epoch: 4 Idx: 0 Loss: 0.022830238488287517
Epoch: 4 Idx: 5000 Loss: 0.02029508270973241
Epoch: 5 Idx: 0 Loss: 0.01961796055350196
Epoch: 5 Idx: 5000 Loss: 0.02213463785259746
Epoch: 6 Idx: 0 Loss: 0.023176718159536074
Epoch: 6 Idx: 5000 Loss: 0.01612530486270595
Epoch: 7 Idx: 0 Loss: 0.02022017861563493
Epoch: 7 Idx: 5000 Loss: 0.015590010713216786
Epoch: 8 Idx: 0 Loss: 0.02248643338483903
Epoch: 8 Idx: 5000 Loss: 0.022023034062729464
Epoch: 9 Idx: 0 Loss: 0.023105105684509485
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 396, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
KeyboardInterrupt
och: 13 Idx: 0 Loss: 0.015616187845047553
Epoch: 13 Idx: 5000 Loss: 0.03470622962570177
Epoch: 14 Idx: 0 Loss: 0.019787036996588257
Epoch: 14 Idx: 5000 Loss: 0.013801614679307378
Epoch: 15 Idx: 0 Loss: 0.027151896032380978
Epoch: 15 Idx: 5000 Loss: 0.019868674334507085
Epoch: 16 Idx: 0 Loss: 0.03584006480156281
Epoch: 16 Idx: 5000 Loss: 0.008503000594655492
Epoch: 17 Idx: 0 Loss: 0.03498938311897726
Epoch: 17 Idx: 5000 Loss: 0.030422598721995188
Epoch: 18 Idx: 0 Loss: 0.030515294361376143
Epoch: 18 Idx: 5000 Loss: 0.024375597429606072
Epoch: 19 Idx: 0 Loss: 0.03651097752454674
Epoch: 19 Idx: 5000 Loss: 0.023644319858091165
Epoch: 20 Idx: 0 Loss: 0.019638818871083104
Epoch: 20 Idx: 5000 Loss: 0.0381560918591127
Epoch: 21 Idx: 0 Loss: 0.017369385723069966
Epoch: 21 Idx: 5000 Loss: 0.04631636497692841
Epoch: 22 Idx: 0 Loss: 0.016037913148012433
Epoch: 22 Idx: 5000 Loss: 0.02233758279346751
Epoch: 23 Idx: 0 Loss: 0.013467302133741709
Epoch: 23 Idx: 5000 Loss: 0.01341623788889519
Epoch: 24 Idx: 0 Loss: 0.02369810352137976
Epoch: 24 Idx: 5000 Loss: 0.013536821235514565
Epoch: 25 Idx: 0 Loss: 0.019116063608047296
Epoch: 25 Idx: 5000 Loss: 0.022179011461148854
Epoch: 26 Idx: 0 Loss: 0.0374742512448831
Epoch: 26 Idx: 5000 Loss: 0.020420371478789844
Epoch: 27 Idx: 0 Loss: 0.023685163113513295
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 396, in <module>
    outputs = model(node_elems, inp_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "Attention_anatomy_aml.py", line 274, in forward
    attended_path = node_weights.unsqueeze(-1) * best_path # batch_size * 4 * max_pathlen * 512
KeyboardInterrupt
7680017493442585
Epoch: 32 Idx: 5000 Loss: 0.013426204387583417
Epoch: 33 Idx: 0 Loss: 0.006656817906546948
Epoch: 33 Idx: 5000 Loss: 0.020546158447855817
Epoch: 34 Idx: 0 Loss: 0.016876361085961356
Epoch: 34 Idx: 5000 Loss: 0.02500574286568633
Epoch: 35 Idx: 0 Loss: 0.03123628170496466
Epoch: 35 Idx: 5000 Loss: 0.03705449806901144
Epoch: 36 Idx: 0 Loss: 0.013311870294109353
Epoch: 36 Idx: 5000 Loss: 0.04071730966612196
Epoch: 37 Idx: 0 Loss: 0.018702832847547538
Epoch: 37 Idx: 5000 Loss: 0.01266819371887218
Epoch: 38 Idx: 0 Loss: 0.013930523433470659
Epoch: 38 Idx: 5000 Loss: 0.01091331331189108
Epoch: 39 Idx: 0 Loss: 0.029768961633625246
Epoch: 39 Idx: 5000 Loss: 0.022687954279028002
Epoch: 40 Idx: 0 Loss: 0.030203163292581693
Epoch: 40 Idx: 5000 Loss: 0.02719229705913606
Epoch: 41 Idx: 0 Loss: 0.014168468239559608
Epoch: 41 Idx: 5000 Loss: 0.024480260314867164
Epoch: 42 Idx: 0 Loss: 0.01104777642337387
Epoch: 42 Idx: 5000 Loss: 0.027834387308579026
Epoch: 43 Idx: 0 Loss: 0.01835253057886277
Epoch: 43 Idx: 5000 Loss: 0.015107591262374931
Epoch: 44 Idx: 0 Loss: 0.01623238821225362
Epoch: 44 Idx: 5000 Loss: 0.022375736830705553
Epoch: 45 Idx: 0 Loss: 0.015176336323007848
Epoch: 45 Idx: 5000 Loss: 0.02513350122990233
Epoch: 46 Idx: 0 Loss: 0.01907836562869062
Epoch: 46 Idx: 5000 Loss: 0.040510419363491465
Epoch: 47 Idx: 0 Loss: 0.018896303383855832
Epoch: 47 Idx: 5000 Loss: 0.03156567391296734
Epoch: 48 Idx: 0 Loss: 0.04903862631908114
Epoch: 48 Idx: 5000 Loss: 0.019948369540134212
Epoch: 49 Idx: 0 Loss: 0.03730259974207493
Epoch: 49 Idx: 5000 Loss: 0.0227997216095514
Len (direct inputs):  106
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.18679403962959604
Epoch: 0 Idx: 5000 Loss: 0.012632109415990527
Epoch: 1 Idx: 0 Loss: 0.02209066460750011
Epoch: 1 Idx: 5000 Loss: 0.024328285048009973
Epoch: 2 Idx: 0 Loss: 0.011004130920571144
Epoch: 2 Idx: 5000 Loss: 0.027487948578918377
Epoch: 3 Idx: 0 Loss: 0.024584966821284193
Epoch: 3 Idx: 5000 Loss: 0.04353743643434588
Epoch: 4 Idx: 0 Loss: 0.030503857830288267
Epoch: 4 Idx: 5000 Loss: 0.020405840320664306
Epoch: 5 Idx: 0 Loss: 0.017585338879651066
Epoch: 5 Idx: 5000 Loss: 0.01716825134116734
Traceback (most recent call last):
  File "Attention_anatomy_aml.py", line 398, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc206>
Subject: Job 3290097: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs22_14.pkl Models/anatomy_aml_bagofnbrs22_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs22_14.pkl Models/anatomy_aml_bagofnbrs22_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc206>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:02:03 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:02:03 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 22 14 Output/test_anatomy_aml_bagofnbrs22_14.pkl Models/anatomy_aml_bagofnbrs22_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   29520.03 sec.
    Max Memory :                                 2734 MB
    Average Memory :                             2641.82 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40683.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   29805 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc278>
Subject: Job 3290109: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs80_14.pkl Models/anatomy_aml_bagofnbrs80_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs80_14.pkl Models/anatomy_aml_bagofnbrs80_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc278>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:55:04 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:55:04 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 80 14 Output/test_anatomy_aml_bagofnbrs80_14.pkl Models/anatomy_aml_bagofnbrs80_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   26561.81 sec.
    Max Memory :                                 2670 MB
    Average Memory :                             2568.92 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40747.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   26624 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc235>
Subject: Job 3290107: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs40_14.pkl Models/anatomy_aml_bagofnbrs40_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs40_14.pkl Models/anatomy_aml_bagofnbrs40_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc235>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:45:59 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:45:59 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 40 14 Output/test_anatomy_aml_bagofnbrs40_14.pkl Models/anatomy_aml_bagofnbrs40_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27134.33 sec.
    Max Memory :                                 2718 MB
    Average Memory :                             2602.74 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40699.00 MB
    Max Swap :                                   4 MB
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27195 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc253>
Subject: Job 3290099: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs24_14.pkl Models/anatomy_aml_bagofnbrs24_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs24_14.pkl Models/anatomy_aml_bagofnbrs24_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc253>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:08:02 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:08:02 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 24 14 Output/test_anatomy_aml_bagofnbrs24_14.pkl Models/anatomy_aml_bagofnbrs24_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   29435.30 sec.
    Max Memory :                                 2737 MB
    Average Memory :                             2643.16 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40680.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   29446 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc245>
Subject: Job 3290111: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs152_14.pkl Models/anatomy_aml_bagofnbrs152_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs152_14.pkl Models/anatomy_aml_bagofnbrs152_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:04 2020
Job was executed on host(s) <dccxc245>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:57:14 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:57:14 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 14 Output/test_anatomy_aml_bagofnbrs152_14.pkl Models/anatomy_aml_bagofnbrs152_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   26449.14 sec.
    Max Memory :                                 2676 MB
    Average Memory :                             2492.08 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40741.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   26494 sec.
    Turnaround time :                            80684 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc245>
Subject: Job 3290105: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs32_14.pkl Models/anatomy_aml_bagofnbrs32_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs32_14.pkl Models/anatomy_aml_bagofnbrs32_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc245>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:41:56 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:41:56 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 32 14 Output/test_anatomy_aml_bagofnbrs32_14.pkl Models/anatomy_aml_bagofnbrs32_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27408.53 sec.
    Max Memory :                                 2722 MB
    Average Memory :                             2619.27 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40695.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27416 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc238>
Subject: Job 3290103: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs30_14.pkl Models/anatomy_aml_bagofnbrs30_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs30_14.pkl Models/anatomy_aml_bagofnbrs30_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc238>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:39:06 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:39:06 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 30 14 Output/test_anatomy_aml_bagofnbrs30_14.pkl Models/anatomy_aml_bagofnbrs30_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27513.16 sec.
    Max Memory :                                 2724 MB
    Average Memory :                             2629.26 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40693.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27582 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc254>
Subject: Job 3290095: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs20_14.pkl Models/anatomy_aml_bagofnbrs20_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs20_14.pkl Models/anatomy_aml_bagofnbrs20_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc254>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:55:45 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:55:45 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 20 14 Output/test_anatomy_aml_bagofnbrs20_14.pkl Models/anatomy_aml_bagofnbrs20_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30097.92 sec.
    Max Memory :                                 2731 MB
    Average Memory :                             2649.21 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40686.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   30183 sec.
    Turnaround time :                            80685 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc265>
Subject: Job 3290089: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs12_14.pkl Models/anatomy_aml_bagofnbrs12_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs12_14.pkl Models/anatomy_aml_bagofnbrs12_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc265>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:36:09 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:36:09 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 12 14 Output/test_anatomy_aml_bagofnbrs12_14.pkl Models/anatomy_aml_bagofnbrs12_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   31256.77 sec.
    Max Memory :                                 2733 MB
    Average Memory :                             2660.67 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40684.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   31360 sec.
    Turnaround time :                            80687 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 3290101: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs26_14.pkl Models/anatomy_aml_bagofnbrs26_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs26_14.pkl Models/anatomy_aml_bagofnbrs26_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 04:34:44 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 04:34:44 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 26 14 Output/test_anatomy_aml_bagofnbrs26_14.pkl Models/anatomy_aml_bagofnbrs26_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27796.55 sec.
    Max Memory :                                 2723 MB
    Average Memory :                             2631.06 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40694.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   27844 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc244>
Subject: Job 3290093: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs18_14.pkl Models/anatomy_aml_bagofnbrs18_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs18_14.pkl Models/anatomy_aml_bagofnbrs18_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc244>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:53:03 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:53:03 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 18 14 Output/test_anatomy_aml_bagofnbrs18_14.pkl Models/anatomy_aml_bagofnbrs18_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30275.34 sec.
    Max Memory :                                 2730 MB
    Average Memory :                             2655.78 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40687.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   30346 sec.
    Turnaround time :                            80686 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc201>
Subject: Job 3290087: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs10_14.pkl Models/anatomy_aml_bagofnbrs10_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs10_14.pkl Models/anatomy_aml_bagofnbrs10_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:02 2020
Job was executed on host(s) <dccxc201>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:31:41 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:31:41 2020
Terminated at Wed Sep  2 12:18:49 2020
Results reported at Wed Sep  2 12:18:49 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 10 14 Output/test_anatomy_aml_bagofnbrs10_14.pkl Models/anatomy_aml_bagofnbrs10_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   31586.63 sec.
    Max Memory :                                 2743 MB
    Average Memory :                             2669.42 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40674.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   31628 sec.
    Turnaround time :                            80687 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc233>
Subject: Job 3290091: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs15_14.pkl Models/anatomy_aml_bagofnbrs15_14.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs15_14.pkl Models/anatomy_aml_bagofnbrs15_14.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:54:03 2020
Job was executed on host(s) <dccxc233>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Wed Sep  2 03:45:38 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Wed Sep  2 03:45:38 2020
Terminated at Wed Sep  2 12:18:50 2020
Results reported at Wed Sep  2 12:18:50 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml.py Input/data_anatomy_oaei_bagofnbrs.pkl 15 14 Output/test_anatomy_aml_bagofnbrs15_14.pkl Models/anatomy_aml_bagofnbrs15_14.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30783.00 sec.
    Max Memory :                                 2737 MB
    Average Memory :                             2658.77 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40680.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                9
    Run time :                                   30791 sec.
    Turnaround time :                            80687 sec.

The output (if any) is above this job summary.

