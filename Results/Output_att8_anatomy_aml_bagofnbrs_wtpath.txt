Max number of nodes in a path: Input/data_anatomy_oaei_bagofnbrs.pkl
Number of entities: 150000
Training size: 127500 Validation size: 22500
Epoch: 0 Idx: 0 Loss: 0.22546342892921886
Epoch: 0 Idx: 5000 Loss: 0.022792535702598652
Epoch: 1 Idx: 0 Loss: 0.016799149042208986
Epoch: 1 Idx: 5000 Loss: 0.026827131690374942
Epoch: 2 Idx: 0 Loss: 0.023663373749990516
Epoch: 2 Idx: 5000 Loss: 0.0198677582706987
Epoch: 3 Idx: 0 Loss: 0.02736428474601828
Epoch: 3 Idx: 5000 Loss: 0.013032986019856738
Epoch: 4 Idx: 0 Loss: 0.014398892940005716
Epoch: 4 Idx: 5000 Loss: 0.01943027547348327
Epoch: 5 Idx: 0 Loss: 0.01586201658780421
Epoch: 5 Idx: 5000 Loss: 0.02261849750013492
Epoch: 6 Idx: 0 Loss: 0.01619326973430779
Epoch: 6 Idx: 5000 Loss: 0.01728961153823693
Epoch: 7 Idx: 0 Loss: 0.009727771574471779
Epoch: 7 Idx: 5000 Loss: 0.026778477649114847
Epoch: 8 Idx: 0 Loss: 0.0141712555506209
Epoch: 8 Idx: 5000 Loss: 0.0162683361221213
Epoch: 9 Idx: 0 Loss: 0.030851322089744285
Epoch: 9 Idx: 5000 Loss: 0.02192006174249264
Epoch: 10 Idx: 0 Loss: 0.03382818011185641
Epoch: 10 Idx: 5000 Loss: 0.026017958287279826
Epoch: 11 Idx: 0 Loss: 0.016248761257279063
Epoch: 11 Idx: 5000 Loss: 0.023128092944999987
Epoch: 12 Idx: 0 Loss: 0.01823081955903571
Epoch: 12 Idx: 5000 Loss: 0.020569081147164308
Epoch: 13 Idx: 0 Loss: 0.012324957972727413
Epoch: 13 Idx: 5000 Loss: 0.02218746698640294
Epoch: 14 Idx: 0 Loss: 0.009819588567820926
Epoch: 14 Idx: 5000 Loss: 0.025382209566769943
Epoch: 15 Idx: 0 Loss: 0.01756394107330516
Epoch: 15 Idx: 5000 Loss: 0.0250156755009776
Epoch: 16 Idx: 0 Loss: 0.02288902904856356
Epoch: 16 Idx: 5000 Loss: 0.023995069646294553
Epoch: 17 Idx: 0 Loss: 0.019926987864257523
Epoch: 17 Idx: 5000 Loss: 0.03326031352937197
Epoch: 18 Idx: 0 Loss: 0.013967588560204396
Epoch: 18 Idx: 5000 Loss: 0.016091435659302877
Epoch: 19 Idx: 0 Loss: 0.018231272039060886
Epoch: 19 Idx: 5000 Loss: 0.01884933781748421
Epoch: 20 Idx: 0 Loss: 0.01880552396426651
Epoch: 20 Idx: 5000 Loss: 0.013315848753721401
Epoch: 21 Idx: 0 Loss: 0.020573357785528615
Epoch: 21 Idx: 5000 Loss: 0.01750646496843844
Epoch: 22 Idx: 0 Loss: 0.018626415244572907
Epoch: 22 Idx: 5000 Loss: 0.02381153720709
Epoch: 23 Idx: 0 Loss: 0.029953344744795538
Epoch: 23 Idx: 5000 Loss: 0.01347872849560262
Epoch: 24 Idx: 0 Loss: 0.012907960162933307
Epoch: 24 Idx: 5000 Loss: 0.011338227634001871
Epoch: 25 Idx: 0 Loss: 0.03867643014857068
Epoch: 25 Idx: 5000 Loss: 0.017817795145688327
Epoch: 26 Idx: 0 Loss: 0.02703795010240396
Epoch: 26 Idx: 5000 Loss: 0.031107998545106687
Epoch: 27 Idx: 0 Loss: 0.021961026349825975
Epoch: 27 Idx: 5000 Loss: 0.015218657130014572
Epoch: 28 Idx: 0 Loss: 0.01566301699955148
Epoch: 28 Idx: 5000 Loss: 0.020939608322819173
Epoch: 29 Idx: 0 Loss: 0.020407160782537768
Epoch: 29 Idx: 5000 Loss: 0.017019306564907723
Epoch: 30 Idx: 0 Loss: 0.02726912837068192
Epoch: 30 Idx: 5000 Loss: 0.021917159420101345
Epoch: 31 Idx: 0 Loss: 0.0323260726919473
Epoch: 31 Idx: 5000 Loss: 0.02439231370036318
Epoch: 32 Idx: 0 Loss: 0.027360860567250213
Epoch: 32 Idx: 5000 Loss: 0.01837577478020819
Epoch: 33 Idx: 0 Loss: 0.023648987505617714
Epoch: 33 Idx: 5000 Loss: 0.03558361449429773
Epoch: 34 Idx: 0 Loss: 0.022301888702788306
Epoch: 34 Idx: 5000 Loss: 0.014493806758062763
Epoch: 35 Idx: 0 Loss: 0.035112654457336856
Epoch: 35 Idx: 5000 Loss: 0.020922296856325122
Epoch: 36 Idx: 0 Loss: 0.028019830651703506
Epoch: 36 Idx: 5000 Loss: 0.01504112473418701
Epoch: 37 Idx: 0 Loss: 0.038608473311604816
Epoch: 37 Idx: 5000 Loss: 0.011668616204640705
Epoch: 38 Idx: 0 Loss: 0.026903569060933195
Epoch: 38 Idx: 5000 Loss: 0.027077516757379003
Epoch: 39 Idx: 0 Loss: 0.013397544948258027
Epoch: 39 Idx: 5000 Loss: 0.022853517136561703
Epoch: 40 Idx: 0 Loss: 0.010026152926423726
Epoch: 40 Idx: 5000 Loss: 0.01595947778843083
Epoch: 41 Idx: 0 Loss: 0.02058766560071152
Epoch: 41 Idx: 5000 Loss: 0.019545669743779068
Epoch: 42 Idx: 0 Loss: 0.017224717068577665
Traceback (most recent call last):
  File "Attention_anatomy_aml_weighted.py", line 399, in <module>
    loss = F.mse_loss(outputs, targ_elems)
  File "/u/harshitk/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 2190, in mse_loss
    ret = torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <rer@dccxc251>
Subject: Job 3289992: </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 8 Output/test_anatomy_aml_bagofnbrs_wtpath152_8.pkl Models/anatomy_aml_bagofnbrs_wtpath152_8.pt> in cluster <dcc> Exited

Job </u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 8 Output/test_anatomy_aml_bagofnbrs_wtpath152_8.pkl Models/anatomy_aml_bagofnbrs_wtpath152_8.pt> was submitted from host <dccxl001> by user <harshitk> in cluster <dcc> at Tue Sep  1 13:53:56 2020
Job was executed on host(s) <dccxc251>, in queue <x86_24h>, as user <harshitk> in cluster <dcc> at Tue Sep  1 22:16:37 2020
</u/harshitk> was used as the home directory.
</dccstor/cogfin/arvind/da/IBM-Internship> was used as the working directory.
Started at Tue Sep  1 22:16:37 2020
Terminated at Wed Sep  2 12:18:48 2020
Results reported at Wed Sep  2 12:18:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/u/harshitk/anaconda2/envs/myenv/bin/python3.6 Attention_anatomy_aml_weighted.py Input/data_anatomy_oaei_bagofnbrs.pkl 152 8 Output/test_anatomy_aml_bagofnbrs_wtpath152_8.pkl Models/anatomy_aml_bagofnbrs_wtpath152_8.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   50432.55 sec.
    Max Memory :                                 2676 MB
    Average Memory :                             2590.63 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               40741.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   50531 sec.
    Turnaround time :                            80692 sec.

The output (if any) is above this job summary.

