Number of neighbours: Input/data_conf_oaei_german.pkl
Number of entities: 130000
Training size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.2270351296654681
Epoch: 1 Idx: 0 Loss: 0.019047242647675874
Epoch: 2 Idx: 0 Loss: 0.01765077557414025
Epoch: 3 Idx: 0 Loss: 0.013448099268218121
Epoch: 4 Idx: 0 Loss: 0.04251295821627498
Epoch: 5 Idx: 0 Loss: 0.012246635908227988
Epoch: 6 Idx: 0 Loss: 0.016186548635833513
Epoch: 7 Idx: 0 Loss: 0.016106517467462573
Epoch: 8 Idx: 0 Loss: 0.006733054195954247
Epoch: 9 Idx: 0 Loss: 0.03177647127150246
Epoch: 10 Idx: 0 Loss: 0.00774351287488008
Epoch: 11 Idx: 0 Loss: 0.015176340965563055
Epoch: 12 Idx: 0 Loss: 0.013727695282593235
Epoch: 13 Idx: 0 Loss: 0.031719366944674185
Epoch: 14 Idx: 0 Loss: 0.010431305312995654
Epoch: 15 Idx: 0 Loss: 0.01129921825818794
Epoch: 16 Idx: 0 Loss: 0.01727851249325593
Epoch: 17 Idx: 0 Loss: 0.010010517250280973
Epoch: 18 Idx: 0 Loss: 0.02035731033689828
Epoch: 19 Idx: 0 Loss: 0.01614255912278053
Epoch: 20 Idx: 0 Loss: 0.03140920587141055
Epoch: 21 Idx: 0 Loss: 0.03571929198649755
Epoch: 22 Idx: 0 Loss: 0.018778182531313616
Epoch: 23 Idx: 0 Loss: 0.035240000230036116
Epoch: 24 Idx: 0 Loss: 0.01410070162947406
Epoch: 25 Idx: 0 Loss: 0.013890649480108277
Epoch: 26 Idx: 0 Loss: 0.008767210109974981
Epoch: 27 Idx: 0 Loss: 0.005151749207643943
Epoch: 28 Idx: 0 Loss: 0.025592108716459647
Epoch: 29 Idx: 0 Loss: 0.025665336765474122
Epoch: 30 Idx: 0 Loss: 0.011641560888427018
Epoch: 31 Idx: 0 Loss: 0.008683349978876593
Epoch: 32 Idx: 0 Loss: 0.01805582018605315
Epoch: 33 Idx: 0 Loss: 0.003927012881632763
Epoch: 34 Idx: 0 Loss: 0.013397578179426243
Epoch: 35 Idx: 0 Loss: 0.014972406010834402
Epoch: 36 Idx: 0 Loss: 0.01124400262375307
Epoch: 37 Idx: 0 Loss: 0.04120838065555058
Epoch: 38 Idx: 0 Loss: 0.01237773989978238
Epoch: 39 Idx: 0 Loss: 0.009536557526931678
Epoch: 40 Idx: 0 Loss: 0.03285360818318061
Epoch: 41 Idx: 0 Loss: 0.011640386458275266
Epoch: 42 Idx: 0 Loss: 0.00854972930031832
Epoch: 43 Idx: 0 Loss: 0.030780372542325837
Epoch: 44 Idx: 0 Loss: 0.02085530202264326
Epoch: 45 Idx: 0 Loss: 0.031041795924325447
Epoch: 46 Idx: 0 Loss: 0.01270200095960356
Epoch: 47 Idx: 0 Loss: 0.05298849151177777
Epoch: 48 Idx: 0 Loss: 0.02442525264849781
Epoch: 49 Idx: 0 Loss: 0.018690285451721057
Len (direct inputs):  3905
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zerTrTraining size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.24156992420510498
Epoch: 1 Idx: 0 Loss: 0.017805556967507585
Epoch: 2 Idx: 0 Loss: 0.016587063376637644
Epoch: 3 Idx: 0 Loss: 0.050248087948672346
Epoch: 4 Idx: 0 Loss: 0.01931830858443728
Epoch: 5 Idx: 0 Loss: 0.010681669416338965
Epoch: 6 Idx: 0 Loss: 0.027079668746154365
Epoch: 7 Idx: 0 Loss: 0.015704645138883557
Epoch: 8 Idx: 0 Loss: 0.03502219175091574
Epoch: 9 Idx: 0 Loss: 0.020208097459996285
Epoch: 10 Idx: 0 Loss: 0.02469040235517248
Epoch: 11 Idx: 0 Loss: 0.009045199909364547
Epoch: 12 Idx: 0 Loss: 0.03271652035933198
Epoch: 13 Idx: 0 Loss: 0.03588075279475258
Epoch: 14 Idx: 0 Loss: 0.03300821069382582
Epoch: 15 Idx: 0 Loss: 0.007062928576561996
Epoch: 16 Idx: 0 Loss: 0.01727931087921339
Epoch: 17 Idx: 0 Loss: 0.008787870818658741
Epoch: 18 Idx: 0 Loss: 0.02315955467975802
Epoch: 19 Idx: 0 Loss: 0.007394662993443277
Epoch: 20 Idx: 0 Loss: 0.01678189823027328
Epoch: 21 Idx: 0 Loss: 0.0114348371349897
Epoch: 22 Idx: 0 Loss: 0.03159195274077542
Epoch: 23 Idx: 0 Loss: 0.009535440180168496
Epoch: 24 Idx: 0 Loss: 0.03814275112146777
Epoch: 25 Idx: 0 Loss: 0.02888245403176901
Epoch: 26 Idx: 0 Loss: 0.013453411407402877
Epoch: 27 Idx: 0 Loss: 0.005471439581647416
Epoch: 28 Idx: 0 Loss: 0.01059450220795374
Epoch: 29 Idx: 0 Loss: 0.022249740756717862
Epoch: 30 Idx: 0 Loss: 0.013064409134186255
Epoch: 31 Idx: 0 Loss: 0.015622953740057437
Epoch: 32 Idx: 0 Loss: 0.008236425941339888
Epoch: 33 Idx: 0 Loss: 0.013631167066899524
Epoch: 34 Idx: 0 Loss: 0.014935882490713339
Epoch: 35 Idx: 0 Loss: 0.010073163324496606
Epoch: 36 Idx: 0 Loss: 0.008745114481887382
Epoch: 37 Idx: 0 Loss: 0.009982741299221939
Epoch: 38 Idx: 0 Loss: 0.01553354186261676
Epoch: 39 Idx: 0 Loss: 0.01657054722189535
Epoch: 40 Idx: 0 Loss: 0.010429818442749608
Epoch: 41 Idx: 0 Loss: 0.012781401741967497
Epoch: 42 Idx: 0 Loss: 0.03347943530370655
Epoch: 43 Idx: 0 Loss: 0.011494419465101414
Epoch: 44 Idx: 0 Loss: 0.00785813323499758
Epoch: 45 Idx: 0 Loss: 0.014737863489436592
Epoch: 46 Idx: 0 Loss: 0.012692545163671569
Epoch: 47 Idx: 0 Loss: 0.029970531856068836
Epoch: 48 Idx: 0 Loss: 0.012397970764304381
Epoch: 49 Idx: 0 Loss: 0.03401757109343706
Len (direct inputs):  3955
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Training size: 110501 Val size: 19499
Epoch: 0 Idx: 0 Loss: 0.10642780718651784
Epoch: 1 Idx: 0 Loss: 0.012624940378470919
Epoch: 2 Idx: 0 Loss: 0.046752279023594474
Epoch: 3 Idx: 0 Loss: 0.014668851826976647
Epoch: 4 Idx: 0 Loss: 0.0250478885215968
Epoch: 5 Idx: 0 Loss: 0.018904908228408013
Epoch: 6 Idx: 0 Loss: 0.03154962795135145
Epoch: 7 Idx: 0 Loss: 0.020707473788240807
Epoch: 8 Idx: 0 Loss: 0.020481734863452877
Epoch: 9 Idx: 0 Loss: 0.012590404877913231
Epoch: 10 Idx: 0 Loss: 0.015599818625531538
Epoch: 11 Idx: 0 Loss: 0.015945541534365823
Epoch: 12 Idx: 0 Loss: 0.023625766332560878
Epoch: 13 Idx: 0 Loss: 0.02822925593280465
Epoch: 14 Idx: 0 Loss: 0.017819920670298202
Epoch: 15 Idx: 0 Loss: 0.009051119873370103
Epoch: 16 Idx: 0 Loss: 0.013899233258001844
Epoch: 17 Idx: 0 Loss: 0.024249313214113784
Epoch: 18 Idx: 0 Loss: 0.030483523969509534
Epoch: 19 Idx: 0 Loss: 0.013507476476976608
Epoch: 20 Idx: 0 Loss: 0.015621541363425131
Epoch: 21 Idx: 0 Loss: 0.011877505394644449
Epoch: 22 Idx: 0 Loss: 0.01737511802346263
Epoch: 23 Idx: 0 Loss: 0.023513439063225172
Epoch: 24 Idx: 0 Loss: 0.032388225587948745
Epoch: 25 Idx: 0 Loss: 0.018567140685401988
Epoch: 26 Idx: 0 Loss: 0.010022828617241488
Epoch: 27 Idx: 0 Loss: 0.02932313728943317
Epoch: 28 Idx: 0 Loss: 0.008987175840436804
Epoch: 29 Idx: 0 Loss: 0.02482706556913994
Epoch: 30 Idx: 0 Loss: 0.02936539470932562
Epoch: 31 Idx: 0 Loss: 0.020925455334181692
Epoch: 32 Idx: 0 Loss: 0.023300268682544468
Epoch: 33 Idx: 0 Loss: 0.023335380412703065
Epoch: 34 Idx: 0 Loss: 0.0467975035254646
Epoch: 35 Idx: 0 Loss: 0.018911868402610173
Epoch: 36 Idx: 0 Loss: 0.043620832674304666
Epoch: 37 Idx: 0 Loss: 0.05840323489411828
Epoch: 38 Idx: 0 Loss: 0.017292397612511078
Epoch: 39 Idx: 0 Loss: 0.03523600029671591
Epoch: 40 Idx: 0 Loss: 0.005346210225963807
Epoch: 41 Idx: 0 Loss: 0.010390496310762283
Epoch: 42 Idx: 0 Loss: 0.03359702771538373
Epoch: 43 Idx: 0 Loss: 0.01838358268646233
Epoch: 44 Idx: 0 Loss: 0.010570952738245312
Epoch: 45 Idx: 0 Loss: 0.04029039855231563
Epoch: 46 Idx: 0 Loss: 0.012753148075740106
Epoch: 47 Idx: 0 Loss: 0.017919410615886082
Epoch: 48 Idx: 0 Loss: 0.02351967708641517
Epoch: 49 Idx: 0 Loss: 0.029134391068795003
Len (direct inputs):  3835
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by TrainTraining size: 110499 Val size: 19501
Epoch: 0 Idx: 0 Loss: 0.2673241648355527
Epoch: 1 Idx: 0 Loss: 0.025464002134905666
Epoch: 2 Idx: 0 Loss: 0.007552470059376752
Epoch: 3 Idx: 0 Loss: 0.027036059893764834
Epoch: 4 Idx: 0 Loss: 0.017073132561848614
Epoch: 5 Idx: 0 Loss: 0.033321778069582544
Epoch: 6 Idx: 0 Loss: 0.03616226445510754
Epoch: 7 Idx: 0 Loss: 0.006192333127309779
Epoch: 8 Idx: 0 Loss: 0.01683806117626237
Epoch: 9 Idx: 0 Loss: 0.013705480787799113
Epoch: 10 Idx: 0 Loss: 0.02309356494648642
Epoch: 11 Idx: 0 Loss: 0.012640083551585735
Epoch: 12 Idx: 0 Loss: 0.018696091091937123
Epoch: 13 Idx: 0 Loss: 0.05481143393570178
Epoch: 14 Idx: 0 Loss: 0.028875195341873106
Epoch: 15 Idx: 0 Loss: 0.04070123883897958
Epoch: 16 Idx: 0 Loss: 0.015820779247807563
Epoch: 17 Idx: 0 Loss: 0.012407553254562864
Epoch: 18 Idx: 0 Loss: 0.017451106694018476
Epoch: 19 Idx: 0 Loss: 0.025967309310978674
Epoch: 20 Idx: 0 Loss: 0.012892003719637377
Epoch: 21 Idx: 0 Loss: 0.029646537836883702
Epoch: 22 Idx: 0 Loss: 0.012456091765199346
Epoch: 23 Idx: 0 Loss: 0.017127866017215547
Epoch: 24 Idx: 0 Loss: 0.014968230738237252
Epoch: 25 Idx: 0 Loss: 0.031893481471620466
Epoch: 26 Idx: 0 Loss: 0.013287593945830463
Epoch: 27 Idx: 0 Loss: 0.006337403850155791
Epoch: 28 Idx: 0 Loss: 0.02378896613651652
Epoch: 29 Idx: 0 Loss: 0.012722833176346506
Epoch: 30 Idx: 0 Loss: 0.017957499695133536
Epoch: 31 Idx: 0 Loss: 0.012315970842109981
Epoch: 32 Idx: 0 Loss: 0.01540659123071824
Epoch: 33 Idx: 0 Loss: 0.04817474995517977
Epoch: 34 Idx: 0 Loss: 0.05295790078752691
Epoch: 35 Idx: 0 Loss: 0.018490148282453545
Epoch: 36 Idx: 0 Loss: 0.0408139223645891
Epoch: 37 Idx: 0 Loss: 0.010682995634417299
Epoch: 38 Idx: 0 Loss: 0.013877620131173121
Epoch: 39 Idx: 0 Loss: 0.03341163143127774
Epoch: 40 Idx: 0 Loss: 0.012190265119112628
Epoch: 41 Idx: 0 Loss: 0.021725439526575567
Epoch: 42 Idx: 0 Loss: 0.034987944772226005
Epoch: 43 Idx: 0 Loss: 0.006244101238656659
Epoch: 44 Idx: 0 Loss: 0.011897322243987204
Epoch: 45 Idx: 0 Loss: 0.013152984199344997
Epoch: 46 Idx: 0 Loss: 0.007600241809048945
Epoch: 47 Idx: 0 Loss: 0.019919450181080225
Epoch: 48 Idx: 0 Loss: 0.007196279611979386
Epoch: 49 Idx: 0 Loss: 0.01228298175295229
Len (direct inputs):  3790
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Training size: 110500 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.21710438207107932
Epoch: 1 Idx: 0 Loss: 0.013087632173768798
Epoch: 2 Idx: 0 Loss: 0.00965745275911965
Epoch: 3 Idx: 0 Loss: 0.011798144663999222
Epoch: 4 Idx: 0 Loss: 0.03570589240209206
Epoch: 5 Idx: 0 Loss: 0.020450807529088143
Epoch: 6 Idx: 0 Loss: 0.012517361542072569
Epoch: 7 Idx: 0 Loss: 0.027938326531124182
Epoch: 8 Idx: 0 Loss: 0.012489665042041565
Epoch: 9 Idx: 0 Loss: 0.025916282350158738
Epoch: 10 Idx: 0 Loss: 0.021283076316969237
Epoch: 11 Idx: 0 Loss: 0.032976794435051845
Epoch: 12 Idx: 0 Loss: 0.03540640547509104
Epoch: 13 Idx: 0 Loss: 0.013802980599110913
Epoch: 14 Idx: 0 Loss: 0.015296284757736686
Epoch: 15 Idx: 0 Loss: 0.011516391099979439
Epoch: 16 Idx: 0 Loss: 0.0326744814937904
Epoch: 17 Idx: 0 Loss: 0.015684825341812456
Epoch: 18 Idx: 0 Loss: 0.03920709886431004
Epoch: 19 Idx: 0 Loss: 0.014397530172133344
Epoch: 20 Idx: 0 Loss: 0.029116689304349255
Epoch: 21 Idx: 0 Loss: 0.012397363081215751
Epoch: 22 Idx: 0 Loss: 0.026098023045180788
Epoch: 23 Idx: 0 Loss: 0.0214124687159485
Epoch: 24 Idx: 0 Loss: 0.007454211974070372
Epoch: 25 Idx: 0 Loss: 0.014118503470116082
Epoch: 26 Idx: 0 Loss: 0.04084490235287987
Epoch: 27 Idx: 0 Loss: 0.0079440873430696
Epoch: 28 Idx: 0 Loss: 0.04092230989882032
Epoch: 29 Idx: 0 Loss: 0.030659060954194295
Epoch: 30 Idx: 0 Loss: 0.014494973140937046
Epoch: 31 Idx: 0 Loss: 0.03635376330889455
Epoch: 32 Idx: 0 Loss: 0.012196941673500074
Epoch: 33 Idx: 0 Loss: 0.02596250105507105
Epoch: 34 Idx: 0 Loss: 0.007584007375822494
Epoch: 35 Idx: 0 Loss: 0.014792379349132275
Epoch: 36 Idx: 0 Loss: 0.013029282233834757
Epoch: 37 Idx: 0 Loss: 0.018238379997833596
Epoch: 38 Idx: 0 Loss: 0.02513633938962747
Epoch: 39 Idx: 0 Loss: 0.044686145357737794
Epoch: 40 Idx: 0 Loss: 0.012802156952307443
Epoch: 41 Idx: 0 Loss: 0.013338840865244221
Epoch: 42 Idx: 0 Loss: 0.010129625078220229
Epoch: 43 Idx: 0 Loss: 0.00865352579157887
Epoch: 44 Idx: 0 Loss: 0.02364710864361677
Epoch: 45 Idx: 0 Loss: 0.04391581513809744
Epoch: 46 Idx: 0 Loss: 0.03378723358411922
Epoch: 47 Idx: 0 Loss: 0.010766714884864161
Epoch: 48 Idx: 0 Loss: 0.03486908831539665
Epoch: 49 Idx: 0 Loss: 0.016844957881025063
Len (direct inputs):  3879
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
Training size: 110501 Val size: 19500
Epoch: 0 Idx: 0 Loss: 0.16792831799486246
Epoch: 1 Idx: 0 Loss: 0.016268268868174837
Epoch: 2 Idx: 0 Loss: 0.023322827402596225
Epoch: 3 Idx: 0 Loss: 0.02691004677973914
Epoch: 4 Idx: 0 Loss: 0.016794644527047747
Epoch: 5 Idx: 0 Loss: 0.015368714223490246
Epoch: 6 Idx: 0 Loss: 0.01729187374710503
Epoch: 7 Idx: 0 Loss: 0.013861819140404475
Epoch: 8 Idx: 0 Loss: 0.005544679879551595
Epoch: 9 Idx: 0 Loss: 0.015249140870915102
Epoch: 10 Idx: 0 Loss: 0.038142489531515326
Epoch: 11 Idx: 0 Loss: 0.019568685695115058
Epoch: 12 Idx: 0 Loss: 0.02126914025949003
Epoch: 13 Idx: 0 Loss: 0.036881068823146464
Epoch: 14 Idx: 0 Loss: 0.029305623389258233
Epoch: 15 Idx: 0 Loss: 0.018164281303340954
Epoch: 16 Idx: 0 Loss: 0.012540453133328456
Epoch: 17 Idx: 0 Loss: 0.015598618623348638
Epoch: 18 Idx: 0 Loss: 0.022171769285670273
Epoch: 19 Idx: 0 Loss: 0.015827145116506205
Epoch: 20 Idx: 0 Loss: 0.02529406678321303
Epoch: 21 Idx: 0 Loss: 0.019440835152029944
Epoch: 22 Idx: 0 Loss: 0.012583133705360225
Epoch: 23 Idx: 0 Loss: 0.014512866619746316
Epoch: 24 Idx: 0 Loss: 0.013845677153142923
Epoch: 25 Idx: 0 Loss: 0.011304296796199424
Epoch: 26 Idx: 0 Loss: 0.012342428295148106
Epoch: 27 Idx: 0 Loss: 0.012610938035515388
Epoch: 28 Idx: 0 Loss: 0.020864141177579242
Epoch: 29 Idx: 0 Loss: 0.005006722448143135
Epoch: 30 Idx: 0 Loss: 0.034276918170741175
Epoch: 31 Idx: 0 Loss: 0.03821660240449042
Epoch: 32 Idx: 0 Loss: 0.014841922161589256
Epoch: 33 Idx: 0 Loss: 0.02355498913256046
Epoch: 34 Idx: 0 Loss: 0.006668164735892708
Epoch: 35 Idx: 0 Loss: 0.014000222885801494
Epoch: 36 Idx: 0 Loss: 0.012935920965645494
Epoch: 37 Idx: 0 Loss: 0.036314416996659306
Epoch: 38 Idx: 0 Loss: 0.013414182718323757
Epoch: 39 Idx: 0 Loss: 0.029548447729010597
Epoch: 40 Idx: 0 Loss: 0.011551947387372355
Epoch: 41 Idx: 0 Loss: 0.027037978259478727
Epoch: 42 Idx: 0 Loss: 0.012819780431561978
Epoch: 43 Idx: 0 Loss: 0.010535588693463964
Epoch: 44 Idx: 0 Loss: 0.02779360267398488
Epoch: 45 Idx: 0 Loss: 0.02389392052000417
Epoch: 46 Idx: 0 Loss: 0.028392027559249168
Epoch: 47 Idx: 0 Loss: 0.030034695993528426
Epoch: 48 Idx: 0 Loss: 0.018533684111012853
Epoch: 49 Idx: 0 Loss: 0.037621101509080476
Len (direct inputs):  3825
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division by zero
division bEEpoch:Epoch: 0 Idx: 0 Loss: 0.2739154487993167
Epoch: 1 Idx: 0 Loss: 0.01194154434423765
Epoch: 2 Idx: 0 Loss: 0.040811361117227815
Epoch: 3 Idx: 0 Loss: 0.012923186500174778
Epoch: 4 Idx: 0 Loss: 0.0210147029061847
Epoch: 5 Idx: 0 Loss: 0.024658537553571593
Epoch: 6 Idx: 0 Loss: 0.026764355481502265
Epoch: 7 Idx: 0 Loss: 0.00455128491350661
Epoch: 8 Idx: 0 Loss: 0.031045921592773168
Epoch: 9 Idx: 0 Loss: 0.024523915471859767
Epoch: 10 Idx: 0 Loss: 0.013801441766257463
Epoch: 11 Idx: 0 Loss: 0.025168318435950802
Epoch: 12 Idx: 0 Loss: 0.021003827200652535
Epoch: 13 Idx: 0 Loss: 0.012727603432561602
Epoch: 14 Idx: 0 Loss: 0.02606011481666773
Epoch: 15 Idx: 0 Loss: 0.015172625760888632
Epoch: 16 Idx: 0 Loss: 0.007486029361166688
Epoch: 17 Idx: 0 Loss: 0.019075449409629113
Epoch: 18 Idx: 0 Loss: 0.014525465968800746
Epoch: 19 Idx: 0 Loss: 0.015076235158102408
Epoch: 20 Idx: 0 Loss: 0.008628698732753348
Epoch: 21 Idx: 0 Loss: 0.029507580928738723
Epoch: 22 Idx: 0 Loss: 0.011442099148203273
Epoch: 23 Idx: 0 Loss: 0.01350791766958414
Epoch: 24 Idx: 0 Loss: 0.038421218017994425
Epoch: 25 Idx: 0 Loss: 0.011691992640771533
Epoch: 26 Idx: 0 Loss: 0.019687895912254984
Epoch: 27 Idx: 0 Loss: 0.013136608011634222
Epoch: 28 Idx: 0 Loss: 0.0363455231832271
Epoch: 29 Idx: 0 Loss: 0.016034187748400704
Epoch: 30 Idx: 0 Loss: 0.009373279940693766
Epoch: 31 Idx: 0 Loss: 0.015531682082701129
Epoch: 32 Idx: 0 Loss: 0.018870862358342462
Epoch: 33 Idx: 0 Loss: 0.018814073295422448
Epoch: 34 Idx: 0 Loss: 0.02283806604496666
Epoch: 35 Idx: 0 Loss: 0.011183084238468553
Epoch: 36 Idx: 0 Loss: 0.01732049251343696
Epoch: 37 Idx: 0 Loss: 0.028308394230108065
Epoch: 38 Idx: 0 Loss: 0.0067626976281711295
Epoch: 39 Idx: 0 Loss: 0.01297814237504849
Epoch: 40 Idx: 0 Loss: 0.016002196334640173
Epoch: 41 Idx: 0 Loss: 0.015951910164873077
Epoch: 42 Idx: 0 Loss: 0.009047298261014745
Epoch: 43 Idx: 0 Loss: 0.019635033844215298
Epoch: 44 Idx: 0 Loss: 0.030791662500637865
Epoch: 45 Idx: 0 Loss: 0.014380847295258204
Epoch: 46 Idx: 0 Loss: 0.033474521096784865
Epoch: 47 Idx: 0 Loss: 0.018104148959066216
Epoch: 48 Idx: 0 Loss: 0.017750133822799538
Epoch: 49 Idx: 0 Loss: 0.013258387125722658
Len (direct inputs):  2941
Len (direct inputs):  3848
Len (direct inputs):  2814
Len (direct inputs):  5361
Len (direct inputs):  4611
Len (direct inputs):  3971
Len (direct inputs):  4254
Performance for [('confOf', 'sigkdd'), ('iasted', 'sigkdd'), ('cmt', 'ekaw')] is : (0.00615542446781226, 1.0, 0.01223553403007902, 0.030037546933667086, 0.0076824583866837385)
Performance for [('confOf', 'iasted'), ('conference', 'edas'), ('cmt', 'sigkdd')] is : (0.005815205685978893, 1.0, 0.011563169164882228, 0.028415070511471272, 0.007258454755632023)
Performance for [('ekaw', 'sigkdd'), ('conference', 'confOf'), ('conference', 'sigkdd')] is : (0.0074337427278603745, 1.0, 0.014757779916586462, 0.03609541745134966, 0.009274941527542544)
Performance for [('confOf', 'edas'), ('cmt', 'conference'), ('edas', 'iasted')] is : (0.003448792922477133, 1.0, 0.006873879258816497, 0.017009318148202928, 0.004307277426120828)
Performance for [('conference', 'iasted'), ('edas', 'sigkdd'), ('ekaw', 'iasted')] is : (0.0029562982005141387, 1.0, 0.00589516852492631, 0.014608739837398375, 0.0036926436117265516)
Performance for [('cmt', 'edas'), ('edas', 'ekaw'), ('cmt', 'confOf')] is : (0.0060960741282614, 1.0, 0.012118274357731459, 0.029754820280885504, 0.007608497169639054)
Performance for [('confOf', 'ekaw'), ('conference', 'ekaw'), ('cmt', 'iasted')] is : (0.006984285357944624, 1.0, 0.013871686896210055, 0.03397233681145353, 0.008715139442231075)
Final Results: [0.00555569 1.         0.01104507 0.02712761 0.0069342 ]
Threshold:  0.5200329815750085
8
--------------------------------------------
Sender: LSF System <rer@dccxc229>
Subject: Job 3480269: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:18 2020
Job was executed on host(s) <dccxc229>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 18:47:52 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 18:47:52 2020
Terminated at Sat Sep  5 01:39:30 2020
Results reported at Sat Sep  5 01:39:30 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   40327.02 sec.
    Max Memory :                                 1549 MB
    Average Memory :                             1161.29 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41868.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   24703 sec.
    Turnaround time :                            84672 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc268>
Subject: Job 3480271: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:18 2020
Job was executed on host(s) <dccxc268>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 18:50:16 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 18:50:16 2020
Terminated at Sat Sep  5 01:45:17 2020
Results reported at Sat Sep  5 01:45:17 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   24895.26 sec.
    Max Memory :                                 1521 MB
    Average Memory :                             1148.67 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41896.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   24903 sec.
    Turnaround time :                            85019 sec.

The output (if any) is above this job summary.


------------------------------------------------------------
Sender: LSF System <rer@dccxc251>
Subject: Job 3480273: <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> in cluster <dcc> Done

Job <python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt> was submitted from host <dccxl009> by user <arvagarw> in cluster <dcc> at Fri Sep  4 02:08:18 2020
Job was executed on host(s) <dccxc251>, in queue <x86_24h>, as user <arvagarw> in cluster <dcc> at Fri Sep  4 18:51:21 2020
</u/arvagarw> was used as the home directory.
</u/arvagarw/arvind/IBM-Internship> was used as the working directory.
Started at Fri Sep  4 18:51:21 2020
Terminated at Sat Sep  5 01:56:57 2020
Results reported at Sat Sep  5 01:56:57 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python Attention_twostep_german_wtpath_oaei.py Input/data_conf_oaei_german.pkl 2 5 Output/test_conf_oaei_german_wtpath2_5.pkl Models/conf_oaei_german_wtpath2_5.pt
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   25495.76 sec.
    Max Memory :                                 1525 MB
    Average Memory :                             1145.01 MB
    Total Requested Memory :                     43417.00 MB
    Delta Memory :                               41892.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                7
    Run time :                                   25550 sec.
    Turnaround time :                            85719 sec.

The output (if any) is above this job summary.

