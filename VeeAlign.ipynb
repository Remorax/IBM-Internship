{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of dataset\n",
    "\n",
    "import os, itertools, time, pickle, sys\n",
    "import subprocess\n",
    "from xml.dom import minidom\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import wordnet\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil, exp\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "\n",
    "USE_folder = \"/home/vlead/USE\"\n",
    "alignment_folder = \"reference-alignment/\"\n",
    "\n",
    "# Load reference alignments \n",
    "def load_alignments(folder):\n",
    "    alignments = []\n",
    "    for f in os.listdir(folder):\n",
    "        doc = minidom.parse(folder + f)\n",
    "        ls = list(zip(doc.getElementsByTagName('entity1'), doc.getElementsByTagName('entity2')))\n",
    "        alignments.extend([(a.getAttribute('rdf:resource'), b.getAttribute('rdf:resource')) for (a,b) in ls])\n",
    "    return alignments\n",
    "        \n",
    "reference_alignments = load_alignments(alignment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "class Ontology():\n",
    "    def __init__(self, ontology):\n",
    "        self.ontology = ontology\n",
    "        self.ontology_obj = minidom.parse(ontology)\n",
    "        self.root = self.ontology_obj.documentElement\n",
    "        self.subclasses = self.parse_subclasses()\n",
    "        self.object_properties = self.parse_object_properties()\n",
    "        self.data_properties = self.parse_data_properties()\n",
    "        self.triples = self.parse_triples()\n",
    "        self.classes = self.parse_classes()\n",
    "    \n",
    "    def get_child_node(self, element, tag):\n",
    "        return [e for e in element._get_childNodes() if type(e)==minidom.Element and e._get_tagName() == tag]\n",
    "        \n",
    "    def has_attribute_value(self, element, attribute, value):\n",
    "        return True if element.getAttribute(attribute).split(\"#\")[-1] == value else False\n",
    "    \n",
    "    def get_subclass_triples(self):\n",
    "        return [(b,a,\"subclass_of\") for (a,b) in self.get_subclasses()]\n",
    "    \n",
    "    def parse_triples(self, union_flag=0, subclass_of=True):\n",
    "        obj_props = self.object_properties\n",
    "        data_props = self.data_properties\n",
    "        props = obj_props + data_props\n",
    "        all_triples = []\n",
    "        for prop in props:\n",
    "            domain_children = self.get_child_node(prop, \"rdfs:domain\")\n",
    "            range_children = self.get_child_node(prop, \"rdfs:range\")\n",
    "            domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children])\n",
    "            range_prop = self.filter_null([self.extract_ID(el) for el in range_children])\n",
    "            if not domain_children or not range_children:\n",
    "                continue\n",
    "            if not domain_prop:\n",
    "                domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if not range_prop:\n",
    "                range_prop = self.filter_null([self.extract_ID(el) for el in range_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if domain_prop and range_prop:\n",
    "                if union_flag == 0:\n",
    "                    all_triples.extend([(el[0], el[1], self.extract_ID(prop)) for el in list(itertools.product(domain_prop, range_prop))])\n",
    "                else:\n",
    "                    all_triples.append((\"###\".join(domain_prop), \"###\".join(range_prop), self.extract_ID(prop)))\n",
    "        if subclass_of:\n",
    "            all_triples.extend(self.get_subclass_triples())\n",
    "        return list(set(all_triples))\n",
    "    \n",
    "    def get_triples(self, union_flag=0, subclass_of=True, include_inv=True):\n",
    "        return self.parse_triples(union_flag, subclass_of)\n",
    "\n",
    "    def parse_subclasses(self, union_flag=0):\n",
    "        subclasses = self.root.getElementsByTagName(\"rdfs:subClassOf\")\n",
    "        subclass_pairs = []\n",
    "        for el in subclasses:\n",
    "            inline_subclasses = self.extract_ID(el)\n",
    "            if inline_subclasses:\n",
    "                subclass_pairs.append((el, el.parentNode))\n",
    "            else:\n",
    "                level1_class = self.get_child_node(el, \"owl:Class\")\n",
    "                if not level1_class:\n",
    "                    continue\n",
    "                if self.extract_ID(level1_class[0]):\n",
    "                    subclass_pairs.append((level1_class[0], el.parentNode))\n",
    "                else:\n",
    "                    level2classes = level1_class[0].getElementsByTagName(\"owl:Class\")\n",
    "                    \n",
    "                    subclass_pairs.extend([(elem, el.parentNode) for elem in level2classes if self.extract_ID(elem)])\n",
    "        return subclass_pairs\n",
    "        \n",
    "    def get_subclasses(self):\n",
    "        return [(self.extract_ID(a), self.extract_ID(b)) for (a,b) in self.subclasses]\n",
    "    \n",
    "    def filter_null(self, data):\n",
    "        return [el for el in data if el]\n",
    "    \n",
    "    def extract_ID(self, element):\n",
    "        element_id = element.getAttribute(\"rdf:ID\") or element.getAttribute(\"rdf:resource\") or element.getAttribute(\"rdf:about\")\n",
    "        return element_id.split(\"#\")[-1]\n",
    "    \n",
    "    def parse_classes(self):\n",
    "        class_elems = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        subclass_classes = list(set(flatten([el[:-1] for el in self.triples])))\n",
    "        return list(set(self.filter_null(class_elems + subclass_classes)))\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def get_entities(self):\n",
    "        entities = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        return list(set(self.filter_null(entities)))\n",
    "\n",
    "    def parse_data_properties(self):\n",
    "        data_properties = [el for el in self.get_child_node(self.root, 'owl:DatatypeProperty')]\n",
    "        fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_data_properties = [el for el in fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        inv_fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_data_properties = [el for el in inv_fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        return data_properties + fn_data_properties + inv_fn_data_properties\n",
    "        \n",
    "    def parse_object_properties(self):\n",
    "        obj_properties = [el for el in self.get_child_node(self.root, 'owl:ObjectProperty')]\n",
    "        fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_obj_properties = [el for el in fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        inv_fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_obj_properties = [el for el in inv_fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        return obj_properties + fn_obj_properties + inv_fn_obj_properties\n",
    "    \n",
    "    def get_object_properties(self):\n",
    "        obj_props = [self.extract_ID(el) for el in self.object_properties]\n",
    "        return list(set(self.filter_null(obj_props)))\n",
    "    \n",
    "    def get_data_properties(self):\n",
    "        data_props = [self.extract_ID(el) for el in self.data_properties]\n",
    "        return list(set(self.filter_null(data_props)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of extracted unique classes and properties from entire RA set:  834\n"
     ]
    }
   ],
   "source": [
    "# Extracting USE embeddings\n",
    "\n",
    "ontologies_in_alignment = [l.split(\".\")[0].split(\"-\") for l in os.listdir(\"reference-alignment/\")]\n",
    "\n",
    "def extractUSEEmbeddings(words):\n",
    "    try:\n",
    "        embed = hub.KerasLayer(USE_folder)\n",
    "    except Exception as e:\n",
    "        !mkdir $USE_folder\n",
    "        !curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\" | tar -zxvC $USE_folder\n",
    "        embed = hub.KerasLayer(USE_folder)\n",
    "        pass\n",
    "    word_embeddings = embed(words)\n",
    "    return word_embeddings.numpy()\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "def camel_case_split(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0).lower() for m in matches]\n",
    "\n",
    "def parse(word):\n",
    "    return flatten([el.split(\"_\") for el in camel_case_split(word)])\n",
    "    \n",
    "\n",
    "extracted_elems = []\n",
    "\n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    entities = ont.get_entities()\n",
    "    props = ont.get_object_properties() + ont.get_data_properties()\n",
    "    triples = list(set(flatten(ont.get_triples())))\n",
    "    extracted_elems.extend([ont_name + \"#\" + elem for elem in entities + props + triples])\n",
    "\n",
    "extracted_elems = list(set(extracted_elems))\n",
    "\n",
    "inp = [\" \".join(parse(word.split(\"#\")[1])) for word in extracted_elems]\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\S+\")\n",
    "X = vectorizer.fit_transform(inp)\n",
    "word2idx_tfidf = {word: i for (i, word)  in enumerate(vectorizer.get_feature_names())}\n",
    "entity2idx_tfidf = {word.split(\"#\")[1]: i for (i, word)  in enumerate(extracted_elems)}\n",
    "\n",
    "\n",
    "print (\"Total number of extracted unique classes and properties from entire RA set: \", len(extracted_elems))\n",
    "\n",
    "inp = [\"<UNK>\"] + inp\n",
    "extracted_elems = [\"<UNK>\"] + extracted_elems\n",
    "\n",
    "embeds = extractUSEEmbeddings(inp)\n",
    "embeddings = dict(zip(extracted_elems, embeds))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type storage\n",
    "\n",
    "types_dict = {}\n",
    "\n",
    "def get_tfidf_score(word, phrase):\n",
    "    return np.sum([X[entity2idx_tfidf[phrase]][:,word2idx_tfidf[word]][0,0] for word in parse(phrase)])\n",
    "    \n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    \n",
    "    entities = ont.get_entities()\n",
    "    props = ont.get_object_properties() + ont.get_data_properties()\n",
    "\n",
    "    for entity in entities:\n",
    "        types_dict[entity] = {\"type\": \"entity\"}\n",
    "    for prop in props:\n",
    "        types_dict[prop] = {\"type\": \"property\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinatorial mapping generation\n",
    "\n",
    "all_mappings = []\n",
    "for l in ontologies_in_alignment:\n",
    "    ont1 = Ontology(\"conference_ontologies/\" + l[0] + \".owl\")\n",
    "    ont2 = Ontology(\"conference_ontologies/\" + l[1] + \".owl\")\n",
    "    \n",
    "    ent1 = ont1.get_entities()\n",
    "    ent2 = ont2.get_entities()\n",
    "    \n",
    "    obj1 = ont1.get_object_properties()\n",
    "    obj2 = ont2.get_object_properties()\n",
    "    \n",
    "    data1 = ont1.get_data_properties()\n",
    "    data2 = ont2.get_data_properties()\n",
    "    \n",
    "    mappings = list(itertools.product(ent1, ent2)) + list(itertools.product(obj1, obj2)) + list(itertools.product(data1, data2))\n",
    "    \n",
    "    all_mappings.extend([(l[0] + \"#\" + el[0], l[1] + \"#\" + el[1]) for el in mappings])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mappings = [tuple([elem.split(\"/\")[-1] for elem in el]) for el in reference_alignments]\n",
    "\n",
    "data = {}\n",
    "for mapping in all_mappings:\n",
    "    if mapping in gt_mappings:\n",
    "        data[(mapping[0], mapping[1])] = True\n",
    "    else:\n",
    "        data[(mapping[0], mapping[1])] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_matching():\n",
    "    global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics\n",
    "    all_results = OrderedDict()\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        batch_size = min(batch_size, len(test_data_t))\n",
    "        num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "        batch_size_f = int(ceil(len(test_data_f)/num_batches))\n",
    "        \n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            batch_start_f = batch_idx * batch_size_f\n",
    "            batch_end_f = (batch_idx+1) * batch_size_f\n",
    "            \n",
    "            pos_elems = np.array(test_data_t)[batch_start:batch_end]\n",
    "            neg_elems = np.array(test_data_f)[batch_start_f:batch_end_f]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = np.array([generate_data(elem) for elem in list(pos_elems) + list(neg_elems)])     \n",
    "            targets = np.array([1 for i in range(len(pos_elems))] + [0 for i in range(len(neg_elems))])\n",
    "            \n",
    "            indices = np.random.permutation(inputs.shape[0])\n",
    "            inputs, targets = inputs[indices].transpose(1,0,2), targets[indices]\n",
    "            inputs = inputs.transpose(1,0,2)\n",
    "            inputs_elem = inputs.copy()\n",
    "            \n",
    "            nonzero_elems = np.count_nonzero(inputs, axis=-1)\n",
    "            indices = np.flip(np.argsort(nonzero_elems, axis=-1), axis=-1)\n",
    "            seq_lens = np.flip(np.sort(nonzero_elems, axis=-1), axis=-1)\n",
    "            inputs = np.stack((inputs[0][[indices[0]]], inputs[1][[indices[1]]]), axis=0)\n",
    "            \n",
    "            d1 = {elem:i for i,elem in enumerate(indices[0])}\n",
    "            d2 = {elem:i for i,elem in enumerate(indices[1])}\n",
    "            rev_indices = np.stack(([d1[k] for k in range(inputs_elem.shape[1])], [d2[k] for k in range(inputs_elem.shape[1])]))\n",
    "\n",
    "            rev_indices = torch.LongTensor(rev_indices)\n",
    "            inputs = torch.LongTensor(inputs)\n",
    "            seq_lens = torch.LongTensor(seq_lens.copy())\n",
    "            targets = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inputs, seq_lens, rev_indices)\n",
    "            #             outputs /= torch.sum(outputs, dim=1).view(-1, 1)\n",
    "# #             write ((\"Outputs Finally: \", str([str(s) for s in outputs])))\n",
    "#             outputs = [(1-el[1].item()) for el in outputs]\n",
    "\n",
    "#             return\n",
    "#             print (\"2\", inputs)\n",
    "#             print (\"3\", seq_lens)\n",
    "#             print (\"4\", rev_indices)\n",
    "            \n",
    "            targets = [True if el.item() else False for el in targets]\n",
    "#             print (inputs)\n",
    "            for idx, pred_elem in enumerate(outputs):\n",
    "                ent1 = emb_indexer_inv[inputs_elem[0][idx][0]]\n",
    "                ent2 = emb_indexer_inv[inputs_elem[1][idx][0]]\n",
    "                if (ent1, ent2) in all_results:\n",
    "                    print (\"Error: \", ent1, ent2, \"already present\")\n",
    "                all_results[(ent1, ent2)] = (pred_elem, targets[idx])\n",
    "        \n",
    "        all_results = OrderedDict(sorted(all_results.items(), key=lambda x: x[0], reverse=True))\n",
    "        filtered_results = dict()\n",
    "        \n",
    "        entities_to_assign = set([el[0] for el in list(all_results.keys())])\n",
    "        for pair in all_results:\n",
    "            if pair[0] in entities_to_assign:\n",
    "                filtered_results[pair] = all_results[pair]\n",
    "                entities_to_assign.remove(pair[0])\n",
    "                \n",
    "        entities_to_assign = set([el[1] for el in list(all_results.keys())])\n",
    "        for pair in all_results:\n",
    "            if pair[1] in entities_to_assign:\n",
    "                filtered_results[pair] = all_results[pair]\n",
    "                entities_to_assign.remove(pair[1])        \n",
    "\n",
    "        filtered_results = OrderedDict(sorted(filtered_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "        \n",
    "        optimum_metrics, opt_threshold = [-1000 for i in range(5)], -1000\n",
    "        low_threshold = np.min([el[0] for el in all_results.values()]) - 0.01\n",
    "        high_threshold = np.max([el[0] for el in all_results.values()]) + 0.01\n",
    "        for j,threshold in enumerate(np.arange(low_threshold, high_threshold, 0.01)):\n",
    "            res = []\n",
    "            for i,key in enumerate(all_results):\n",
    "                if all_results[key][0] > threshold:\n",
    "                    res.append(key)\n",
    "            fn_list = [key for key in gt_mappings if key not in set(res) and is_test(test_onto, key)]\n",
    "            fp_list = [elem for elem in res if not all_results[elem][1]]\n",
    "            tp_list = [elem for elem in res if all_results[elem][1]]\n",
    "            \n",
    "            tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1score = 2 * precision * recall / (precision + recall)\n",
    "                f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "                f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            print (\"Threshold: \", threshold, precision, recall, f1score, f2score, f0_5score)\n",
    "\n",
    "            if f1score > optimum_metrics[2]:\n",
    "                optimum_metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "                opt_threshold = threshold\n",
    "        \n",
    "        print (\"Precision: {} Recall: {} F1-Score: {} F2-Score: {} F0.5-Score: {}\".format(*optimum_metrics))\n",
    "        all_metrics.append((opt_threshold, optimum_metrics))\n",
    "    return all_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cmt#acceptPaper', 'edas#AcceptRating', 'iasted#Author', 'edas#MealEvent', 'confOf#Administrator', 'cmt#SubjectArea', 'edas#ReviewRating', 'cmt#setMaxPapers', 'conference#Publisher', 'iasted#is_used_by', 'iasted#need', 'iasted#Speaker_lecture', 'cmt#addProgramCommitteeMember', 'sigkdd#Abstract', 'confOf#Paper', 'confOf#Member', 'confOf#hasFirstName', 'cmt#rejectPaper', 'confOf#hasPhone', 'edas#string', 'iasted#Departure_tax', 'conference#has_an_organizing_committee', 'cmt#Meta-Review', 'iasted#Listener', 'conference#has_a_commtitee', 'iasted#prepare', 'confOf#Workshop', 'cmt#readPaper', 'edas#DiningPlace', 'cmt#ConferenceChair', 'cmt#acceptsHardcopySubmissions', 'conference#is_a_date_of_camera_ready_paper_submission', 'edas#isReviewHistoryOf', 'edas#hasCostCurrency', 'ekaw#University', 'iasted#Form', 'edas#ReviewForm', 'confOf#maxChoice', 'ekaw#Individual_Presentation', 'sigkdd#Best_Applications_Paper_Award', 'conference#Call_for_paper', 'iasted#Presenter_house', 'confOf#hasCountry', 'edas#endDate', 'sigkdd#End_of_conference', 'confOf#hasKeyword', 'iasted#Session_room', 'confOf#Company', 'confOf#hasSurname', 'confOf#location', 'edas#ConferenceEvent', 'edas#ComputerNetworksManagementTopic', 'sigkdd#Program_Committee', 'iasted#go_through', 'iasted#Lecture', 'ekaw#organises', 'sigkdd#Bronze_Supporter', 'ekaw#PC_Member', 'iasted#Money', 'edas#MedicineTopic', 'confOf#hasTopic', 'sigkdd#Name_of_conference', 'conference#is_part_of_conference_volumes', 'sigkdd#Start_of_conference', 'sigkdd#dateTime', 'edas#hasFirstName', 'sigkdd#award', 'ekaw#Demo_Session', 'ekaw#OC_Member', 'iasted#Technical_commitee', 'conference#Program_committee', 'sigkdd#Author_of_paper', 'cmt#PaperFullVersion', 'confOf#writes', 'iasted#Submission', 'conference#Conference_part', 'sigkdd#E-mail', 'edas#SocialEvent', 'ekaw#Scientific_Event', 'ekaw#Evaluated_Paper', 'iasted#Social_program', 'iasted#Worker_lecturer', 'edas#ComputerNetworksTopic', 'edas#isTopicOf', 'iasted#Activity_before_conference', 'sigkdd#can_stay_in', 'cmt#hasBid', 'conference#Written_contribution', 'conference#Invited_talk', 'conference#date', 'iasted#sign', 'confOf#Topic', 'iasted#Camera_ready_manuscript_deadline', 'edas#Sponsorship', 'conference#gives_presentations', 'confOf#hasPostalCode', 'ekaw#Conference_Proceedings', 'iasted#Trip_city', 'edas#WelcomeTalk', 'cmt#readByReviewer', 'cmt#Thing', 'cmt#Review', 'confOf#employedBy', 'cmt#Document', 'conference#was_a_committee_of', 'iasted#Fee_for_extra_trip', 'sigkdd#Program_Committee_member', 'ekaw#Industrial_Session', 'conference#reviews', 'cmt#Person', 'edas#hasCall', 'iasted#is_present', 'iasted#Conference_restaurant', 'edas#isReviewedBy', 'edas#Paper', 'edas#PersonalHistory', 'edas#ConferenceSession', 'conference#Tutorial', 'iasted#Sponsor_company_house', 'ekaw#Conference', 'ekaw#Research_Institute', 'confOf#Submission_event', 'ekaw#listsEvent', 'ekaw#Student', 'iasted#Introduction_of_speaker', 'conference#has_a_track-workshop-tutorial_topic', 'sigkdd#Deadline_Abstract_Submission', 'ekaw#OC_Chair', 'confOf#Social_event', 'iasted#is_paid_by', 'edas#TalkEvent', 'edas#Conference', 'ekaw#Presenter', 'cmt#endReview', 'iasted#is_made_from', 'cmt#Conference', 'edas#hasCity', 'sigkdd#holded_by', 'ekaw#Tutorial_Chair', 'ekaw#Contributed_Talk', 'iasted#Session_chair', 'conference#is_a_topis_of_conference_parts', 'ekaw#Conference_Paper', 'conference#Conference_contribution', 'ekaw#hasPart', 'ekaw#technicallyOrganises', 'cmt#ExternalReviewer', 'ekaw#Demo_Paper', 'sigkdd#string', 'cmt#hasDecision', 'edas#startDate', 'edas#OperatingTopicsystems', 'cmt#co-writePaper', 'conference#Review_preference', 'conference#Conference_www', 'iasted#Simulating', 'ekaw#subclass_of', 'edas#MobileComputingTopic', 'iasted#Author_book_proceedings_included', 'edas#PersonalReviewHistory', 'edas#Place', 'ekaw#Organisation', 'confOf#reviewes', 'sigkdd#Document', 'sigkdd#Registration_SIGMOD_Member', 'cmt#email', 'conference#Camera_ready_contribution', 'edas#isMenuOf', 'ekaw#Abstract', 'conference#has_a_program_committee', 'edas#TwoLevelConference', 'confOf#string', 'cmt#logoURL', 'cmt#readByMeta-Reviewer', 'conference#Committee_member', 'sigkdd#Gold_Supporter', 'sigkdd#Best_Research_Paper_Award', 'iasted#Conference_hotel', 'cmt#User', 'iasted#Hotel_presenter', 'edas#AcceptedPaper', 'iasted#give', 'conference#Paper', 'edas#GovernmentOrganization', 'conference#has_a_name', 'ekaw#eventOnList', 'iasted#Research', 'cmt#assignExternalReviewer', 'iasted#Sponsor', 'edas#hasPhone', 'cmt#ProgramCommitteeChair', 'cmt#enableVirtualMeeting', 'conference#Organization', 'sigkdd#Registration_SIGKDD_Member', 'ekaw#locationOf', 'iasted#Book_proceeding', 'conference#Organizing_committee', 'confOf#Student', 'ekaw#Submitted_Paper', 'ekaw#reviewOfPaper', 'conference#Invited_speaker', 'iasted#Nonmember_registration_fee', 'conference#has_a_review_reference_or_expertise', 'iasted#is_dated_on', 'conference#Active_conference_participant', 'edas#RadioCommunicationsTopic', 'conference#invites_co-reviewers', 'ekaw#publisherOf', 'ekaw#referencedIn', 'ekaw#SC_Member', 'edas#paperDueOn', 'iasted#Technic_activity', 'edas#CoffeeBreak', 'edas#PersonalPublicationHistory', 'conference#has_a_topic_or_a_submission_contribution', 'cmt#paperAssignmentFinalizedBy', 'cmt#memberOfConference', 'iasted#is_used_for', 'conference#has_a_steering_committee', 'cmt#writePaper', 'sigkdd#ACM_SIGKDD', 'conference#Conference_contributor', 'iasted#Tax', 'edas#Country', 'iasted#Single_hotel_room', 'sigkdd#Registration_fee', 'conference#Co-chair', 'edas#attendeeAt', 'cmt#hasSubjectArea', 'cmt#hasCo-author', 'iasted#IASTED_non_member', 'conference#Conference_applicant', 'edas#hasMenu', 'ekaw#Conference_Trip', 'conference#was_a_track-workshop_chair_of', 'iasted#is_occupied_by', 'cmt#assignedTo', 'edas#IndustryOrganization', 'confOf#Administrative_event', 'edas#hasPostalCode', 'edas#ComputerNetworksEnterpriseTopic', 'cmt#finalizePaperAssignment', 'iasted#obtain', 'iasted#Registation_deadline', 'cmt#hasConflictOfInterest', 'edas#ComputerNetworksSwitchingTopic', 'iasted#Worker_non_speaker', 'conference#has_authors', 'ekaw#writtenBy', 'edas#Organization', 'cmt#adjustedBy', 'cmt#AssociatedChair', 'edas#hasSubmissionInstructions', 'ekaw#Programme_Brochure', 'conference#was_an_organizing_committee_of', 'edas#CommunicationTheoryTopic', 'edas#hasCostAmount', 'ekaw#reviewerOfPaper', 'sigkdd#Webmaster', 'conference#Conference_fees', 'confOf#Reviewing_results_event', 'ekaw#Proceedings_Publisher', 'ekaw#Industrial_Paper', 'conference#Conference_document', 'conference#Thing', 'confOf#hasEmail', 'ekaw#references', 'edas#forEvent', 'confOf#Registration_of_participants_event', 'iasted#Submissions_deadline', 'iasted#is_given_to', 'ekaw#Conference_Session', 'edas#PerformanceTopic', 'sigkdd#Currency', 'edas#BreakEvent', 'ekaw#paperPresentedAs', 'edas#CallForReviews', 'edas#hasReviewHistory', 'iasted#is_writen_by', 'iasted#Car', 'confOf#hasHomePage', 'sigkdd#Deadline', 'edas#ParallelAndDistributedComputingTopic', 'sigkdd#Conference_hall', 'conference#has_members', 'sigkdd#Silver_Supporter', 'sigkdd#Date', 'iasted#Registration_form', 'conference#Registeered_applicant', 'conference#has_an_abstract', 'conference#issues', 'iasted#Conference_state', 'ekaw#Accepted_Paper', 'edas#AcademiaOrganization', 'cmt#unsignedLong', 'confOf#Event', 'edas#ComputerNetworksSensorTopic', 'edas#Presenter', 'confOf#writtenBy', 'ekaw#volumeContainsPaper', 'cmt#int', 'iasted#is_situated_in', 'confOf#City', 'edas#RejectRating', 'edas#CommunicationsTopic', 'ekaw#Agency_Staff_Member', 'conference#has_gender', 'iasted#Item', 'conference#Paid_applicant', 'cmt#Preference', 'conference#was_a_steering_committee_of', 'conference#int', 'confOf#positiveInteger', 'iasted#Memeber_registration_fee', 'iasted#Main_office', 'iasted#Session', 'cmt#submitPaper', 'confOf#Organization', 'edas#CryptographyTopic', 'confOf#Conference', 'iasted#Deadline_hotel_reservation', 'iasted#Author_attendee_cd_registration_fee', 'iasted#is_sent_after', 'iasted#Deadline_for_notification_of_acceptance', 'edas#ComputerNetworksOpticalTopic', 'iasted#Presentation', 'confOf#Scholar', 'iasted#Refusing_manuscript', 'edas#PendingPaper', 'ekaw#paperInVolume', 'edas#Reviewer', 'ekaw#Session', 'iasted#Plenary_lecture_speaker', 'iasted#is_present_in', 'cmt#virtualMeetingEnabledBy', 'ekaw#Early-Registered_Participant', 'conference#Topic', 'cmt#string', 'conference#Poster', 'edas#isWrittenBy', 'sigkdd#Deadline_Paper_Submission', 'iasted#One_day_presenter', 'conference#has_a_review_expertise', 'ekaw#Event', 'confOf#hasFax', 'sigkdd#Paper', 'edas#MealBreak', 'iasted#Viza', 'cmt#hardcopyMailingManifestsPrintedBy', 'iasted#is_given_by', 'cmt#assignedByReviewer', 'sigkdd#Author_of_paper_student', 'iasted#Speaker', 'iasted#Computer', 'edas#TPCMember', 'iasted#Student_non_speaker', 'iasted#is_paid_with', 'conference#has_a_submitted_contribution', 'ekaw#Session_Chair', 'iasted#Initial_manuscipt', 'edas#PowerlineTransmissionTopic', 'cmt#siteURL', 'conference#has_the_last_name', 'edas#ClosingTalk', 'conference#belong_to_a_conference_volume', 'sigkdd#Program_Chair', 'cmt#paperID', 'edas#Attendee', 'edas#Review', 'edas#MeetingRoomPlace', 'iasted#is_needed_for', 'cmt#Decision', 'iasted#is_paid_in', 'confOf#hasCity', 'iasted#Student_lecturer', 'edas#MicroelectronicsTopic', 'ekaw#organisedBy', 'cmt#reviewsPerPaper', 'sigkdd#Organizator', 'ekaw#Neutral_Review', 'iasted#Record_of_attendance', 'iasted#Invitation_letter', 'iasted#Person', 'sigkdd#Committee', 'edas#registrationDueOn', 'confOf#boolean', 'sigkdd#awarded_by', 'ekaw#Conference_Banquet', 'iasted#Registration', 'iasted#Conference_city', 'confOf#Member_PC', 'cmt#rejectedBy', 'sigkdd#notification_until', 'edas#ComputerNetworksAapplicationsTopic', 'confOf#subclass_of', 'ekaw#Poster_Session', 'conference#Submitted_contribution', 'edas#ActivePaper', 'cmt#Co-author', 'cmt#AuthorNotReviewer', 'iasted#Welcome_address', 'edas#belongsToEvent', 'edas#relatedToEvent', 'iasted#Delegate', 'confOf#starts_on', 'iasted#PowerPoint_presentation', 'iasted#Author_attendee_book_registration_fee', 'ekaw#updatedVersionOf', 'conference#is_a_full_paper_submission_date', 'conference#Conference', 'iasted#Student_registration_fee', 'cmt#writtenBy', 'sigkdd#Best_Student_Paper_Supporter', 'conference#Call_for_participation', 'edas#hasLocation', 'ekaw#Organising_Agency', 'edas#NumericalReviewQuestion', 'conference#has_a_committee_co-chair', 'confOf#contactEmail', 'sigkdd#Registration_Student', 'edas#SlideSet', 'conference#Organizer', 'confOf#Thing', 'sigkdd#Platinum_Supporter', 'edas#AcademicEvent', 'iasted#Sponsor_state', 'iasted#Final_manuscript', 'iasted#done_till', 'iasted#Review', 'iasted#is_visited_by', 'conference#Passive_conference_participant', 'edas#CallForPapers', 'ekaw#presentationOfPaper', 'confOf#Author', 'iasted#is_equipped_by', 'iasted#Taxi', 'iasted#Bank_transfer', 'edas#hasSubmissionDeadline', 'sigkdd#Conference', 'ekaw#hasEvent', 'iasted#dateTime', 'edas#TestOnlyTopic', 'ekaw#Review', 'iasted#Conference_activity', 'ekaw#Social_Event', 'edas#AccpetIfRoomRating', 'cmt#printHardcopyMailingManifests', 'confOf#Assistant', 'iasted#Accepting_manuscript', 'ekaw#hasReviewer', 'iasted#Presenter_city', 'conference#Chair', 'conference#was_a_committee_chair_of', 'confOf#expertOn', 'conference#has_a_review', 'cmt#PaperAbstract', 'ekaw#Workshop_Chair', 'conference#Contribution_co-author', 'iasted#is_sent_by', 'confOf#hasTitle', 'edas#ConferenceChair', 'edas#ReviewQuestion', 'ekaw#Track', 'cmt#detailsEnteredBy', 'iasted#Conference_hall', 'ekaw#coversTopic', 'cmt#enterConferenceDetails', 'conference#Accepted_contribution', 'conference#Contribution_1th-author', 'edas#hasRelatedPaper', 'cmt#ProgramCommittee', 'iasted#Van', 'iasted#Thing', 'cmt#Paper', 'sigkdd#Invited_Speaker', 'cmt#runPaperAssignmentTools', 'conference#Late_paid_applicant', 'iasted#Publication', 'iasted#Tip', 'cmt#Reviewer', 'ekaw#Regular_Session', 'confOf#hasVAT', 'edas#ConferenceDinner', 'confOf#remark', 'confOf#Person', 'sigkdd#Name_of_sponsor', 'edas#SecurityTopic', 'ekaw#Workshop_Session', 'iasted#Activity_after_conference', 'iasted#Deadline', 'ekaw#Late-Registered_Participant', 'iasted#is_sent_before', 'cmt#acceptedBy', 'iasted#date', 'ekaw#hasUpdatedVersion', 'ekaw#technicallyOrganisedBy', 'sigkdd#Organizing_Committee_member', 'cmt#Chairman', 'edas#TextualReviewQuestion', 'confOf#has_short_title', 'confOf#Short_paper', 'sigkdd#Best_Paper_Awards_Committee', 'edas#relatedToPaper', 'ekaw#Multi-author_Volume', 'iasted#Modelling', 'edas#ConferenceVenuePlace', 'iasted#Hotel_room', 'iasted#Transport_vehicle', 'conference#Conference_participant', 'ekaw#partOf', 'confOf#Banquet', 'iasted#Dinner_banquet', 'iasted#Payment_document', 'edas#ComputerNetworksMeasurementsTopic', 'iasted#write', 'edas#hasRelatedDocument', 'edas#hasStartDateTime', 'edas#Programme', 'conference#Steering_committee', 'edas#hasLastName', 'cmt#reviewCriteriaEnteredBy', 'conference#Review_expertise', 'ekaw#Proceedings', 'edas#TravelGrant', 'conference#Person', 'conference#is_an_abstract_submission_date', 'iasted#Shuttle_bus', 'conference#has_parts', 'iasted#Card', 'sigkdd#Person', 'confOf#Country', 'edas#WirelessCommunicationsTopic', 'edas#MultimediaTopic', 'sigkdd#City_of_conference', 'iasted#Video_presentation', 'cmt#hasAuthor', 'sigkdd#Fee', 'iasted#Author_information_form', 'conference#invited_by', 'edas#hasEndDateTime', 'iasted#Transparency', 'edas#hasAttendee', 'conference#has_a_publisher', 'iasted#occupy', 'iasted#Author_cd_proceedings_included', 'sigkdd#obtain', 'iasted#Tutorial', 'confOf#Reception', 'edas#Person', 'iasted#Departure', 'ekaw#Poster_Paper', 'sigkdd#Price', 'iasted#Coctail_reception', 'iasted#speak_in', 'edas#int', 'conference#is_given_by', 'conference#was_a_program_committee_of', 'sigkdd#Listener', 'sigkdd#searched_by', 'confOf#studyAt', 'ekaw#Person', 'ekaw#hasReview', 'ekaw#Rejected_Paper', 'iasted#Time', 'ekaw#Negative_Review', 'conference#is_a_starting_date', 'confOf#University', 'conference#subclass_of', 'edas#hasStreet', 'edas#hasEmail', 'sigkdd#Sponzor_fee', 'edas#WeekRejectRating', 'iasted#is_paid_for', 'ekaw#Paper', 'ekaw#PC_Chair', 'conference#Committee', 'iasted#is_held_in', 'edas#MealMenu', 'confOf#defaultChoice', 'edas#SatelliteAndSpaceCommunicationsTopic', 'edas#hasTopic', 'edas#initiates', 'conference#Conference_volume', 'iasted#Brief_introduction_for_Session_chair', 'sigkdd#Sponzor', 'ekaw#Workshop_Paper', 'conference#is_the_1th_part_of', 'conference#has_a_date_of_issue', 'edas#Reception', 'ekaw#Location', 'iasted#Mailing_list', 'iasted#Presenter_university', 'edas#AntennasTopic', 'ekaw#Camera_Ready_Paper', 'sigkdd#Deadline_Author_notification', 'ekaw#heldIn', 'iasted#Video_cassette_player', 'sigkdd#Author', 'iasted#Cheque', 'conference#Important_dates', 'iasted#Place', 'conference#has_an_ISBN', 'iasted#Conference_days', 'conference#contributes', 'edas#isProviderOf', 'sigkdd#Award', 'sigkdd#Name', 'ekaw#Positive_Review', 'conference#has_a_committee_chair', 'edas#FreeTimeBreak', 'conference#Extended_abstract', 'sigkdd#search', 'cmt#subclass_of', 'iasted#Full_day_tour', 'iasted#Sponsor_city', 'edas#PaperPresentation', 'iasted#Activity', 'cmt#startReviewerBidding', 'conference#has_a_degree', 'conference#Regular_contribution', 'ekaw#Paper_Author', 'edas#Topic', 'edas#isInitiatedBy', 'edas#Call', 'cmt#Meta-Reviewer', 'conference#has_a_location', 'conference#belongs_to_a_review_reference', 'confOf#Camera_Ready_event', 'edas#CADTopic', 'conference#is_submitted_at', 'ekaw#Research_Topic', 'iasted#Nonauthor_registration_fee', 'conference#has_workshops', 'sigkdd#General_Chair', 'sigkdd#pay', 'ekaw#Web_Site', 'edas#RatedPapers', 'conference#Presentation', 'iasted#One_conference_day', 'confOf#Science_Worker', 'confOf#Volunteer', 'ekaw#Tutorial_Abstract', 'conference#Information_for_participants', 'cmt#Rejection', 'conference#has_the_first_name', 'sigkdd#Best_Student_Paper_Award', 'conference#Rejected_contribution', 'confOf#Tutorial', 'iasted#Hotel_registration_form', 'iasted#Fee', 'ekaw#authorOf', 'cmt#anyURI', 'iasted#Introduction', 'cmt#maxPapers', 'sigkdd#Organizing_Committee', 'sigkdd#Hotel', 'iasted#Document', 'conference#is_a_date_of_acceptance_announcement', 'conference#Reviewer', 'ekaw#topicCoveredBy', 'ekaw#Invited_Speaker', 'edas#dateTime', 'iasted#Non_speaker', 'confOf#dealsWith', 'iasted#Sponzorship', 'sigkdd#Main_office', 'iasted#Conference_building', 'conference#Conference_announcement', 'confOf#ends_on', 'iasted#Plenary_lecture', 'cmt#addedBy', 'cmt#assignedByAdministrator', 'conference#has_tutorials', 'conference#has_a_track-workshop-tutorial_chair', 'cmt#name', 'confOf#Participant', 'edas#isLocationOf', 'cmt#adjustBid', 'iasted#City', 'edas#SingleLevelConference', 'sigkdd#Exhibitor', 'conference#Reviewed_contribution', 'ekaw#Demo_Chair', 'iasted#is_connected_with', 'sigkdd#submit_until', 'edas#hasRating', 'ekaw#Document', 'ekaw#Academic_Institution', 'sigkdd#Registration_Non-Member', 'iasted#LCD_projector', 'confOf#minChoice', 'sigkdd#hold', 'edas#isReviewing', 'edas#manuscriptDueOn', 'conference#has_a_volume', 'edas#NonAcademicEvent', 'edas#SessionChair', 'edas#ComputerNetworksSecurityTopic', 'confOf#has_title', 'iasted#State', 'iasted#Currency', 'iasted#is_signed_by', 'cmt#Author', 'confOf#hasStreet', 'iasted#Tutorial_speaker', 'ekaw#Invited_Talk', 'edas#hasCountry', 'cmt#assignReviewer', 'conference#was_a_committe_co-chair_of', 'edas#Excursion', 'cmt#hasConferenceMember', 'sigkdd#designed_by', 'iasted#subclass_of', 'ekaw#Assigned_Paper', 'edas#CallForManuscripts', 'iasted#Renting', 'sigkdd#payed_by', 'ekaw#Invited_Talk_Abstract', 'edas#hasProgramme', 'ekaw#Workshop', 'confOf#earlyRegistration', 'conference#string', 'confOf#Trip', 'edas#providedBy', 'conference#Conference_proceedings', 'sigkdd#submit', 'iasted#Credit_card', 'iasted#Double_hotel_room', 'iasted#IASTED_member', 'conference#is_an_ending_date', 'cmt#writeReview', 'sigkdd#presentation', 'edas#ContactInformation', 'conference#Track', 'sigkdd#Place', 'edas#hasName', 'edas#isMemberOf', 'conference#Early_paid_applicant', 'confOf#Regular', 'conference#has_an_expertise', 'cmt#memberOfProgramCommittee', 'iasted#is_held_after', 'edas#OrganizationalMeeting', 'cmt#paperAssignmentToolsRunBy', 'cmt#Administrator', 'conference#belongs_to_reviewers', 'confOf#abstract', 'edas#NGO', 'sigkdd#Speaker', 'sigkdd#subclass_of', 'conference#has_been_assigned_a_review_reference', 'cmt#title', 'confOf#hasAdministrativeEvent', 'confOf#Reviewing_event', 'edas#Author', 'ekaw#Conference_Participant', 'edas#Document', 'iasted#Audiovisual_equipment', 'iasted#Registration_fee', 'conference#Track-workshop_chair', 'iasted#int', 'iasted#Time_zone', 'cmt#hasProgramCommitteeMember', 'conference#Workshop', 'sigkdd#design', 'edas#ComputerArchitectureTopic', 'conference#has_a_URL', 'cmt#Bid', 'ekaw#Tutorial', 'ekaw#Regular_Paper', 'conference#has_tracks', 'edas#WithdrawnPaper', 'edas#AccommodationPlace', 'confOf#Working_event', 'cmt#markConflictOfInterest', 'cmt#enterReviewCriteria', 'iasted#pay', 'conference#Regular_author', 'ekaw#partOfEvent', 'ekaw#inverse_of_partOf_7', 'conference#has_an_email', 'edas#RejectedPaper', 'conference#was_a_member_of', 'edas#subclass_of', 'conference#Abstract', 'iasted#Coffee_break', 'sigkdd#Nation', 'edas#hasBiography', 'iasted#has_amount_of', 'confOf#Poster', 'edas#hasMember', 'ekaw#reviewWrittenBy', 'iasted#Conference_Hiker', 'edas#SignalProcessingTopic', 'edas#PublishedPaper', 'iasted#Presenter_state', 'iasted#Conference_airport', 'iasted#Reviewer', 'ekaw#Flyer', 'iasted#Cd_proceening', 'sigkdd#Thing', 'conference#has_important_dates', 'iasted#Value_added_tax', 'iasted#send', 'cmt#reviewerBiddingStartedBy', 'conference#has_contributions', 'sigkdd#Review', 'sigkdd#presentationed_by', 'edas#relatesTo', 'cmt#boolean', 'edas#Workshop', 'sigkdd#int', 'conference#Review', 'ekaw#scientificallyOrganises', 'iasted#Lecturer', 'cmt#hasBeenAssigned', 'iasted#Receiving_manuscript', 'iasted#Overhead_projector', 'iasted#Hotel_fee', 'ekaw#scientificallyOrganisedBy', 'iasted#is_held_before', 'confOf#follows', 'confOf#Contribution', 'ekaw#Possible_Reviewer', 'iasted#Building', 'cmt#ProgramCommitteeMember', 'confOf#Chair_PC', 'confOf#parallel_with', 'iasted#is_designed_for', 'cmt#date', 'cmt#ConferenceMember', 'iasted#Trip_day', 'cmt#Acceptance', 'iasted#is_prepared_by'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_test, inp_test1, inp_test2 = None, None, None\n",
    "\n",
    "def write(elem):\n",
    "    f = open(\"Logs\", \"a+\")\n",
    "    if type(elem) == list or type(elem) == tuple:\n",
    "        string = str(\"\\n\".join([str(s) for s in elem]))\n",
    "    else:\n",
    "        string = str(elem)\n",
    "    f.write(\"\\n\"+string)\n",
    "    f.close()\n",
    "    \n",
    "inputs3, results3 = None, None\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.name_embedding = nn.Embedding(len(embeddings), self.embedding_dim)\n",
    "        self.name_embedding.load_state_dict({'weight': torch.from_numpy(np.array(emb_vals))})\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "        self.cosine_sim_layer = nn.CosineSimilarity(dim=1)\n",
    "        self.layer1 = nn.Bilinear(self.hidden_dim, self.hidden_dim, 2)\n",
    "\n",
    "    def forward(self, inputs, seq_lens, rev_indices):\n",
    "        results = []\n",
    "        for i in range(2):\n",
    "            x = self.name_embedding(inputs[i])\n",
    "#             print (\"Embeddings\", x)\n",
    "            packed_inp = pack_padded_sequence(x, seq_lens[i].numpy(), batch_first=True)\n",
    "            op, (ht, ct) = self.lstm(x)\n",
    "            x = ht[2*(self.num_layers-1):].permute(1,0,2)\n",
    "            x = x[rev_indices[i],:,:]\n",
    "            results.append(x.reshape(-1, self.hidden_dim))\n",
    "        global inputs3, results3\n",
    "        results3 = results\n",
    "        inputs3 = inputs\n",
    "        x = self.cosine_sim_layer(results[0], results[1])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-361-2f3b2776b474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_indexer_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_mappings\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0montologies_in_alignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reference-alignment/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "import os, itertools, time, pickle\n",
    "import subprocess\n",
    "from xml.dom import minidom\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil, exp\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "f = open(\"data.pkl\", \"rb\")\n",
    "data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings  = pickle.load(f)\n",
    "\n",
    "ontologies_in_alignment = [l.split(\".\")[0].split(\"-\") for l in os.listdir(\"reference-alignment/\")]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "ind_test, inp_test1, inp_test2 = None, None, None\n",
    "\n",
    "class Ontology():\n",
    "    def __init__(self, ontology):\n",
    "        self.ontology = ontology\n",
    "        self.ontology_obj = minidom.parse(ontology)\n",
    "        self.root = self.ontology_obj.documentElement\n",
    "        self.subclasses = self.parse_subclasses()\n",
    "        self.object_properties = self.parse_object_properties()\n",
    "        self.data_properties = self.parse_data_properties()\n",
    "        self.triples = self.parse_triples()\n",
    "        self.classes = self.parse_classes()\n",
    "    \n",
    "    def get_child_node(self, element, tag):\n",
    "        return [e for e in element._get_childNodes() if type(e)==minidom.Element and e._get_tagName() == tag]\n",
    "        \n",
    "    def has_attribute_value(self, element, attribute, value):\n",
    "        return True if element.getAttribute(attribute).split(\"#\")[-1] == value else False\n",
    "    \n",
    "    def get_subclass_triples(self):\n",
    "        return [(b,a,\"subclass_of\") for (a,b) in self.get_subclasses()]\n",
    "    \n",
    "    def parse_triples(self, union_flag=0, subclass_of=True):\n",
    "        obj_props = self.object_properties\n",
    "        data_props = self.data_properties\n",
    "        props = obj_props + data_props\n",
    "        all_triples = []\n",
    "        for prop in props:\n",
    "            domain_children = self.get_child_node(prop, \"rdfs:domain\")\n",
    "            range_children = self.get_child_node(prop, \"rdfs:range\")\n",
    "            domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children])\n",
    "            range_prop = self.filter_null([self.extract_ID(el) for el in range_children])\n",
    "            if not domain_children or not range_children:\n",
    "                continue\n",
    "            if not domain_prop:\n",
    "                domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if not range_prop:\n",
    "                range_prop = self.filter_null([self.extract_ID(el) for el in range_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if domain_prop and range_prop:\n",
    "                if union_flag == 0:\n",
    "                    all_triples.extend([(el[0], el[1], self.extract_ID(prop)) for el in list(itertools.product(domain_prop, range_prop))])\n",
    "                else:\n",
    "                    all_triples.append((\"###\".join(domain_prop), \"###\".join(range_prop), self.extract_ID(prop)))\n",
    "        if subclass_of:\n",
    "            all_triples.extend(self.get_subclass_triples())\n",
    "        return list(set(all_triples))\n",
    "    \n",
    "    def get_triples(self, union_flag=0, subclass_of=True, include_inv=True):\n",
    "        return self.parse_triples(union_flag, subclass_of)\n",
    "\n",
    "    def parse_subclasses(self, union_flag=0):\n",
    "        subclasses = self.root.getElementsByTagName(\"rdfs:subClassOf\")\n",
    "        subclass_pairs = []\n",
    "        for el in subclasses:\n",
    "            inline_subclasses = self.extract_ID(el)\n",
    "            if inline_subclasses:\n",
    "                subclass_pairs.append((el, el.parentNode))\n",
    "            else:\n",
    "                level1_class = self.get_child_node(el, \"owl:Class\")\n",
    "                if not level1_class:\n",
    "                    continue\n",
    "                if self.extract_ID(level1_class[0]):\n",
    "                    subclass_pairs.append((level1_class[0], el.parentNode))\n",
    "                else:\n",
    "                    level2classes = level1_class[0].getElementsByTagName(\"owl:Class\")\n",
    "                    \n",
    "                    subclass_pairs.extend([(elem, el.parentNode) for elem in level2classes if self.extract_ID(elem)])\n",
    "        return subclass_pairs\n",
    "        \n",
    "    def get_subclasses(self):\n",
    "        return [(self.extract_ID(a), self.extract_ID(b)) for (a,b) in self.subclasses]\n",
    "    \n",
    "    def filter_null(self, data):\n",
    "        return [el for el in data if el]\n",
    "    \n",
    "    def extract_ID(self, element):\n",
    "        element_id = element.getAttribute(\"rdf:ID\") or element.getAttribute(\"rdf:resource\") or element.getAttribute(\"rdf:about\")\n",
    "        return element_id.split(\"#\")[-1]\n",
    "    \n",
    "    def parse_classes(self):\n",
    "        class_elems = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        subclass_classes = list(set(flatten([el[:-1] for el in self.triples])))\n",
    "        return list(set(self.filter_null(class_elems + subclass_classes)))\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def get_entities(self):\n",
    "        entities = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        return list(set(self.filter_null(entities)))\n",
    "\n",
    "    def parse_data_properties(self):\n",
    "        data_properties = [el for el in self.get_child_node(self.root, 'owl:DatatypeProperty')]\n",
    "        fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_data_properties = [el for el in fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        inv_fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_data_properties = [el for el in inv_fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        return data_properties + fn_data_properties + inv_fn_data_properties\n",
    "        \n",
    "    def parse_object_properties(self):\n",
    "        obj_properties = [el for el in self.get_child_node(self.root, 'owl:ObjectProperty')]\n",
    "        fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_obj_properties = [el for el in fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        inv_fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_obj_properties = [el for el in inv_fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        return obj_properties + fn_obj_properties + inv_fn_obj_properties\n",
    "    \n",
    "    def get_object_properties(self):\n",
    "        obj_props = [self.extract_ID(el) for el in self.object_properties]\n",
    "        return list(set(self.filter_null(obj_props)))\n",
    "    \n",
    "    def get_data_properties(self):\n",
    "        data_props = [self.extract_ID(el) for el in self.data_properties]\n",
    "        return list(set(self.filter_null(data_props)))\n",
    "\n",
    "\n",
    "def greedy_matching():\n",
    "    global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, all_metrics\n",
    "    all_results = OrderedDict()\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        batch_size = min(batch_size, len(test_data_t))\n",
    "        num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "        batch_size_f = int(ceil(len(test_data_f)/num_batches))\n",
    "        \n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "        gt_mappings_filt = []\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            batch_start_f = batch_idx * batch_size_f\n",
    "            batch_end_f = (batch_idx+1) * batch_size_f\n",
    "\n",
    "            pos_elems = np.array(test_data_t)[batch_start:batch_end]\n",
    "            neg_elems = np.array(test_data_f)[batch_start_f:batch_end_f]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs = np.array([generate_data(elem) for elem in list(pos_elems) + list(neg_elems)])\n",
    "            targets = np.array([1 for i in range(len(pos_elems))] + [0 for i in range(len(neg_elems))])\n",
    "            \n",
    "            indices = np.random.permutation(inputs.shape[0])\n",
    "            inputs, targets = inputs[indices].transpose(1,0,2), targets[indices]\n",
    "            \n",
    "            nonzero_elems = np.count_nonzero(inputs, axis=-1) - 1\n",
    "            \n",
    "            inputs = torch.LongTensor(inputs.transpose(1,0,2))\n",
    "            seq_lens = torch.LongTensor(nonzero_elems.T)\n",
    "            targets = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inputs, seq_lens)\n",
    "            outputs = [el.item() for el in outputs]\n",
    "            #outputs /= torch.sum(outputs, dim=1).view(-1, 1)\n",
    "            #outputs = [(1-el[1].item()) for el in outputs]\n",
    "            gt_mappings_filt.extend([el for el in gt_mappings if el in inputs])\n",
    "            \n",
    "            targets = [True if el.item() else False for el in targets]\n",
    "#             print (inputs)\n",
    "            for idx, pred_elem in enumerate(outputs):\n",
    "                ent1 = emb_indexer_inv[inputs_elem[0][idx][0]]\n",
    "                ent2 = emb_indexer_inv[inputs_elem[1][idx][0]]\n",
    "                if (ent1, ent2) in all_results:\n",
    "                    print (\"Error: \", ent1, ent2, \"already present\")\n",
    "                all_results[(ent1, ent2)] = (pred_elem, targets[idx])\n",
    "        print (\"Len of test data\", len(test_data_t), \"Filtered gt\", len(gt_mappings_filt))\n",
    "        #all_results = OrderedDict(sorted(all_results.items(), key=lambda x: x[0], reverse=True))\n",
    "        #filtered_results = dict()\n",
    "        \n",
    "        #entities_to_assign = set([el[0] for el in list(all_results.keys())])\n",
    "        #for pair in all_results:\n",
    "        #    if pair[0] in entities_to_assign:\n",
    "        #        filtered_results[pair] = all_results[pair]\n",
    "        #        entities_to_assign.remove(pair[0])\n",
    "                \n",
    "        #entities_to_assign = set([el[1] for el in list(all_results.keys())])\n",
    "        #for pair in all_results:\n",
    "        #    if pair[1] in entities_to_assign:\n",
    "        #        filtered_results[pair] = all_results[pair]\n",
    "        #        entities_to_assign.remove(pair[1])        \n",
    "\n",
    "        #filtered_results = OrderedDict(sorted(filtered_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "        \n",
    "        optimum_metrics, opt_threshold = [-1000 for i in range(5)], -1000\n",
    "        low_threshold = np.min([el[0] for el in all_results.values()]) - 0.01\n",
    "        high_threshold = np.max([el[0] for el in all_results.values()]) + 0.01\n",
    "        low_threshold, high_threshold = 0.9, 1.02\n",
    "        for j,threshold in enumerate(np.arange(low_threshold, high_threshold, 0.01)):\n",
    "            res = []\n",
    "            for i,key in enumerate(all_results):\n",
    "                if all_results[key][0] > threshold:\n",
    "                    res.append(key)\n",
    "            fn_list = [key for key in gt_mappings_filt if key not in set(res) and is_test(test_onto, key)]\n",
    "            fp_list = [elem for elem in res if not all_results[elem][1]]\n",
    "            tp_list = [elem for elem in res if all_results[elem][1]]\n",
    "            \n",
    "            tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1score = 2 * precision * recall / (precision + recall)\n",
    "                f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "                f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                continue\n",
    "            print (\"Threshold: \", threshold, precision, recall, f1score, f2score, f0_5score)\n",
    "\n",
    "            if f1score > optimum_metrics[2]:\n",
    "                optimum_metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "                opt_threshold = threshold\n",
    "        \n",
    "        print (\"Precision: {} Recall: {} F1-Score: {} F2-Score: {} F0.5-Score: {}\".format(*optimum_metrics))\n",
    "        all_metrics.append((opt_threshold, optimum_metrics))\n",
    "    return all_results\n",
    "\n",
    "def write(elem):\n",
    "    f = open(\"Logs\", \"a+\")\n",
    "    if type(elem) == list or type(elem) == tuple:\n",
    "        string = str(\"\\n\".join([str(s) for s in elem]))\n",
    "    else:\n",
    "        string = str(elem)\n",
    "    f.write(\"\\n\"+string)\n",
    "    f.close()\n",
    "    \n",
    "inputs3, results3 = None, None\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2\n",
    "        \n",
    "        self.name_embedding = nn.Embedding(len(emb_vals), self.embedding_dim)\n",
    "        self.name_embedding.load_state_dict({'weight': torch.from_numpy(np.array(emb_vals))})\n",
    "        self.name_embedding.weight.requires_grad = False\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, self.num_layers, bidirectional=True, batch_first=True)\n",
    "        self.cosine_sim_layer = nn.CosineSimilarity(dim=1)\n",
    "        self.attn = nn.Linear(1024, 1)\n",
    "        self.bilinear = nn.Bilinear(self.hidden_dim, self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, inputs, seq_lens):\n",
    "        results = []\n",
    "        inputs = inputs.permute(1,0,2)\n",
    "        seq_lens = seq_lens.T\n",
    "\n",
    "        for i in range(2):\n",
    "            x = self.name_embedding(inputs[i])\n",
    "            node = x.permute(1,0,2)[:1].permute(1,0,2)\n",
    "            neighbours = x.permute(1,0,2)[1:].permute(1,0,2)\n",
    "            context = torch.DoubleTensor()\n",
    "            \n",
    "            for j,elem in enumerate(neighbours):\n",
    "                curr_context = torch.DoubleTensor()\n",
    "                for neighbour in elem[:seq_lens[i][j],:]:\n",
    "                    attention = self.attn(torch.cat((node[j].reshape(512), neighbour.reshape(512))))\n",
    "                    attention = attention * neighbour.reshape(512)\n",
    "                    curr_context = torch.cat((curr_context, attention.unsqueeze(0)))\n",
    "                context = torch.cat((context, torch.mean(curr_context, dim=0).unsqueeze(0)))\n",
    "            \n",
    "            x = torch.cat((node.reshape(-1, 512), context.reshape(-1, 512)), dim=1)\n",
    "            results.append(x)\n",
    "        #global inputs3, results3\n",
    "        #results3 = results\n",
    "        #inputs3 = inputs\n",
    "        #x = self.layer1(results[0], results[1])\n",
    "        #x = F.log_softmax(x)\n",
    "#         print (results[0].shape)\n",
    "        x = self.cosine_sim_layer(results[0], results[1])\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_one_hop_neighbours(ont, K=1):\n",
    "    ont_obj = Ontology(\"conference_ontologies/\" + ont + \".owl\")\n",
    "    triples = ont_obj.get_triples()\n",
    "    entities = [(a,b) for (a,b,c) in triples]\n",
    "    neighbours_dict = {elem: [elem] for elem in list(set(flatten(entities)))}\n",
    "    for e1, e2 in entities:\n",
    "        neighbours_dict[e1].append(e2)\n",
    "        neighbours_dict[e2].append(e1)\n",
    "    \n",
    "    prop_triples = ont_obj.get_triples(subclass_of=False)\n",
    "    neighbours_dict_props = {c: [c] for a,b,c in prop_triples}\n",
    "    for e1, e2, p in prop_triples:\n",
    "        neighbours_dict_props[p].extend([e1, e2])\n",
    "\n",
    "    neighbours_dict = {**neighbours_dict, **neighbours_dict_props}\n",
    "    \n",
    "#     for elem in ont_obj.get_entities() + ont_obj.get_object_properties() + ont_obj.get_data_properties():\n",
    "#         if elem not in neighbours_dict:\n",
    "#             neighbours_dict[elem] = [elem]\n",
    "\n",
    "    neighbours_dict = {el: neighbours_dict[el][:1] + sorted(list(set(neighbours_dict[el][1:])))\n",
    "                       for el in neighbours_dict}\n",
    "#     neighbours_dict = {el: neighbours_dict[el][:10] for el in neighbours_dict}\n",
    "    neighbours_dict = {ont + \"#\" + el: [ont + \"#\" + e for e in neighbours_dict[el]] for el in neighbours_dict}\n",
    "    return neighbours_dict\n",
    "\n",
    "def is_test(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) in test_onto\n",
    "\n",
    "def generate_data(elem_tuple):\n",
    "    op = np.array([[emb_indexer[el] for el in neighbours_dicts[elem.split(\"#\")[0]][elem]] for elem in elem_tuple])\n",
    "    return op\n",
    "\n",
    "def generate_input(elems, target):\n",
    "    inputs, targets = [], []\n",
    "    for elem in list(elems):\n",
    "        try:\n",
    "            inputs.append(generate_data(elem))\n",
    "            targets.append(target)\n",
    "        except:\n",
    "            continue\n",
    "    print (\"Filtered len: \", len(inputs), \"Original len:\", len(elems))\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "neighbours_dicts = {ont: get_one_hop_neighbours(ont) for ont in list(set(flatten(ontologies_in_alignment)))}\n",
    "max_neighbours = np.max(flatten([[len(el[e]) for e in el] for el in neighbours_dicts.values()]))\n",
    "neighbours_lens = {ont: {key: len(neighbours_dicts[ont][key]) for key in neighbours_dicts[ont]}\n",
    "                   for ont in neighbours_dicts}\n",
    "neighbours_dicts = {ont: {key: neighbours_dicts[ont][key] + [\"<UNK>\" for i in range(max_neighbours -len(neighbours_dicts[ont][key]))]\n",
    "              for key in neighbours_dicts[ont]} for ont in neighbours_dicts}\n",
    "\n",
    "# data_items = data.items()\n",
    "# np.random.shuffle(list(data_items))\n",
    "# data = OrderedDict(data_items)\n",
    "\n",
    "# print (\"Number of entities:\", len(data))\n",
    "# all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "\n",
    "# all_metrics = []\n",
    "\n",
    "# for i in list(range(0, len(all_ont_pairs), 3)):\n",
    "    \n",
    "#     test_onto = all_ont_pairs[i:i+3]\n",
    "    \n",
    "#     train_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) not in test_onto}\n",
    "#     test_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) in test_onto}\n",
    "\n",
    "#     torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "#     train_test_split = 0.9\n",
    "\n",
    "#     train_data_t = [key for key in train_data if data[key]]\n",
    "#     train_data_f = [key for key in train_data if not data[key]]\n",
    "#     #train_data_f = train_data_f[:int(len(train_data_t))]\n",
    "# #     [:int(0.1*(len(train_data) - len(train_data_t)) )]\n",
    "# #     np.random.shuffle(train_data_f)\n",
    "    \n",
    "#     lr = 0.001\n",
    "#     num_epochs = 50\n",
    "#     weight_decay = 0.001\n",
    "#     batch_size = 8\n",
    "#     dropout = 0.3\n",
    "#     batch_size = min(batch_size, len(train_data_t))\n",
    "#     num_batches = int(ceil(len(train_data_t)/batch_size))\n",
    "#     batch_size_f = int(ceil(len(train_data_f)/num_batches))\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     model = nn.DataParallel(SiameseNetwork(512, 250, 1)).to(device)\n",
    "\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         inputs_pos, targets_pos = generate_input(train_data_t, 1)\n",
    "#         inputs_neg, targets_neg = generate_input(train_data_f, 0)\n",
    "#         indices_pos = np.random.permutation(len(inputs_pos))\n",
    "#         indices_neg = np.random.permutation(len(inputs_neg))\n",
    "\n",
    "#         inputs_pos, targets_pos = inputs_pos[indices_pos], targets_pos[indices_pos]\n",
    "#         inputs_neg, targets_neg = inputs_neg[indices_neg], targets_neg[indices_neg]\n",
    "\n",
    "# #        indices = np.random.permutation(len(inputs_pos) + len(inputs_neg))\n",
    "        \n",
    "# #        inputs = np.array(list(inputs_pos) + list(inputs_neg))[indices]\n",
    "# #        targets = np.array(list(targets_pos) + list(targets_neg))[indices]\n",
    "\n",
    "# #         inputs = np.array(list(inputs_pos) + list(inputs_neg))\n",
    "# #         targets = np.array(list(targets_pos) + list(targets_neg))\n",
    "\n",
    "#         for batch_idx in range(num_batches):\n",
    "#             batch_start = batch_idx * batch_size\n",
    "#             batch_end = (batch_idx+1) * batch_size\n",
    "            \n",
    "#             batch_start_f = batch_idx * batch_size_f\n",
    "#             batch_end_f = (batch_idx+1) * batch_size_f\n",
    "\n",
    "#             inputs = np.concatenate((inputs_pos[batch_start: batch_end], inputs_neg[batch_start_f: batch_end_f]))\n",
    "#             targets = np.concatenate((targets_pos[batch_start: batch_end], targets_neg[batch_start_f: batch_end_f]))\n",
    "            \n",
    "#             inp = inputs.transpose(1,0,2)\n",
    "#             nonzero_elems = np.count_nonzero(inp, axis=-1) - 1\n",
    "            \n",
    "#             inp_elems = torch.LongTensor(inputs)\n",
    "#             targ_elems = torch.DoubleTensor(targets).to(device)\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             seq_lens = torch.LongTensor(nonzero_elems.T)\n",
    "#             outputs = model(inp_elems, seq_lens)\n",
    "#             loss = F.mse_loss(outputs, targ_elems)\n",
    "#             loss.backward()\n",
    "# #             break\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if batch_idx%10 == 0:\n",
    "#                 print (\"Epoch: {} Idx: {} Loss: {}\".format(epoch, batch_idx, loss.item()))\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "    \n",
    "#     test_data_t = [key for key in test_data if data[key]]\n",
    "#     test_data_f = [key for key in test_data if not data[key]]\n",
    "    \n",
    "#     res = greedy_matching()\n",
    "\n",
    "# print (\"Final Results: \", np.mean([el[1] for el in all_metrics], axis=0))\n",
    "# print (\"Best threshold: \", all_metrics[np.argmax([el[1][2] for el in all_metrics])][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'al', (1, 2)), (1, 'al', (1, 5)), (1, 'sinal', 1)]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted([(1, \"sinal\", (1)), (1, \"al\", (1, 2)), (1, \"al\", (1, 5))], key=operator.itemgetter(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5465,  1.0060, -1.9793,  1.6608,  0.2812,  1.3197, -1.7668, -4.4346,\n",
       "        -0.4951, -0.3795])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curr_context = torch.DoubleTensor([])\n",
    "# curr_context = torch.cat((curr_context, torch.randn(10).unsqueeze(0)))\n",
    "torch.sum(curr_context, dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Conference_part', 0),\n",
       " ('Workshop', 1.0),\n",
       " ('string', 1.0),\n",
       " ('Tutorial', 1.0),\n",
       " ('Topic', 1.0),\n",
       " ('Track', 1.0),\n",
       " ('Track-workshop_chair', 1.0),\n",
       " ('Conference_volume', 1.0),\n",
       " ('Program_committee', 2.0),\n",
       " ('Person', 2.0),\n",
       " ('Conference', 2.0),\n",
       " ('Organizing_committee', 2.0),\n",
       " ('Steering_committee', 2.0),\n",
       " ('Important_dates', 2.0),\n",
       " ('Review_preference', 2.0),\n",
       " ('Conference_www', 2.0),\n",
       " ('Conference_contribution', 2.0),\n",
       " ('Committee', 2.0),\n",
       " ('Conference_proceedings', 2.0),\n",
       " ('Publisher', 2.0),\n",
       " ('Committee_member', 3.0),\n",
       " ('Submitted_contribution', 3.0),\n",
       " ('Written_contribution', 3.0),\n",
       " ('date', 3.0),\n",
       " ('Conference_contributor', 3.0),\n",
       " ('Poster', 3.0),\n",
       " ('int', 3.0),\n",
       " ('Co-chair', 3.0),\n",
       " ('Conference_document', 3.0),\n",
       " ('Conference_participant', 3.0),\n",
       " ('Chair', 3.0),\n",
       " ('Conference_applicant', 3.0),\n",
       " ('Reviewer', 3.0),\n",
       " ('Presentation', 3.0),\n",
       " ('Thing', 3.0),\n",
       " ('Review_expertise', 4.0),\n",
       " ('Invited_speaker', 4.0),\n",
       " ('Reviewed_contribution', 4.0),\n",
       " ('Invited_talk', 4.0),\n",
       " ('Registeered_applicant', 4.0),\n",
       " ('Passive_conference_participant', 4.0),\n",
       " ('Conference_announcement', 4.0),\n",
       " ('Active_conference_participant', 4.0),\n",
       " ('Call_for_paper', 4.0),\n",
       " ('Information_for_participants', 4.0),\n",
       " ('Abstract', 4.0),\n",
       " ('Regular_contribution', 4.0),\n",
       " ('Organizer', 4.0),\n",
       " ('Regular_author', 4.0),\n",
       " ('Call_for_participation', 4.0),\n",
       " ('Review', 4.0),\n",
       " ('Contribution_co-author', 5.0),\n",
       " ('Accepted_contribution', 5.0),\n",
       " ('Paper', 5.0),\n",
       " ('Rejected_contribution', 5.0),\n",
       " ('Organization', 5.0),\n",
       " ('Contribution_1th-author', 5.0),\n",
       " ('Extended_abstract', 5.0),\n",
       " ('Paid_applicant', 5.0),\n",
       " ('Early_paid_applicant', 6.0),\n",
       " ('Late_paid_applicant', 6.0),\n",
       " ('Camera_ready_contribution', 6.0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def djikstra(n, adj_matrix, start_node): \n",
    "\n",
    "    distances = [sys.maxsize] * n \n",
    "    path = [False] * n\n",
    "    \n",
    "    distances[start_node] = 0\n",
    "    \n",
    "    for node in range(n): \n",
    "        \n",
    "        distances_dict = {elem: i for (i,elem) in enumerate(distances) if not path[i]}\n",
    "        closest_node = distances_dict[min(list(distances_dict.keys()))]\n",
    "\n",
    "        path[closest_node] = True\n",
    " \n",
    "        for curr_node in range(n): \n",
    "            if adj_matrix[closest_node][curr_node] > 0 and not path[curr_node] and \\\n",
    "            distances[curr_node] > distances[closest_node] + adj_matrix[closest_node][curr_node]: \n",
    "                distances[curr_node] = distances[closest_node] + adj_matrix[closest_node][curr_node]\n",
    "\n",
    "    return distances\n",
    "\n",
    "all_triples = Ontology(\"conference_ontologies/conference.owl\").get_triples()\n",
    "\n",
    "entities = {entity:i for i,entity in enumerate(list(set(flatten([(el[0], el[1]) for el in all_triples]))))}\n",
    "entities_inv = {entities[entity]:entity for entity in entities}\n",
    "\n",
    "adj_mat = np.zeros((len(entities), len(entities)))\n",
    "\n",
    "for (a,b,_) in all_triples:\n",
    "    adj_mat[entities[a]][entities[b]] = 1\n",
    "    adj_mat[entities[b]][entities[a]] = 1\n",
    "\n",
    "src = entities[\"Conference_part\"]\n",
    "sorted([(entities_inv[i], entity) for i,entity in enumerate(djikstra(len(entities), adj_mat, src))], key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Workshop',\n",
       " 'string',\n",
       " 'Tutorial',\n",
       " 'Topic',\n",
       " 'Track',\n",
       " 'Track-workshop_chair',\n",
       " 'Conference_volume']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics\n",
    "all_results = OrderedDict()\n",
    "with torch.no_grad():\n",
    "    all_pred = []\n",
    "    batch_size = min(batch_size, len(test_data_t))\n",
    "    num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "    batch_size_f = int(ceil(len(test_data_f)/num_batches))\n",
    "\n",
    "    np.random.shuffle(test_data_t)\n",
    "    np.random.shuffle(test_data_f)\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "        batch_start_f = batch_idx * batch_size_f\n",
    "        batch_end_f = (batch_idx+1) * batch_size_f\n",
    "\n",
    "        pos_elems = np.array(test_data_t)[batch_start:batch_end]\n",
    "        neg_elems = np.array(test_data_f)[batch_start_f:batch_end_f]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = np.array([generate_data(elem) for elem in list(pos_elems) + list(neg_elems)])     \n",
    "        targets = np.array([1 for i in range(len(pos_elems))] + [0 for i in range(len(neg_elems))])\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[270],\n",
       "        [354]],\n",
       "\n",
       "       [[693],\n",
       "        [166]],\n",
       "\n",
       "       [[ 48],\n",
       "        [433]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[582],\n",
       "        [ 82]],\n",
       "\n",
       "       [[434],\n",
       "        [150]],\n",
       "\n",
       "       [[612],\n",
       "        [746]]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings], open(\"data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OrderedDict(embeddings.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8772, 0.9683],\n",
       "        [1.0000, 0.9996],\n",
       "        [1.0000, 0.9994]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.DoubleTensor([[[1,2,3]], [[4,5,6]], [[7,8,9]]])\n",
    "b = torch.DoubleTensor([[[10,2,30], [5,6,7]], [[4,5,6], [5,6,7]], [[7,8,9], [5,6,7]]])\n",
    "F.cosine_similarity(a,b,dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3373, 9, 512]) False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3373, 9, 1)\n",
    "b = torch.randn(3373, 9, 512)\n",
    "c = a * b\n",
    "print(c.shape, torch.equal(c,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1377, -1.0327, -0.6323,  ..., -2.2149,  2.5233,  0.6922]],\n",
      "\n",
      "        [[ 0.5923, -1.5585,  0.7242,  ..., -1.8788, -0.8722, -0.7855]],\n",
      "\n",
      "        [[ 0.4043,  1.5124, -0.3650,  ..., -1.1102,  0.7800, -2.1955]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.7878, -0.3074,  0.4295,  ..., -0.0570,  1.4719,  0.1476]],\n",
      "\n",
      "        [[-0.3127,  0.3369, -0.9186,  ..., -0.0083, -0.2215,  0.5971]],\n",
      "\n",
      "        [[-2.0341, -0.4788, -1.1528,  ..., -0.3162,  1.2564,  1.4677]]])\n",
      "tensor([[-0.1377, -1.0327, -0.6323,  ..., -2.2149,  2.5233,  0.6922],\n",
      "        [ 0.5923, -1.5585,  0.7242,  ..., -1.8788, -0.8722, -0.7855],\n",
      "        [ 0.4043,  1.5124, -0.3650,  ..., -1.1102,  0.7800, -2.1955],\n",
      "        ...,\n",
      "        [ 2.7878, -0.3074,  0.4295,  ..., -0.0570,  1.4719,  0.1476],\n",
      "        [-0.3127,  0.3369, -0.9186,  ..., -0.0083, -0.2215,  0.5971],\n",
      "        [-2.0341, -0.4788, -1.1528,  ..., -0.3162,  1.2564,  1.4677]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(3373, 1, 512)\n",
    "print (t)\n",
    "print (t.reshape(-1, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c = torch.DoubleTensor()\n",
    "c = torch.cat((c, torch.randn(3,4).unsqueeze(0)))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neighbours: -f\n",
      "Number of entities: 122893\n",
      "Filtered len:  261 Original len: 263\n",
      "Filtered len:  108145 Original len: 112782\n",
      "Epoch: 0 Idx: 0 Loss: 0.3495687231833145\n",
      "Epoch: 0 Idx: 10 Loss: 0.04882450803129536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-37cf893d2113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_elems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_elems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;31m#             break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, itertools, time, pickle\n",
    "import subprocess\n",
    "from xml.dom import minidom\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re, sys\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil, exp\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "f = open(\"data.pkl\", \"rb\")\n",
    "data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings  = pickle.load(f)\n",
    "\n",
    "ontologies_in_alignment = [l.split(\".\")[0].split(\"-\") for l in os.listdir(\"reference-alignment/\")]\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "ind_test, inp_test1, inp_test2 = None, None, None\n",
    "\n",
    "def write(statement):\n",
    "    op_file = open(\"Logs\", \"a+\")\n",
    "    op_file.write(\"\\n\" + str(statement) + \"\\n\")\n",
    "    op_file.close()\n",
    "\n",
    "class Ontology():\n",
    "    def __init__(self, ontology):\n",
    "        self.ontology = ontology\n",
    "        self.ontology_obj = minidom.parse(ontology)\n",
    "        self.root = self.ontology_obj.documentElement\n",
    "        self.subclasses = self.parse_subclasses()\n",
    "        self.object_properties = self.parse_object_properties()\n",
    "        self.data_properties = self.parse_data_properties()\n",
    "        self.triples = self.parse_triples()\n",
    "        self.classes = self.parse_classes()\n",
    "    \n",
    "    def get_child_node(self, element, tag):\n",
    "        return [e for e in element._get_childNodes() if type(e)==minidom.Element and e._get_tagName() == tag]\n",
    "        \n",
    "    def has_attribute_value(self, element, attribute, value):\n",
    "        return True if element.getAttribute(attribute).split(\"#\")[-1] == value else False\n",
    "    \n",
    "    def get_subclass_triples(self):\n",
    "        return [(b,a,\"subclass_of\") for (a,b) in self.get_subclasses()]\n",
    "    \n",
    "    def parse_triples(self, union_flag=0, subclass_of=True):\n",
    "        obj_props = self.object_properties\n",
    "        data_props = self.data_properties\n",
    "        props = obj_props + data_props\n",
    "        all_triples = []\n",
    "        for prop in props:\n",
    "            domain_children = self.get_child_node(prop, \"rdfs:domain\")\n",
    "            range_children = self.get_child_node(prop, \"rdfs:range\")\n",
    "            domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children])\n",
    "            range_prop = self.filter_null([self.extract_ID(el) for el in range_children])\n",
    "            if not domain_children or not range_children:\n",
    "                continue\n",
    "            if not domain_prop:\n",
    "                domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if not range_prop:\n",
    "                range_prop = self.filter_null([self.extract_ID(el) for el in range_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if domain_prop and range_prop:\n",
    "                if union_flag == 0:\n",
    "                    all_triples.extend([(el[0], el[1], self.extract_ID(prop)) for el in list(itertools.product(domain_prop, range_prop))])\n",
    "                else:\n",
    "                    all_triples.append((\"###\".join(domain_prop), \"###\".join(range_prop), self.extract_ID(prop)))\n",
    "        if subclass_of:\n",
    "            all_triples.extend(self.get_subclass_triples())\n",
    "        return list(set(all_triples))\n",
    "    \n",
    "    def get_triples(self, union_flag=0, subclass_of=True, include_inv=True):\n",
    "        return self.parse_triples(union_flag, subclass_of)\n",
    "\n",
    "    def parse_subclasses(self, union_flag=0):\n",
    "        subclasses = self.root.getElementsByTagName(\"rdfs:subClassOf\")\n",
    "        subclass_pairs = []\n",
    "        for el in subclasses:\n",
    "            inline_subclasses = self.extract_ID(el)\n",
    "            if inline_subclasses:\n",
    "                subclass_pairs.append((el, el.parentNode))\n",
    "            else:\n",
    "                level1_class = self.get_child_node(el, \"owl:Class\")\n",
    "                if not level1_class:\n",
    "                    continue\n",
    "                if self.extract_ID(level1_class[0]):\n",
    "                    subclass_pairs.append((level1_class[0], el.parentNode))\n",
    "                else:\n",
    "                    level2classes = level1_class[0].getElementsByTagName(\"owl:Class\")\n",
    "                    \n",
    "                    subclass_pairs.extend([(elem, el.parentNode) for elem in level2classes if self.extract_ID(elem)])\n",
    "        return subclass_pairs\n",
    "        \n",
    "    def get_subclasses(self):\n",
    "        return [(self.extract_ID(a), self.extract_ID(b)) for (a,b) in self.subclasses]\n",
    "    \n",
    "    def filter_null(self, data):\n",
    "        return [el for el in data if el]\n",
    "    \n",
    "    def extract_ID(self, element):\n",
    "        element_id = element.getAttribute(\"rdf:ID\") or element.getAttribute(\"rdf:resource\") or element.getAttribute(\"rdf:about\")\n",
    "        return element_id.split(\"#\")[-1]\n",
    "    \n",
    "    def parse_classes(self):\n",
    "        class_elems = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        subclass_classes = list(set(flatten([el[:-1] for el in self.triples])))\n",
    "        return list(set(self.filter_null(class_elems + subclass_classes)))\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def get_entities(self):\n",
    "        entities = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        return list(set(self.filter_null(entities)))\n",
    "\n",
    "    def parse_data_properties(self):\n",
    "        data_properties = [el for el in self.get_child_node(self.root, 'owl:DatatypeProperty')]\n",
    "        fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_data_properties = [el for el in fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        inv_fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_data_properties = [el for el in inv_fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        return data_properties + fn_data_properties + inv_fn_data_properties\n",
    "        \n",
    "    def parse_object_properties(self):\n",
    "        obj_properties = [el for el in self.get_child_node(self.root, 'owl:ObjectProperty')]\n",
    "        fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_obj_properties = [el for el in fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        inv_fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_obj_properties = [el for el in inv_fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        return obj_properties + fn_obj_properties + inv_fn_obj_properties\n",
    "    \n",
    "    def get_object_properties(self):\n",
    "        obj_props = [self.extract_ID(el) for el in self.object_properties]\n",
    "        return list(set(self.filter_null(obj_props)))\n",
    "    \n",
    "    def get_data_properties(self):\n",
    "        data_props = [self.extract_ID(el) for el in self.data_properties]\n",
    "        return list(set(self.filter_null(data_props)))\n",
    "\n",
    "\n",
    "def greedy_matching():\n",
    "    global batch_size, test_data_t, test_data_f, model, optimizer, emb_indexer_inv, gt_mappings, all_metrics\n",
    "    all_results = OrderedDict()\n",
    "    with torch.no_grad():\n",
    "        all_pred = []\n",
    "        batch_size = min(batch_size, len(test_data_t))\n",
    "        num_batches = int(ceil(len(test_data_t)/batch_size))\n",
    "        batch_size_f = int(ceil(len(test_data_f)/num_batches))\n",
    "        \n",
    "        np.random.shuffle(test_data_t)\n",
    "        np.random.shuffle(test_data_f)\n",
    "        \n",
    "        gt_mappings_filt = []\n",
    "\n",
    "        inputs_pos, targets_pos = generate_input(test_data_t, 1)\n",
    "        inputs_neg, targets_neg = generate_input(test_data_f, 0)\n",
    "\n",
    "        indices_pos = np.random.permutation(len(inputs_pos))\n",
    "        indices_neg = np.random.permutation(len(inputs_neg))\n",
    "\n",
    "        inputs_pos, targets_pos = inputs_pos[indices_pos], targets_pos[indices_pos]\n",
    "        inputs_neg, targets_neg = inputs_neg[indices_neg], targets_neg[indices_neg]\n",
    "\n",
    "        gt_mappings_filt = [el for el in gt_mappings if el in inputs_pos]\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            batch_start = batch_idx * batch_size\n",
    "            batch_end = (batch_idx+1) * batch_size\n",
    "\n",
    "            batch_start_f = batch_idx * batch_size_f\n",
    "            batch_end_f = (batch_idx+1) * batch_size_f\n",
    "\n",
    "            inputs = np.concatenate((inputs_pos[batch_start: batch_end], inputs_neg[batch_start_f: batch_end_f]))\n",
    "            targets = np.concatenate((targets_pos[batch_start: batch_end], targets_neg[batch_start_f: batch_end_f]))\n",
    "            \n",
    "            inp = inputs.transpose(1,0,2)\n",
    "            \n",
    "            nonzero_elems = np.count_nonzero(inp, axis=-1) - 1\n",
    "\n",
    "            inp_elems = torch.LongTensor(inputs).to(device)\n",
    "            seq_lens = torch.LongTensor(nonzero_elems.T).to(device)\n",
    "            targ_elems = torch.DoubleTensor(targets)\n",
    "\n",
    "            outputs = model(inp_elems, seq_lens)\n",
    "            outputs = [el.item() for el in outputs]\n",
    "            #outputs /= torch.sum(outputs, dim=1).view(-1, 1)\n",
    "            #outputs = [(1-el[1].item()) for el in outputs]\n",
    "            \n",
    "\n",
    "            targets = [True if el.item() else False for el in targets]\n",
    "#             print (inputs)\n",
    "            for idx, pred_elem in enumerate(outputs):\n",
    "                ent1 = emb_indexer_inv[inp[0][idx][0]]\n",
    "                ent2 = emb_indexer_inv[inp[1][idx][0]]\n",
    "                if (ent1, ent2) in all_results:\n",
    "                    print (\"Error: \", ent1, ent2, \"already present\")\n",
    "                all_results[(ent1, ent2)] = (pred_elem, targets[idx])\n",
    "        \n",
    "        #all_results = OrderedDict(sorted(all_results.items(), key=lambda x: x[0], reverse=True))\n",
    "        #filtered_results = dict()\n",
    "        \n",
    "        #entities_to_assign = set([el[0] for el in list(all_results.keys())])\n",
    "        #for pair in all_results:\n",
    "        #    if pair[0] in entities_to_assign:\n",
    "        #        filtered_results[pair] = all_results[pair]\n",
    "        #        entities_to_assign.remove(pair[0])\n",
    "                \n",
    "        #entities_to_assign = set([el[1] for el in list(all_results.keys())])\n",
    "        #for pair in all_results:\n",
    "        #    if pair[1] in entities_to_assign:\n",
    "        #        filtered_results[pair] = all_results[pair]\n",
    "        #        entities_to_assign.remove(pair[1])        \n",
    "\n",
    "        #filtered_results = OrderedDict(sorted(filtered_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "        \n",
    "        optimum_metrics, opt_threshold = [-1000 for i in range(5)], -1000\n",
    "        low_threshold = np.min([el[0] for el in all_results.values()]) - 0.02\n",
    "        high_threshold = np.max([el[0] for el in all_results.values()]) + 0.02\n",
    "        #low_threshold, high_threshold = 0.9, 1.02\n",
    "        threshold = low_threshold\n",
    "        step = 0.01\n",
    "        while threshold < high_threshold:\n",
    "            res = []\n",
    "            for i,key in enumerate(all_results):\n",
    "                if all_results[key][0] > threshold:\n",
    "                    res.append(key)\n",
    "            fn_list = [key for key in gt_mappings_filt if key not in set(res) and is_test(test_onto, key)]\n",
    "            fp_list = [elem for elem in res if not all_results[elem][1]]\n",
    "            tp_list = [elem for elem in res if all_results[elem][1]]\n",
    "            \n",
    "            tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "            exception = False\n",
    "            \n",
    "            try:\n",
    "                precision = tp/(tp+fp)\n",
    "                recall = tp/(tp+fn)\n",
    "                f1score = 2 * precision * recall / (precision + recall)\n",
    "                f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "                f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                exception = True\n",
    "                step = 0.01\n",
    "                threshold += step\n",
    "                continue\n",
    "            print (\"Threshold: \", threshold, precision, recall, f1score, f2score, f0_5score)\n",
    "\n",
    "            if f1score > optimum_metrics[2]:\n",
    "                optimum_metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "                opt_threshold = threshold\n",
    "            \n",
    "            if threshold > 0.98 and not exception:\n",
    "                step = 0.0001\n",
    "            else:\n",
    "                step = 0.01\n",
    "            print (step, threshold, exception)\n",
    "            threshold += step \n",
    "        print (\"Precision: {} Recall: {} F1-Score: {} F2-Score: {} F0.5-Score: {}\".format(*optimum_metrics))\n",
    "        if optimum_metrics[2] != -1000:\n",
    "            all_metrics.append((opt_threshold, optimum_metrics))\n",
    "    return all_results\n",
    "\n",
    "def write(elem):\n",
    "    f = open(\"Logs\", \"a+\")\n",
    "    if type(elem) == list or type(elem) == tuple:\n",
    "        string = str(\"\\n\".join([str(s) for s in elem]))\n",
    "    else:\n",
    "        string = str(elem)\n",
    "    f.write(\"\\n\"+string)\n",
    "    f.close()\n",
    "    \n",
    "inputs3, results3 = None, None\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_directions = 2\n",
    "        \n",
    "        self.name_embedding = nn.Embedding(len(emb_vals), self.embedding_dim)\n",
    "        self.name_embedding.load_state_dict({'weight': torch.from_numpy(np.array(emb_vals))})\n",
    "        self.name_embedding.weight.requires_grad = False\n",
    "\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, self.num_layers, bidirectional=True, batch_first=True)\n",
    "        self.cosine_sim_layer = nn.CosineSimilarity(dim=1)\n",
    "        self.attn = nn.Linear(1024, 1)\n",
    "        self.bilinear = nn.Bilinear(self.hidden_dim, self.hidden_dim, 1)\n",
    "\n",
    "    def forward(self, inputs, seq_lens):\n",
    "        results = []\n",
    "        inputs = inputs.permute(1,0,2)\n",
    "        seq_lens = seq_lens.T\n",
    "        #print (\"input len: {} seq len: {}, rev len: {}\".format(inputs.shape, seq_lens.shape, rev_indices.shape))\n",
    "        for i in range(2):\n",
    "            x = self.name_embedding(inputs[i])\n",
    "            node = x.permute(1,0,2)[:1].permute(1,0,2)\n",
    "            neighbours = x.permute(1,0,2)[1:].permute(1,0,2)\n",
    "            context = torch.DoubleTensor().to(device)\n",
    "            \n",
    "            for j,elem in enumerate(neighbours):\n",
    "                curr_context = torch.DoubleTensor().to(device)\n",
    "                for neighbour in elem[:seq_lens[i][j],:]:\n",
    "                    attention = self.attn(torch.cat((node[j].reshape(512), neighbour.reshape(512))))\n",
    "                    attention = attention * neighbour.reshape(512)\n",
    "                    curr_context = torch.cat((curr_context, attention.unsqueeze(0)))\n",
    "                context = torch.cat((context, torch.mean(curr_context, dim=0).unsqueeze(0)))\n",
    "            \n",
    "            x = torch.cat((node.reshape(-1, 512), context.reshape(-1, 512)), dim=1)\n",
    "            results.append(x)\n",
    "        #global inputs3, results3\n",
    "        #results3 = results\n",
    "        #inputs3 = inputs\n",
    "        #x = self.layer1(results[0], results[1])\n",
    "        #x = F.log_softmax(x)\n",
    "        x = self.cosine_sim_layer(results[0], results[1])\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_one_hop_neighbours(ont, K=1):\n",
    "    ont_obj = Ontology(\"conference_ontologies/\" + ont + \".owl\")\n",
    "    triples = ont_obj.get_triples()\n",
    "    entities = [(a,b) for (a,b,c) in triples]\n",
    "    neighbours_dict = {elem: [elem] for elem in list(set(flatten(entities)))}\n",
    "    for e1, e2 in entities:\n",
    "        neighbours_dict[e1].append(e2)\n",
    "        neighbours_dict[e2].append(e1)\n",
    "    \n",
    "    prop_triples = ont_obj.get_triples(subclass_of=False)\n",
    "    neighbours_dict_props = {c: [c] for a,b,c in prop_triples}\n",
    "    for e1, e2, p in prop_triples:\n",
    "        neighbours_dict_props[p].extend([e1, e2])\n",
    "\n",
    "    neighbours_dict = {**neighbours_dict, **neighbours_dict_props}\n",
    "    \n",
    "    # for elem in ont_obj.get_entities() + ont_obj.get_object_properties() + ont_obj.get_data_properties():\n",
    "    #     if elem not in neighbours_dict:\n",
    "    #         neighbours_dict[elem] = [elem]\n",
    "\n",
    "    neighbours_dict = {el: neighbours_dict[el][:1] + sorted(list(set(neighbours_dict[el][1:])))\n",
    "                       for el in neighbours_dict}\n",
    "    neighbours_dict = {el: neighbours_dict[el][:int(sys.argv[1])] for el in neighbours_dict}\n",
    "    neighbours_dict = {ont + \"#\" + el: [ont + \"#\" + e for e in neighbours_dict[el]] for el in neighbours_dict}\n",
    "    return neighbours_dict\n",
    "\n",
    "def generate_data(elem_tuple):\n",
    "    op = np.array([[emb_indexer[el] for el in neighbours_dicts[elem.split(\"#\")[0]][elem]] for elem in elem_tuple])\n",
    "    return op\n",
    "\n",
    "def generate_input(elems, target):\n",
    "    inputs, targets = [], []\n",
    "    for elem in list(elems):\n",
    "        try:\n",
    "            inputs.append(generate_data(elem))\n",
    "            targets.append(target)\n",
    "        except:\n",
    "            continue\n",
    "    print (\"Filtered len: \", len(inputs), \"Original len:\", len(elems))\n",
    "    return np.array(inputs), np.array(targets)\n",
    "\n",
    "neighbours_dicts = {ont: get_one_hop_neighbours(ont) for ont in list(set(flatten(ontologies_in_alignment)))}\n",
    "max_neighbours = np.max(flatten([[len(el[e]) for e in el] for el in neighbours_dicts.values()]))\n",
    "neighbours_lens = {ont: {key: len(neighbours_dicts[ont][key]) for key in neighbours_dicts[ont]}\n",
    "                   for ont in neighbours_dicts}\n",
    "neighbours_dicts = {ont: {key: neighbours_dicts[ont][key] + [\"<UNK>\" for i in range(max_neighbours -len(neighbours_dicts[ont][key]))]\n",
    "              for key in neighbours_dicts[ont]} for ont in neighbours_dicts}\n",
    "\n",
    "print(\"Number of neighbours: \" + sys.argv[1])\n",
    "\n",
    "data_items = data.items()\n",
    "np.random.shuffle(list(data_items))\n",
    "data = OrderedDict(data_items)\n",
    "\n",
    "print (\"Number of entities:\", len(data))\n",
    "all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for i in list(range(0, len(all_ont_pairs), 3)):\n",
    "    \n",
    "    test_onto = all_ont_pairs[i:i+3]\n",
    "    \n",
    "    train_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) not in test_onto}\n",
    "    test_data = {elem: data[elem] for elem in data if tuple([el.split(\"#\")[0] for el in elem]) in test_onto}\n",
    "\n",
    "    torch.set_default_dtype(torch.float64)\n",
    "    \n",
    "    train_test_split = 0.9\n",
    "\n",
    "    train_data_t = [key for key in train_data if data[key]]\n",
    "    train_data_f = [key for key in train_data if not data[key]]\n",
    "    #train_data_f = train_data_f[:int(len(train_data_t))]\n",
    "#     [:int(0.1*(len(train_data) - len(train_data_t)) )]\n",
    "#     np.random.shuffle(train_data_f)\n",
    "    \n",
    "    lr = 0.001\n",
    "    num_epochs = 50\n",
    "    weight_decay = 0.001\n",
    "    batch_size = 8\n",
    "    dropout = 0.3\n",
    "    batch_size = min(batch_size, len(train_data_t))\n",
    "    num_batches = int(ceil(len(train_data_t)/batch_size))\n",
    "    batch_size_f = int(ceil(len(train_data_f)/num_batches))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model = SiameseNetwork(512, 250, 1).to(device)\n",
    "    model.load_state_dict(torch.load(\"/attention.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    \n",
    "    test_data_t = [key for key in test_data if data[key]]\n",
    "    test_data_f = [key for key in test_data if not data[key]]\n",
    "    \n",
    "    res = greedy_matching()\n",
    "    break\n",
    "\n",
    "print (\"Final Results: \" + str(np.mean([el[1] for el in all_metrics], axis=0)))\n",
    "print (\"Best threshold: \" + str(all_metrics[np.argmax([el[1][2] for el in all_metrics])][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3993, 1, 512)\n",
    "b = torch.randn(3993, 9, 512)\n",
    "mult = torch.bmm(b, a.permute(0, 2, 1)).squeeze()\n",
    "att_weights = masked_softmax(mult).unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (att_weights * b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_softmax(inp):\n",
    "    inp = inp.double()\n",
    "    mask = ((inp != 0).double() - 1) * 9999  # for -inf\n",
    "    return F.softmax(inp + mask, dim=-1)\n",
    "masked_softmax(torch.DoubleTensor([[1,1,0], [0.5, 0,0 ], [0.2, 0,0.8 ]])).requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3993, 9, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3993, 9, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3993, 512])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ((att_weights * b).shape)\n",
    "torch.sum(att_weights * b, dim=1).shape\n",
    "# torch.cat((a.reshape(-1, 512), context.reshape(-1, 512)), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2673, -0.5345,  0.8018],\n",
       "        [ 0.2673,  0.5345,  0.8018]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = []\n",
    "for file in os.listdir(\".\"):\n",
    "    if file.startswith(\"Output_att\"):\n",
    "        neighbours = int(''.join(filter(str.isdigit, file)))\n",
    "        intent = \"USE + dot Attn + \" + neighbours + \" neighbours + Cos Sim \"\n",
    "        threshold = str(round(float([l for l in open(file).read().split(\"\\n\") if \"Best threshold:\" in l][0]), 3))\n",
    "\n",
    "        if \"ent_prop\" in file:\n",
    "            intent += \"(avg, ent+prop)\"\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, softmax, weighted average, concat with entity, both entities and props\"\n",
    "        elif \"sum\" in file:\n",
    "            intent += \"(sum)\"\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, softmax, weighted sum, concat with entity\"\n",
    "        elif \"unsoftmax\" in file:\n",
    "            intent += \"(avg, no softmax)\"\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, weighted average, concat with entity\"\n",
    "        elif \"context\" in file:\n",
    "            intent += \"(only context)\"\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, softmax, weighted average, context is directly output\"\n",
    "        elif \"normalize\" in file:\n",
    "            intent += \"(avg, normalized)\"\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, softmax, weighted average, normalized, concat with entity\"\n",
    "        else:\n",
    "            desc = \"Optimum threshold \" + threshold + \", Dot product of node with neighbours, softmax, weighted average, concat with entity\"\n",
    "        results = [l for l in open(file).read().split(\"\\n\") if \"Final Results:\" in l][0]\n",
    "        \n",
    "        results = results.split(\"[\")[1].split(\"]\")[0].strip().split()\n",
    "        line = \"\\t\".join([intent] + results + [desc])\n",
    "        final.append(line)\n",
    "final = sorted(final, key=lambda x:x.split(\"\\t\")[0])\n",
    "open(\"results.tsv\", \"w+\").write(\"\\n\".join(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/1.31G [00:00<?, ?B/s]\u001b[A\n",
      "  0%|          | 32.8k/1.31G [00:00<1:40:43, 217kB/s]\u001b[A\n",
      "  0%|          | 49.2k/1.31G [00:00<2:12:21, 165kB/s]\u001b[A\n",
      "  0%|          | 98.3k/1.31G [00:00<1:53:24, 193kB/s]\u001b[A\n",
      "  0%|          | 164k/1.31G [00:00<1:34:52, 230kB/s] \u001b[A\n",
      "  0%|          | 246k/1.31G [00:00<1:18:51, 277kB/s]\u001b[A\n",
      "  0%|          | 344k/1.31G [00:00<1:05:33, 333kB/s]\u001b[A\n",
      "  0%|          | 475k/1.31G [00:01<53:39, 407kB/s]  \u001b[A\n",
      "  0%|          | 623k/1.31G [00:01<44:26, 492kB/s]\u001b[A\n",
      "  0%|          | 819k/1.31G [00:01<36:17, 602kB/s]\u001b[A\n",
      "  0%|          | 1.03M/1.31G [00:01<29:08, 750kB/s]\u001b[A\n",
      "  0%|          | 1.28M/1.31G [00:01<23:26, 932kB/s]\u001b[A\n",
      "  0%|          | 1.49M/1.31G [00:01<19:55, 1.10MB/s]\u001b[A\n",
      "  0%|          | 1.65M/1.31G [00:01<18:50, 1.16MB/s]\u001b[A\n",
      "  0%|          | 1.97M/1.31G [00:01<15:39, 1.39MB/s]\u001b[A\n",
      "  0%|          | 2.34M/1.31G [00:02<12:56, 1.69MB/s]\u001b[A\n",
      "  0%|          | 2.70M/1.31G [00:02<11:06, 1.96MB/s]\u001b[A\n",
      "  0%|          | 2.96M/1.31G [00:02<10:58, 1.99MB/s]\u001b[A\n",
      "  0%|          | 3.49M/1.31G [00:02<09:06, 2.40MB/s]\u001b[A\n",
      "  0%|          | 4.11M/1.31G [00:02<07:35, 2.87MB/s]\u001b[A\n",
      "  0%|          | 4.65M/1.31G [00:02<06:42, 3.25MB/s]\u001b[A\n",
      "  0%|          | 5.06M/1.31G [00:02<06:37, 3.28MB/s]\u001b[A\n",
      "  0%|          | 5.83M/1.31G [00:02<05:36, 3.88MB/s]\u001b[A\n",
      "  1%|          | 6.72M/1.31G [00:03<04:46, 4.56MB/s]\u001b[A\n",
      "  1%|          | 7.52M/1.31G [00:03<04:15, 5.10MB/s]\u001b[A\n",
      "  1%|          | 8.12M/1.31G [00:03<04:17, 5.05MB/s]\u001b[A\n",
      "  1%|          | 9.29M/1.31G [00:03<03:38, 5.96MB/s]\u001b[A\n",
      "  1%|          | 10.6M/1.31G [00:03<03:07, 6.95MB/s]\u001b[A\n",
      "  1%|          | 11.5M/1.31G [00:03<02:55, 7.41MB/s]\u001b[A\n",
      "  1%|          | 12.6M/1.31G [00:03<02:51, 7.59MB/s]\u001b[A\n",
      "  1%|          | 14.4M/1.31G [00:03<02:23, 9.05MB/s]\u001b[A\n",
      "  1%|          | 16.3M/1.31G [00:03<02:04, 10.4MB/s]\u001b[A\n",
      "  1%|         | 17.5M/1.31G [00:04<01:59, 10.8MB/s]\u001b[A\n",
      "  1%|         | 19.2M/1.31G [00:04<01:55, 11.2MB/s]\u001b[A\n",
      "  2%|         | 21.8M/1.31G [00:04<01:37, 13.3MB/s]\u001b[A\n",
      "  2%|         | 24.4M/1.31G [00:04<01:25, 15.0MB/s]\u001b[A\n",
      "  2%|         | 26.1M/1.31G [00:04<01:23, 15.4MB/s]\u001b[A\n",
      "  2%|         | 27.9M/1.31G [00:04<01:19, 16.1MB/s]\u001b[A\n",
      "  2%|         | 30.8M/1.31G [00:04<01:14, 17.2MB/s]\u001b[A\n",
      "  3%|         | 33.5M/1.31G [00:04<01:06, 19.3MB/s]\u001b[A\n",
      "  3%|         | 35.6M/1.31G [00:05<01:10, 18.1MB/s]\u001b[A\n",
      "  3%|         | 38.2M/1.31G [00:05<01:10, 18.1MB/s]\u001b[A\n",
      "  3%|         | 41.7M/1.31G [00:05<01:00, 21.1MB/s]\u001b[A\n",
      "  3%|         | 44.0M/1.31G [00:05<00:59, 21.3MB/s]\u001b[A\n",
      "  4%|         | 46.3M/1.31G [00:05<01:06, 18.9MB/s]\u001b[A\n",
      "  4%|         | 49.1M/1.31G [00:05<01:03, 19.9MB/s]\u001b[A\n",
      "  4%|         | 52.3M/1.31G [00:05<00:56, 22.4MB/s]\u001b[A\n",
      "  4%|         | 54.7M/1.31G [00:05<01:04, 19.6MB/s]\u001b[A\n",
      "  4%|         | 56.9M/1.31G [00:06<01:07, 18.6MB/s]\u001b[A\n",
      "  5%|         | 60.4M/1.31G [00:06<00:59, 21.0MB/s]\u001b[A\n",
      "  5%|         | 63.1M/1.31G [00:06<00:55, 22.6MB/s]\u001b[A\n",
      "  5%|         | 65.6M/1.31G [00:06<00:59, 21.1MB/s]\u001b[A\n",
      "  5%|         | 68.3M/1.31G [00:06<01:00, 20.4MB/s]\u001b[A\n",
      "  6%|         | 72.2M/1.31G [00:06<00:57, 21.7MB/s]\u001b[A\n",
      "  6%|         | 76.2M/1.31G [00:06<00:54, 22.8MB/s]\u001b[A\n",
      "  6%|         | 78.6M/1.31G [00:06<00:59, 20.7MB/s]\u001b[A\n",
      "  6%|         | 81.8M/1.31G [00:07<00:53, 23.2MB/s]\u001b[A\n",
      "  6%|         | 84.3M/1.31G [00:07<00:56, 21.6MB/s]\u001b[A\n",
      "  7%|         | 87.9M/1.31G [00:07<00:55, 22.1MB/s]\u001b[A\n",
      "  7%|         | 91.7M/1.31G [00:07<00:54, 22.2MB/s]\u001b[A\n",
      "  7%|         | 95.6M/1.31G [00:07<00:53, 22.6MB/s]\u001b[A\n",
      "  8%|         | 99.6M/1.31G [00:07<00:53, 22.9MB/s]\u001b[A\n",
      "  8%|         | 103M/1.31G [00:08<00:52, 23.0MB/s] \u001b[A\n",
      "  8%|         | 107M/1.31G [00:08<00:52, 23.0MB/s]\u001b[A\n",
      "  8%|         | 111M/1.31G [00:08<00:51, 23.1MB/s]\u001b[A\n",
      "  9%|         | 115M/1.31G [00:08<00:51, 23.3MB/s]\u001b[A\n",
      "  9%|         | 119M/1.31G [00:08<00:50, 23.5MB/s]\u001b[A\n",
      "  9%|         | 123M/1.31G [00:08<00:50, 23.6MB/s]\u001b[A\n",
      " 10%|         | 127M/1.31G [00:09<00:50, 23.6MB/s]\u001b[A\n",
      " 10%|         | 131M/1.31G [00:09<00:50, 23.4MB/s]\u001b[A\n",
      " 10%|         | 135M/1.31G [00:09<00:50, 23.4MB/s]\u001b[A\n",
      " 11%|         | 139M/1.31G [00:09<00:50, 23.3MB/s]\u001b[A\n",
      " 11%|         | 143M/1.31G [00:09<00:50, 23.4MB/s]\u001b[A\n",
      " 11%|         | 147M/1.31G [00:09<00:49, 23.4MB/s]\u001b[A\n",
      " 12%|        | 151M/1.31G [00:10<00:49, 23.5MB/s]\u001b[A\n",
      " 12%|        | 155M/1.31G [00:10<00:44, 25.9MB/s]\u001b[A\n",
      " 12%|        | 157M/1.31G [00:10<00:45, 25.5MB/s]\u001b[A\n",
      " 12%|        | 160M/1.31G [00:10<00:50, 22.9MB/s]\u001b[A\n",
      " 12%|        | 163M/1.31G [00:10<00:54, 21.2MB/s]\u001b[A\n",
      " 13%|        | 167M/1.31G [00:10<00:53, 21.6MB/s]\u001b[A\n",
      " 13%|        | 169M/1.31G [00:10<00:56, 20.1MB/s]\u001b[A\n",
      " 13%|        | 173M/1.31G [00:11<00:56, 20.2MB/s]\u001b[A\n",
      " 13%|        | 176M/1.31G [00:11<00:58, 19.5MB/s]\u001b[A\n",
      " 14%|        | 180M/1.31G [00:11<00:55, 20.3MB/s]\u001b[A\n",
      " 14%|        | 184M/1.31G [00:11<00:53, 21.2MB/s]\u001b[A\n",
      " 14%|        | 188M/1.31G [00:11<00:51, 22.0MB/s]\u001b[A\n",
      " 15%|        | 192M/1.31G [00:11<00:49, 22.4MB/s]\u001b[A\n",
      " 15%|        | 195M/1.31G [00:12<00:49, 22.6MB/s]\u001b[A\n",
      " 15%|        | 199M/1.31G [00:12<00:48, 23.0MB/s]\u001b[A\n",
      " 15%|        | 202M/1.31G [00:12<00:51, 21.5MB/s]\u001b[A\n",
      " 16%|        | 206M/1.31G [00:12<00:50, 22.0MB/s]\u001b[A\n",
      " 16%|        | 210M/1.31G [00:12<00:49, 22.4MB/s]\u001b[A\n",
      " 16%|        | 214M/1.31G [00:12<00:42, 25.6MB/s]\u001b[A\n",
      " 17%|        | 217M/1.31G [00:12<00:42, 25.5MB/s]\u001b[A\n",
      " 17%|        | 219M/1.31G [00:13<00:49, 22.3MB/s]\u001b[A\n",
      " 17%|        | 222M/1.31G [00:13<00:51, 21.1MB/s]\u001b[A\n",
      " 17%|        | 226M/1.31G [00:13<00:49, 21.9MB/s]\u001b[A\n",
      " 18%|        | 230M/1.31G [00:13<00:42, 25.2MB/s]\u001b[A\n",
      " 18%|        | 233M/1.31G [00:13<00:47, 22.8MB/s]\u001b[A\n",
      " 18%|        | 235M/1.31G [00:13<00:48, 22.0MB/s]\u001b[A\n",
      " 18%|        | 238M/1.31G [00:13<00:51, 21.1MB/s]\u001b[A\n",
      " 18%|        | 242M/1.31G [00:14<00:49, 21.6MB/s]\u001b[A\n",
      " 19%|        | 246M/1.31G [00:14<00:48, 22.2MB/s]\u001b[A\n",
      " 19%|        | 250M/1.31G [00:14<00:47, 22.4MB/s]\u001b[A\n",
      " 19%|        | 254M/1.31G [00:14<00:46, 22.7MB/s]\u001b[A\n",
      " 20%|        | 258M/1.31G [00:14<00:45, 23.0MB/s]\u001b[A\n",
      " 20%|        | 262M/1.31G [00:14<00:45, 23.2MB/s]\u001b[A\n",
      " 20%|        | 266M/1.31G [00:15<00:44, 23.4MB/s]\u001b[A\n",
      " 21%|        | 270M/1.31G [00:15<00:44, 23.5MB/s]\u001b[A\n",
      " 21%|        | 274M/1.31G [00:15<00:43, 23.6MB/s]\u001b[A\n",
      " 21%|        | 278M/1.31G [00:15<00:43, 23.7MB/s]\u001b[A\n",
      " 22%|       | 282M/1.31G [00:15<00:43, 23.7MB/s]\u001b[A\n",
      " 22%|       | 286M/1.31G [00:15<00:43, 23.6MB/s]\u001b[A\n",
      " 22%|       | 290M/1.31G [00:16<00:43, 23.5MB/s]\u001b[A\n",
      " 22%|       | 294M/1.31G [00:16<00:43, 23.5MB/s]\u001b[A\n",
      " 23%|       | 298M/1.31G [00:16<00:43, 23.6MB/s]\u001b[A\n",
      " 23%|       | 302M/1.31G [00:16<00:42, 23.6MB/s]\u001b[A\n",
      " 23%|       | 306M/1.31G [00:16<00:42, 23.7MB/s]\u001b[A\n",
      " 24%|       | 310M/1.31G [00:16<00:42, 23.7MB/s]\u001b[A\n",
      " 24%|       | 314M/1.31G [00:17<00:42, 23.7MB/s]\u001b[A\n",
      " 24%|       | 318M/1.31G [00:17<00:42, 23.7MB/s]\u001b[A\n",
      " 25%|       | 322M/1.31G [00:17<00:41, 23.7MB/s]\u001b[A\n",
      " 25%|       | 326M/1.31G [00:17<00:41, 23.6MB/s]\u001b[A\n",
      " 25%|       | 330M/1.31G [00:17<00:41, 23.7MB/s]\u001b[A\n",
      " 25%|       | 334M/1.31G [00:17<00:41, 23.6MB/s]\u001b[A\n",
      " 26%|       | 338M/1.31G [00:18<00:41, 23.7MB/s]\u001b[A\n",
      " 26%|       | 342M/1.31G [00:18<00:40, 23.8MB/s]\u001b[A\n",
      " 26%|       | 346M/1.31G [00:18<00:40, 23.8MB/s]\u001b[A\n",
      " 27%|       | 350M/1.31G [00:18<00:40, 23.8MB/s]\u001b[A\n",
      " 27%|       | 354M/1.31G [00:18<00:40, 23.8MB/s]\u001b[A\n",
      " 27%|       | 358M/1.31G [00:18<00:40, 23.5MB/s]\u001b[A\n",
      " 28%|       | 362M/1.31G [00:19<00:40, 23.6MB/s]\u001b[A\n",
      " 28%|       | 366M/1.31G [00:19<00:40, 23.6MB/s]\u001b[A\n",
      " 28%|       | 370M/1.31G [00:19<00:40, 23.5MB/s]\u001b[A\n",
      " 28%|       | 374M/1.31G [00:19<00:40, 23.4MB/s]\u001b[A\n",
      " 29%|       | 376M/1.31G [00:19<00:42, 22.2MB/s]\u001b[A\n",
      " 29%|       | 380M/1.31G [00:19<00:40, 22.8MB/s]\u001b[A\n",
      " 29%|       | 384M/1.31G [00:20<00:35, 26.0MB/s]\u001b[A\n",
      " 29%|       | 386M/1.31G [00:20<00:40, 22.7MB/s]\u001b[A\n",
      " 30%|       | 390M/1.31G [00:20<00:40, 22.6MB/s]\u001b[A\n",
      " 30%|       | 394M/1.31G [00:20<00:40, 22.9MB/s]\u001b[A\n",
      " 30%|       | 398M/1.31G [00:20<00:39, 22.9MB/s]\u001b[A\n",
      " 31%|       | 402M/1.31G [00:20<00:39, 22.9MB/s]\u001b[A\n",
      " 31%|       | 406M/1.31G [00:21<00:39, 23.1MB/s]\u001b[A\n",
      " 31%|       | 410M/1.31G [00:21<00:38, 23.3MB/s]\u001b[A\n",
      " 32%|      | 414M/1.31G [00:21<00:38, 23.4MB/s]\u001b[A\n",
      " 32%|      | 418M/1.31G [00:21<00:38, 23.5MB/s]\u001b[A\n",
      " 32%|      | 422M/1.31G [00:21<00:37, 23.5MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 426M/1.31G [00:21<00:37, 23.5MB/s]\u001b[A\n",
      " 33%|      | 430M/1.31G [00:22<00:38, 23.0MB/s]\u001b[A\n",
      " 33%|      | 434M/1.31G [00:22<00:37, 23.2MB/s]\u001b[A\n",
      " 33%|      | 438M/1.31G [00:22<00:37, 23.4MB/s]\u001b[A\n",
      " 34%|      | 442M/1.31G [00:22<00:37, 23.4MB/s]\u001b[A\n",
      " 34%|      | 446M/1.31G [00:22<00:36, 23.4MB/s]\u001b[A\n",
      " 34%|      | 450M/1.31G [00:22<00:37, 23.3MB/s]\u001b[A\n",
      " 35%|      | 453M/1.31G [00:23<00:36, 23.3MB/s]\u001b[A\n",
      " 35%|      | 456M/1.31G [00:23<00:46, 18.6MB/s]\u001b[A\n",
      " 35%|      | 460M/1.31G [00:23<00:43, 19.7MB/s]\u001b[A\n",
      " 35%|      | 462M/1.31G [00:23<00:46, 18.3MB/s]\u001b[A\n",
      " 35%|      | 465M/1.31G [00:23<00:46, 18.3MB/s]\u001b[A\n",
      " 36%|      | 468M/1.31G [00:23<00:45, 18.4MB/s]\u001b[A\n",
      " 36%|      | 471M/1.31G [00:24<00:45, 18.5MB/s]\u001b[A\n",
      " 36%|      | 474M/1.31G [00:24<00:44, 18.6MB/s]\u001b[A\n",
      " 36%|      | 477M/1.31G [00:24<00:44, 18.8MB/s]\u001b[A\n",
      " 37%|      | 480M/1.31G [00:24<00:43, 19.0MB/s]\u001b[A\n",
      " 37%|      | 483M/1.31G [00:24<00:43, 19.2MB/s]\u001b[A\n",
      " 37%|      | 486M/1.31G [00:24<00:42, 19.4MB/s]\u001b[A\n",
      " 37%|      | 489M/1.31G [00:24<00:42, 19.6MB/s]\u001b[A\n",
      " 38%|      | 492M/1.31G [00:25<00:41, 19.8MB/s]\u001b[A\n",
      " 38%|      | 495M/1.31G [00:25<00:40, 19.9MB/s]\u001b[A\n",
      " 38%|      | 498M/1.31G [00:25<00:40, 20.1MB/s]\u001b[A\n",
      " 38%|      | 502M/1.31G [00:25<00:39, 20.3MB/s]\u001b[A\n",
      " 38%|      | 505M/1.31G [00:25<00:39, 20.4MB/s]\u001b[A\n",
      " 39%|      | 508M/1.31G [00:25<00:38, 20.6MB/s]\u001b[A\n",
      " 39%|      | 510M/1.31G [00:26<00:38, 20.9MB/s]\u001b[A\n",
      " 39%|      | 512M/1.31G [00:26<00:42, 18.7MB/s]\u001b[A\n",
      " 39%|      | 515M/1.31G [00:26<00:43, 18.5MB/s]\u001b[A\n",
      " 40%|      | 519M/1.31G [00:26<00:41, 19.3MB/s]\u001b[A\n",
      " 40%|      | 522M/1.31G [00:26<00:40, 19.3MB/s]\u001b[A\n",
      " 40%|      | 525M/1.31G [00:26<00:39, 20.0MB/s]\u001b[A\n",
      " 40%|      | 529M/1.31G [00:26<00:38, 20.6MB/s]\u001b[A\n",
      " 41%|      | 532M/1.31G [00:27<00:39, 19.7MB/s]\u001b[A\n",
      " 41%|      | 535M/1.31G [00:27<00:38, 20.4MB/s]\u001b[A\n",
      " 41%|      | 538M/1.31G [00:27<00:39, 19.6MB/s]\u001b[A\n",
      " 41%|     | 542M/1.31G [00:27<00:37, 20.5MB/s]\u001b[A\n",
      " 42%|     | 545M/1.31G [00:27<00:36, 21.1MB/s]\u001b[A\n",
      " 42%|     | 549M/1.31G [00:27<00:37, 20.6MB/s]\u001b[A\n",
      " 42%|     | 552M/1.31G [00:28<00:35, 21.3MB/s]\u001b[A\n",
      " 42%|     | 556M/1.31G [00:28<00:34, 21.8MB/s]\u001b[A\n",
      " 43%|     | 560M/1.31G [00:28<00:33, 22.2MB/s]\u001b[A\n",
      " 43%|     | 563M/1.31G [00:28<00:33, 22.5MB/s]\u001b[A\n",
      " 43%|     | 567M/1.31G [00:28<00:32, 22.7MB/s]\u001b[A\n",
      " 43%|     | 570M/1.31G [00:28<00:32, 23.0MB/s]\u001b[A\n",
      " 44%|     | 573M/1.31G [00:28<00:31, 23.5MB/s]\u001b[A\n",
      " 44%|     | 575M/1.31G [00:29<00:35, 20.7MB/s]\u001b[A\n",
      " 44%|     | 577M/1.31G [00:29<00:40, 18.3MB/s]\u001b[A\n",
      " 44%|     | 581M/1.31G [00:29<00:37, 19.6MB/s]\u001b[A\n",
      " 45%|     | 585M/1.31G [00:29<00:35, 20.7MB/s]\u001b[A\n",
      " 45%|     | 588M/1.31G [00:29<00:36, 19.7MB/s]\u001b[A\n",
      " 45%|     | 592M/1.31G [00:29<00:34, 20.8MB/s]\u001b[A\n",
      " 45%|     | 594M/1.31G [00:30<00:36, 19.8MB/s]\u001b[A\n",
      " 46%|     | 598M/1.31G [00:30<00:34, 21.0MB/s]\u001b[A\n",
      " 46%|     | 601M/1.31G [00:30<00:30, 23.2MB/s]\u001b[A\n",
      " 46%|     | 604M/1.31G [00:30<00:30, 23.1MB/s]\u001b[A\n",
      " 46%|     | 606M/1.31G [00:30<00:32, 21.4MB/s]\u001b[A\n",
      " 46%|     | 608M/1.31G [00:30<00:35, 19.8MB/s]\u001b[A\n",
      " 47%|     | 612M/1.31G [00:30<00:34, 20.6MB/s]\u001b[A\n",
      " 47%|     | 616M/1.31G [00:31<00:32, 21.2MB/s]\u001b[A\n",
      " 47%|     | 620M/1.31G [00:31<00:31, 22.2MB/s]\u001b[A\n",
      " 48%|     | 624M/1.31G [00:31<00:30, 22.9MB/s]\u001b[A\n",
      " 48%|     | 628M/1.31G [00:31<00:29, 23.5MB/s]\u001b[A\n",
      " 48%|     | 630M/1.31G [00:31<00:28, 23.6MB/s]\u001b[A\n",
      " 48%|     | 632M/1.31G [00:31<00:32, 21.1MB/s]\u001b[A\n",
      " 48%|     | 635M/1.31G [00:31<00:29, 22.8MB/s]\u001b[A\n",
      " 49%|     | 639M/1.31G [00:31<00:26, 25.1MB/s]\u001b[A\n",
      " 49%|     | 642M/1.31G [00:32<00:28, 23.2MB/s]\u001b[A\n",
      " 49%|     | 644M/1.31G [00:32<00:32, 20.7MB/s]\u001b[A\n",
      " 49%|     | 647M/1.31G [00:32<00:33, 20.0MB/s]\u001b[A\n",
      " 50%|     | 651M/1.31G [00:32<00:31, 20.7MB/s]\u001b[A\n",
      " 50%|     | 655M/1.31G [00:32<00:30, 21.3MB/s]\u001b[A\n",
      " 50%|     | 659M/1.31G [00:32<00:29, 22.4MB/s]\u001b[A\n",
      " 51%|     | 663M/1.31G [00:33<00:27, 23.2MB/s]\u001b[A\n",
      " 51%|     | 667M/1.31G [00:33<00:27, 23.8MB/s]\u001b[A\n",
      " 51%|     | 671M/1.31G [00:33<00:26, 24.3MB/s]\u001b[A\n",
      " 51%|    | 674M/1.31G [00:33<00:23, 26.8MB/s]\u001b[A\n",
      " 52%|    | 677M/1.31G [00:33<00:27, 23.3MB/s]\u001b[A\n",
      " 52%|    | 680M/1.31G [00:33<00:30, 20.5MB/s]\u001b[A\n",
      " 52%|    | 682M/1.31G [00:33<00:33, 18.6MB/s]\u001b[A\n",
      " 52%|    | 685M/1.31G [00:34<00:31, 20.2MB/s]\u001b[A\n",
      " 53%|    | 689M/1.31G [00:34<00:28, 21.5MB/s]\u001b[A\n",
      " 53%|    | 693M/1.31G [00:34<00:27, 22.6MB/s]\u001b[A\n",
      " 53%|    | 697M/1.31G [00:34<00:23, 25.7MB/s]\u001b[A\n",
      " 53%|    | 700M/1.31G [00:34<00:26, 22.7MB/s]\u001b[A\n",
      " 54%|    | 702M/1.31G [00:34<00:30, 20.2MB/s]\u001b[A\n",
      " 54%|    | 705M/1.31G [00:34<00:30, 19.8MB/s]\u001b[A\n",
      " 54%|    | 709M/1.31G [00:35<00:29, 20.7MB/s]\u001b[A\n",
      " 54%|    | 713M/1.31G [00:35<00:27, 21.5MB/s]\u001b[A\n",
      " 55%|    | 717M/1.31G [00:35<00:26, 22.6MB/s]\u001b[A\n",
      " 55%|    | 721M/1.31G [00:35<00:25, 23.5MB/s]\u001b[A\n",
      " 55%|    | 725M/1.31G [00:35<00:24, 24.1MB/s]\u001b[A\n",
      " 56%|    | 729M/1.31G [00:35<00:27, 21.5MB/s]\u001b[A\n",
      " 56%|    | 733M/1.31G [00:36<00:26, 22.1MB/s]\u001b[A\n",
      " 56%|    | 737M/1.31G [00:36<00:24, 23.0MB/s]\u001b[A\n",
      " 56%|    | 741M/1.31G [00:36<00:24, 23.8MB/s]\u001b[A\n",
      " 57%|    | 745M/1.31G [00:36<00:23, 24.3MB/s]\u001b[A\n",
      " 57%|    | 749M/1.31G [00:36<00:22, 24.7MB/s]\u001b[A\n",
      " 57%|    | 752M/1.31G [00:36<00:20, 26.8MB/s]\u001b[A\n",
      " 58%|    | 755M/1.31G [00:36<00:23, 23.3MB/s]\u001b[A\n",
      " 58%|    | 757M/1.31G [00:37<00:26, 20.8MB/s]\u001b[A\n",
      " 58%|    | 761M/1.31G [00:37<00:25, 21.3MB/s]\u001b[A\n",
      " 58%|    | 765M/1.31G [00:37<00:22, 24.6MB/s]\u001b[A\n",
      " 58%|    | 767M/1.31G [00:37<00:21, 24.9MB/s]\u001b[A\n",
      " 59%|    | 770M/1.31G [00:37<00:24, 21.9MB/s]\u001b[A\n",
      " 59%|    | 773M/1.31G [00:37<00:25, 20.8MB/s]\u001b[A\n",
      " 59%|    | 776M/1.31G [00:37<00:24, 21.5MB/s]\u001b[A\n",
      " 59%|    | 780M/1.31G [00:38<00:24, 22.0MB/s]\u001b[A\n",
      " 60%|    | 784M/1.31G [00:38<00:23, 22.4MB/s]\u001b[A\n",
      " 60%|    | 788M/1.31G [00:38<00:23, 22.7MB/s]\u001b[A\n",
      " 60%|    | 792M/1.31G [00:38<00:23, 22.4MB/s]\u001b[A\n",
      " 61%|    | 796M/1.31G [00:38<00:22, 22.7MB/s]\u001b[A\n",
      " 61%|    | 800M/1.31G [00:38<00:22, 23.0MB/s]\u001b[A\n",
      " 61%|   | 804M/1.31G [00:39<00:21, 23.2MB/s]\u001b[A\n",
      " 62%|   | 808M/1.31G [00:39<00:21, 23.2MB/s]\u001b[A\n",
      " 62%|   | 812M/1.31G [00:39<00:21, 23.3MB/s]\u001b[A\n",
      " 62%|   | 816M/1.31G [00:39<00:21, 23.5MB/s]\u001b[A\n",
      " 63%|   | 820M/1.31G [00:39<00:20, 23.6MB/s]\u001b[A\n",
      " 63%|   | 824M/1.31G [00:40<00:20, 24.2MB/s]\u001b[A\n",
      " 63%|   | 829M/1.31G [00:40<00:19, 24.7MB/s]\u001b[A\n",
      " 63%|   | 833M/1.31G [00:40<00:19, 25.0MB/s]\u001b[A\n",
      " 64%|   | 837M/1.31G [00:40<00:18, 25.3MB/s]\u001b[A\n",
      " 64%|   | 840M/1.31G [00:40<00:17, 26.9MB/s]\u001b[A\n",
      " 64%|   | 842M/1.31G [00:40<00:20, 23.3MB/s]\u001b[A\n",
      " 64%|   | 845M/1.31G [00:40<00:22, 20.7MB/s]\u001b[A\n",
      " 65%|   | 848M/1.31G [00:41<00:21, 21.4MB/s]\u001b[A\n",
      " 65%|   | 852M/1.31G [00:41<00:20, 22.1MB/s]\u001b[A\n",
      " 65%|   | 856M/1.31G [00:41<00:20, 22.4MB/s]\u001b[A\n",
      " 66%|   | 860M/1.31G [00:41<00:19, 22.7MB/s]\u001b[A\n",
      " 66%|   | 864M/1.31G [00:41<00:19, 22.9MB/s]\u001b[A\n",
      " 66%|   | 868M/1.31G [00:41<00:19, 23.1MB/s]\u001b[A\n",
      " 66%|   | 872M/1.31G [00:42<00:18, 23.3MB/s]\u001b[A\n",
      " 67%|   | 876M/1.31G [00:42<00:18, 23.3MB/s]\u001b[A\n",
      " 67%|   | 880M/1.31G [00:42<00:18, 23.4MB/s]\u001b[A\n",
      " 67%|   | 884M/1.31G [00:42<00:18, 23.2MB/s]\u001b[A\n",
      " 68%|   | 888M/1.31G [00:42<00:18, 22.6MB/s]\u001b[A\n",
      " 68%|   | 892M/1.31G [00:42<00:18, 23.0MB/s]\u001b[A\n",
      " 68%|   | 896M/1.31G [00:43<00:17, 23.2MB/s]\u001b[A\n",
      " 69%|   | 900M/1.31G [00:43<00:17, 23.2MB/s]\u001b[A\n",
      " 69%|   | 904M/1.31G [00:43<00:17, 23.4MB/s]\u001b[A\n",
      " 69%|   | 908M/1.31G [00:43<00:17, 23.5MB/s]\u001b[A\n",
      " 70%|   | 912M/1.31G [00:43<00:16, 23.6MB/s]\u001b[A\n",
      " 70%|   | 916M/1.31G [00:43<00:16, 23.7MB/s]\u001b[A\n",
      " 70%|   | 920M/1.31G [00:44<00:16, 23.5MB/s]\u001b[A\n",
      " 70%|   | 924M/1.31G [00:44<00:16, 23.0MB/s]\u001b[A\n",
      " 71%|   | 926M/1.31G [00:44<00:18, 20.9MB/s]\u001b[A\n",
      " 71%|   | 930M/1.31G [00:44<00:17, 21.7MB/s]\u001b[A\n",
      " 71%|   | 934M/1.31G [00:44<00:16, 22.3MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 938M/1.31G [00:44<00:16, 22.7MB/s]\u001b[A\n",
      " 72%|  | 942M/1.31G [00:45<00:16, 23.0MB/s]\u001b[A\n",
      " 72%|  | 946M/1.31G [00:45<00:15, 23.3MB/s]\u001b[A\n",
      " 72%|  | 950M/1.31G [00:45<00:15, 23.4MB/s]\u001b[A\n",
      " 73%|  | 954M/1.31G [00:45<00:15, 23.5MB/s]\u001b[A\n",
      " 73%|  | 958M/1.31G [00:45<00:14, 23.6MB/s]\u001b[A\n",
      " 73%|  | 962M/1.31G [00:45<00:14, 23.7MB/s]\u001b[A\n",
      " 74%|  | 966M/1.31G [00:46<00:14, 23.5MB/s]\u001b[A\n",
      " 74%|  | 970M/1.31G [00:46<00:14, 23.7MB/s]\u001b[A\n",
      " 74%|  | 974M/1.31G [00:46<00:14, 23.7MB/s]\u001b[A\n",
      " 75%|  | 978M/1.31G [00:46<00:14, 23.7MB/s]\u001b[A\n",
      " 75%|  | 982M/1.31G [00:46<00:14, 23.5MB/s]\u001b[A\n",
      " 75%|  | 986M/1.31G [00:46<00:13, 23.4MB/s]\u001b[A\n",
      " 75%|  | 990M/1.31G [00:47<00:13, 23.4MB/s]\u001b[A\n",
      " 76%|  | 994M/1.31G [00:47<00:13, 23.4MB/s]\u001b[A\n",
      " 76%|  | 998M/1.31G [00:47<00:13, 23.5MB/s]\u001b[A\n",
      " 76%|  | 1.00G/1.31G [00:47<00:13, 23.6MB/s]\u001b[A\n",
      " 77%|  | 1.01G/1.31G [00:47<00:13, 23.5MB/s]\u001b[A\n",
      " 77%|  | 1.01G/1.31G [00:47<00:12, 23.5MB/s]\u001b[A\n",
      " 77%|  | 1.01G/1.31G [00:48<00:12, 23.6MB/s]\u001b[A\n",
      " 78%|  | 1.02G/1.31G [00:48<00:12, 23.6MB/s]\u001b[A\n",
      " 78%|  | 1.02G/1.31G [00:48<00:12, 23.7MB/s]\u001b[A\n",
      " 78%|  | 1.03G/1.31G [00:48<00:12, 22.8MB/s]\u001b[A\n",
      " 78%|  | 1.03G/1.31G [00:48<00:12, 23.1MB/s]\u001b[A\n",
      " 79%|  | 1.03G/1.31G [00:48<00:11, 23.3MB/s]\u001b[A\n",
      " 79%|  | 1.04G/1.31G [00:49<00:11, 23.4MB/s]\u001b[A\n",
      " 79%|  | 1.04G/1.31G [00:49<00:11, 23.2MB/s]\u001b[A\n",
      " 80%|  | 1.05G/1.31G [00:49<00:11, 23.2MB/s]\u001b[A\n",
      " 80%|  | 1.05G/1.31G [00:49<00:11, 23.2MB/s]\u001b[A\n",
      " 80%|  | 1.05G/1.31G [00:49<00:11, 23.2MB/s]\u001b[A\n",
      " 81%|  | 1.06G/1.31G [00:49<00:10, 23.2MB/s]\u001b[A\n",
      " 81%|  | 1.06G/1.31G [00:50<00:10, 23.3MB/s]\u001b[A\n",
      " 81%|  | 1.07G/1.31G [00:50<00:10, 23.4MB/s]\u001b[A\n",
      " 82%| | 1.07G/1.31G [00:50<00:10, 23.5MB/s]\u001b[A\n",
      " 82%| | 1.07G/1.31G [00:50<00:10, 23.4MB/s]\u001b[A\n",
      " 82%| | 1.08G/1.31G [00:50<00:14, 16.3MB/s]\u001b[A\n",
      " 82%| | 1.08G/1.31G [00:51<00:11, 20.9MB/s]\u001b[A\n",
      " 83%| | 1.08G/1.31G [00:51<00:10, 22.2MB/s]\u001b[A\n",
      " 83%| | 1.09G/1.31G [00:51<00:11, 20.3MB/s]\u001b[A\n",
      " 83%| | 1.09G/1.31G [00:51<00:09, 23.9MB/s]\u001b[A\n",
      " 83%| | 1.10G/1.31G [00:51<00:10, 20.1MB/s]\u001b[A\n",
      " 84%| | 1.10G/1.31G [00:51<00:09, 23.4MB/s]\u001b[A\n",
      " 84%| | 1.10G/1.31G [00:51<00:09, 22.5MB/s]\u001b[A\n",
      " 84%| | 1.11G/1.31G [00:52<00:09, 21.9MB/s]\u001b[A\n",
      " 85%| | 1.11G/1.31G [00:52<00:09, 22.4MB/s]\u001b[A\n",
      " 85%| | 1.11G/1.31G [00:52<00:08, 22.8MB/s]\u001b[A\n",
      " 85%| | 1.12G/1.31G [00:52<00:08, 23.0MB/s]\u001b[A\n",
      " 85%| | 1.12G/1.31G [00:52<00:08, 23.1MB/s]\u001b[A\n",
      " 86%| | 1.12G/1.31G [00:52<00:08, 23.1MB/s]\u001b[A\n",
      " 86%| | 1.13G/1.31G [00:53<00:07, 23.2MB/s]\u001b[A\n",
      " 86%| | 1.13G/1.31G [00:53<00:07, 23.3MB/s]\u001b[A\n",
      " 87%| | 1.14G/1.31G [00:53<00:07, 23.4MB/s]\u001b[A\n",
      " 87%| | 1.14G/1.31G [00:53<00:07, 23.4MB/s]\u001b[A\n",
      " 87%| | 1.14G/1.31G [00:53<00:07, 23.0MB/s]\u001b[A\n",
      " 88%| | 1.15G/1.31G [00:53<00:07, 23.2MB/s]\u001b[A\n",
      " 88%| | 1.15G/1.31G [00:54<00:06, 23.3MB/s]\u001b[A\n",
      " 88%| | 1.16G/1.31G [00:54<00:06, 23.4MB/s]\u001b[A\n",
      " 88%| | 1.16G/1.31G [00:54<00:06, 23.4MB/s]\u001b[A\n",
      " 89%| | 1.16G/1.31G [00:54<00:06, 23.4MB/s]\u001b[A\n",
      " 89%| | 1.17G/1.31G [00:54<00:06, 23.5MB/s]\u001b[A\n",
      " 89%| | 1.17G/1.31G [00:54<00:05, 23.6MB/s]\u001b[A\n",
      " 90%| | 1.18G/1.31G [00:55<00:05, 23.6MB/s]\u001b[A\n",
      " 90%| | 1.18G/1.31G [00:55<00:05, 23.6MB/s]\u001b[A\n",
      " 90%| | 1.18G/1.31G [00:55<00:05, 23.6MB/s]\u001b[A\n",
      " 91%| | 1.19G/1.31G [00:55<00:05, 23.6MB/s]\u001b[A\n",
      " 91%| | 1.19G/1.31G [00:55<00:05, 23.5MB/s]\u001b[A\n",
      " 91%| | 1.20G/1.31G [00:55<00:04, 23.3MB/s]\u001b[A\n",
      " 91%|| 1.20G/1.31G [00:56<00:04, 23.4MB/s]\u001b[A\n",
      " 92%|| 1.20G/1.31G [00:56<00:04, 23.4MB/s]\u001b[A\n",
      " 92%|| 1.21G/1.31G [00:56<00:04, 23.4MB/s]\u001b[A\n",
      " 92%|| 1.21G/1.31G [00:56<00:04, 23.5MB/s]\u001b[A\n",
      " 93%|| 1.22G/1.31G [00:56<00:04, 23.5MB/s]\u001b[A\n",
      " 93%|| 1.22G/1.31G [00:56<00:03, 23.4MB/s]\u001b[A\n",
      " 93%|| 1.22G/1.31G [00:57<00:03, 23.5MB/s]\u001b[A\n",
      " 94%|| 1.23G/1.31G [00:57<00:03, 23.4MB/s]\u001b[A\n",
      " 94%|| 1.23G/1.31G [00:57<00:03, 23.4MB/s]\u001b[A\n",
      " 94%|| 1.24G/1.31G [00:57<00:03, 23.4MB/s]\u001b[A\n",
      " 95%|| 1.24G/1.31G [00:57<00:03, 23.5MB/s]\u001b[A\n",
      " 95%|| 1.24G/1.31G [00:57<00:02, 23.6MB/s]\u001b[A\n",
      " 95%|| 1.25G/1.31G [00:58<00:02, 23.6MB/s]\u001b[A\n",
      " 95%|| 1.25G/1.31G [00:58<00:02, 23.6MB/s]\u001b[A\n",
      " 96%|| 1.26G/1.31G [00:58<00:02, 23.6MB/s]\u001b[A\n",
      " 96%|| 1.26G/1.31G [00:58<00:02, 23.6MB/s]\u001b[A\n",
      " 96%|| 1.26G/1.31G [00:58<00:02, 23.7MB/s]\u001b[A\n",
      " 97%|| 1.27G/1.31G [00:58<00:01, 23.7MB/s]\u001b[A\n",
      " 97%|| 1.27G/1.31G [00:59<00:01, 23.8MB/s]\u001b[A\n",
      " 97%|| 1.28G/1.31G [00:59<00:01, 23.6MB/s]\u001b[A\n",
      " 98%|| 1.28G/1.31G [00:59<00:01, 23.5MB/s]\u001b[A\n",
      " 98%|| 1.28G/1.31G [00:59<00:01, 23.4MB/s]\u001b[A\n",
      " 98%|| 1.29G/1.31G [00:59<00:01, 23.4MB/s]\u001b[A\n",
      " 98%|| 1.29G/1.31G [00:59<00:00, 23.4MB/s]\u001b[A\n",
      " 99%|| 1.30G/1.31G [01:00<00:00, 23.5MB/s]\u001b[A\n",
      " 99%|| 1.30G/1.31G [01:00<00:00, 23.5MB/s]\u001b[A\n",
      " 99%|| 1.30G/1.31G [01:00<00:00, 23.6MB/s]\u001b[A\n",
      "100%|| 1.31G/1.31G [01:00<00:00, 23.6MB/s]\u001b[A\n",
      "100%|| 1.31G/1.31G [01:00<00:00, 21.6MB/s]\u001b[A\n",
      "\n",
      "  0%|          | 0.00/1.24G [00:00<?, ?B/s]\u001b[A\n",
      "  0%|          | 16.4k/1.24G [00:00<3:13:55, 107kB/s]\u001b[A\n",
      "  0%|          | 49.2k/1.24G [00:00<2:46:17, 125kB/s]\u001b[A\n",
      "  0%|          | 98.3k/1.24G [00:00<2:16:42, 152kB/s]\u001b[A\n",
      "  0%|          | 147k/1.24G [00:00<1:55:57, 179kB/s] \u001b[A\n",
      "  0%|          | 229k/1.24G [00:00<1:33:27, 222kB/s]\u001b[A\n",
      "  0%|          | 328k/1.24G [00:00<1:15:32, 274kB/s]\u001b[A\n",
      "  0%|          | 442k/1.24G [00:01<1:01:33, 337kB/s]\u001b[A\n",
      "  0%|          | 590k/1.24G [00:01<49:51, 415kB/s]  \u001b[A\n",
      "  0%|          | 754k/1.24G [00:01<40:58, 506kB/s]\u001b[A\n",
      "  0%|          | 967k/1.24G [00:01<33:23, 620kB/s]\u001b[A\n",
      "  0%|          | 1.21M/1.24G [00:01<27:25, 755kB/s]\u001b[A\n",
      "  0%|          | 1.49M/1.24G [00:01<22:45, 909kB/s]\u001b[A\n",
      "  0%|          | 1.82M/1.24G [00:02<18:18, 1.13MB/s]\u001b[A\n",
      "  0%|          | 2.21M/1.24G [00:02<14:38, 1.41MB/s]\u001b[A\n",
      "  0%|          | 2.54M/1.24G [00:02<12:29, 1.65MB/s]\u001b[A\n",
      "  0%|          | 2.78M/1.24G [00:02<12:01, 1.72MB/s]\u001b[A\n",
      "  0%|          | 3.28M/1.24G [00:02<09:58, 2.07MB/s]\u001b[A\n",
      "  0%|          | 3.92M/1.24G [00:02<08:03, 2.56MB/s]\u001b[A\n",
      "  0%|          | 4.42M/1.24G [00:02<07:05, 2.91MB/s]\u001b[A\n",
      "  0%|          | 4.81M/1.24G [00:02<06:59, 2.95MB/s]\u001b[A\n",
      "  0%|          | 5.64M/1.24G [00:03<05:48, 3.56MB/s]\u001b[A\n",
      "  1%|          | 6.65M/1.24G [00:03<04:45, 4.33MB/s]\u001b[A\n",
      "  1%|          | 7.44M/1.24G [00:03<04:06, 5.01MB/s]\u001b[A\n",
      "  1%|          | 8.09M/1.24G [00:03<04:17, 4.81MB/s]\u001b[A\n",
      "  1%|          | 9.32M/1.24G [00:03<03:35, 5.72MB/s]\u001b[A\n",
      "  1%|          | 10.8M/1.24G [00:03<02:58, 6.90MB/s]\u001b[A\n",
      "  1%|          | 11.7M/1.24G [00:03<02:46, 7.41MB/s]\u001b[A\n",
      "  1%|          | 12.8M/1.24G [00:03<02:34, 7.95MB/s]\u001b[A\n",
      "  1%|          | 14.7M/1.24G [00:03<02:09, 9.48MB/s]\u001b[A\n",
      "  1%|         | 15.9M/1.24G [00:04<02:03, 9.91MB/s]\u001b[A\n",
      "  1%|         | 17.3M/1.24G [00:04<01:54, 10.7MB/s]\u001b[A\n",
      "  2%|         | 19.7M/1.24G [00:04<01:36, 12.6MB/s]\u001b[A\n",
      "  2%|         | 21.2M/1.24G [00:04<01:39, 12.3MB/s]\u001b[A\n",
      "  2%|         | 22.9M/1.24G [00:04<01:33, 13.0MB/s]\u001b[A\n",
      "  2%|         | 25.6M/1.24G [00:04<01:22, 14.8MB/s]\u001b[A\n",
      "  2%|         | 28.4M/1.24G [00:04<01:10, 17.2MB/s]\u001b[A\n",
      "  2%|         | 30.4M/1.24G [00:04<01:16, 15.9MB/s]\u001b[A\n",
      "  3%|         | 32.2M/1.24G [00:04<01:19, 15.2MB/s]\u001b[A\n",
      "  3%|         | 34.8M/1.24G [00:05<01:10, 17.2MB/s]\u001b[A\n",
      "  3%|         | 36.7M/1.24G [00:05<01:13, 16.5MB/s]\u001b[A\n",
      "  3%|         | 38.7M/1.24G [00:05<01:12, 16.6MB/s]\u001b[A\n",
      "  3%|         | 41.5M/1.24G [00:05<01:06, 18.1MB/s]\u001b[A\n",
      "  4%|         | 43.9M/1.24G [00:05<01:01, 19.6MB/s]\u001b[A\n",
      "  4%|         | 46.0M/1.24G [00:05<01:07, 17.7MB/s]\u001b[A\n",
      "  4%|         | 47.9M/1.24G [00:05<01:05, 18.2MB/s]\u001b[A\n",
      "  4%|         | 51.0M/1.24G [00:05<01:02, 19.1MB/s]\u001b[A\n",
      "  4%|         | 53.3M/1.24G [00:06<00:59, 20.1MB/s]\u001b[A\n",
      "  4%|         | 55.3M/1.24G [00:06<01:01, 19.2MB/s]\u001b[A\n",
      "  5%|         | 57.9M/1.24G [00:06<00:57, 20.8MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 60.1M/1.24G [00:06<00:58, 20.2MB/s]\u001b[A\n",
      "  5%|         | 62.2M/1.24G [00:06<01:02, 18.8MB/s]\u001b[A\n",
      "  5%|         | 65.1M/1.24G [00:06<00:59, 19.7MB/s]\u001b[A\n",
      "  5%|         | 68.3M/1.24G [00:06<00:52, 22.3MB/s]\u001b[A\n",
      "  6%|         | 70.7M/1.24G [00:06<00:55, 21.1MB/s]\u001b[A\n",
      "  6%|         | 72.9M/1.24G [00:07<01:01, 19.1MB/s]\u001b[A\n",
      "  6%|         | 76.1M/1.24G [00:07<00:55, 21.1MB/s]\u001b[A\n",
      "  6%|         | 78.5M/1.24G [00:07<00:55, 20.8MB/s]\u001b[A\n",
      "  6%|         | 80.7M/1.24G [00:07<00:58, 19.9MB/s]\u001b[A\n",
      "  7%|         | 83.8M/1.24G [00:07<00:57, 20.3MB/s]\u001b[A\n",
      "  7%|         | 87.0M/1.24G [00:07<00:50, 22.8MB/s]\u001b[A\n",
      "  7%|         | 89.4M/1.24G [00:07<00:53, 21.7MB/s]\u001b[A\n",
      "  7%|         | 91.7M/1.24G [00:07<01:00, 19.2MB/s]\u001b[A\n",
      "  8%|         | 95.0M/1.24G [00:08<00:57, 20.1MB/s]\u001b[A\n",
      "  8%|         | 98.4M/1.24G [00:08<00:50, 22.8MB/s]\u001b[A\n",
      "  8%|         | 101M/1.24G [00:08<00:56, 20.1MB/s] \u001b[A\n",
      "  8%|         | 103M/1.24G [00:08<00:59, 19.1MB/s]\u001b[A\n",
      "  9%|         | 107M/1.24G [00:08<00:52, 21.6MB/s]\u001b[A\n",
      "  9%|         | 109M/1.24G [00:08<00:56, 20.0MB/s]\u001b[A\n",
      "  9%|         | 111M/1.24G [00:08<00:54, 20.7MB/s]\u001b[A\n",
      "  9%|         | 114M/1.24G [00:08<00:53, 21.0MB/s]\u001b[A\n",
      "  9%|         | 117M/1.24G [00:09<00:53, 21.1MB/s]\u001b[A\n",
      " 10%|         | 119M/1.24G [00:09<00:51, 21.8MB/s]\u001b[A\n",
      " 10%|         | 122M/1.24G [00:09<00:48, 23.2MB/s]\u001b[A\n",
      " 10%|         | 125M/1.24G [00:09<00:53, 21.0MB/s]\u001b[A\n",
      " 10%|         | 127M/1.24G [00:09<00:54, 20.6MB/s]\u001b[A\n",
      " 10%|         | 130M/1.24G [00:09<00:55, 20.1MB/s]\u001b[A\n",
      " 11%|         | 133M/1.24G [00:09<00:54, 20.5MB/s]\u001b[A\n",
      " 11%|         | 137M/1.24G [00:09<00:53, 20.8MB/s]\u001b[A\n",
      " 11%|        | 141M/1.24G [00:10<00:51, 21.3MB/s]\u001b[A\n",
      " 12%|        | 145M/1.24G [00:10<00:49, 22.1MB/s]\u001b[A\n",
      " 12%|        | 149M/1.24G [00:10<00:50, 21.7MB/s]\u001b[A\n",
      " 12%|        | 153M/1.24G [00:10<00:48, 22.4MB/s]\u001b[A\n",
      " 13%|        | 156M/1.24G [00:10<00:45, 24.1MB/s]\u001b[A\n",
      " 13%|        | 158M/1.24G [00:10<00:46, 23.4MB/s]\u001b[A\n",
      " 13%|        | 161M/1.24G [00:11<00:51, 21.0MB/s]\u001b[A\n",
      " 13%|        | 165M/1.24G [00:11<00:44, 24.3MB/s]\u001b[A\n",
      " 13%|        | 167M/1.24G [00:11<00:49, 21.7MB/s]\u001b[A\n",
      " 14%|        | 170M/1.24G [00:11<00:50, 21.1MB/s]\u001b[A\n",
      " 14%|        | 173M/1.24G [00:11<00:50, 21.3MB/s]\u001b[A\n",
      " 14%|        | 175M/1.24G [00:11<00:51, 20.9MB/s]\u001b[A\n",
      " 14%|        | 178M/1.24G [00:11<00:47, 22.4MB/s]\u001b[A\n",
      " 14%|        | 180M/1.24G [00:11<00:50, 21.2MB/s]\u001b[A\n",
      " 15%|        | 182M/1.24G [00:11<00:50, 21.0MB/s]\u001b[A\n",
      " 15%|        | 184M/1.24G [00:12<00:50, 20.9MB/s]\u001b[A\n",
      " 15%|        | 187M/1.24G [00:12<00:45, 23.0MB/s]\u001b[A\n",
      " 15%|        | 190M/1.24G [00:12<00:45, 23.0MB/s]\u001b[A\n",
      " 15%|        | 192M/1.24G [00:12<00:53, 19.5MB/s]\u001b[A\n",
      " 16%|        | 196M/1.24G [00:12<00:52, 20.0MB/s]\u001b[A\n",
      " 16%|        | 200M/1.24G [00:12<00:50, 20.7MB/s]\u001b[A\n",
      " 16%|        | 204M/1.24G [00:13<00:50, 20.6MB/s]\u001b[A\n",
      " 17%|        | 208M/1.24G [00:13<00:49, 21.1MB/s]\u001b[A\n",
      " 17%|        | 212M/1.24G [00:13<00:48, 21.5MB/s]\u001b[A\n",
      " 17%|        | 215M/1.24G [00:13<00:41, 24.6MB/s]\u001b[A\n",
      " 18%|        | 218M/1.24G [00:13<00:47, 21.4MB/s]\u001b[A\n",
      " 18%|        | 220M/1.24G [00:13<00:48, 21.2MB/s]\u001b[A\n",
      " 18%|        | 223M/1.24G [00:13<00:48, 20.9MB/s]\u001b[A\n",
      " 18%|        | 227M/1.24G [00:13<00:43, 23.3MB/s]\u001b[A\n",
      " 18%|        | 229M/1.24G [00:14<00:48, 20.8MB/s]\u001b[A\n",
      " 19%|        | 231M/1.24G [00:14<00:48, 21.0MB/s]\u001b[A\n",
      " 19%|        | 234M/1.24G [00:14<00:47, 21.1MB/s]\u001b[A\n",
      " 19%|        | 237M/1.24G [00:14<00:42, 23.4MB/s]\u001b[A\n",
      " 19%|        | 239M/1.24G [00:14<00:46, 21.4MB/s]\u001b[A\n",
      " 19%|        | 242M/1.24G [00:14<00:47, 21.3MB/s]\u001b[A\n",
      " 20%|        | 245M/1.24G [00:14<00:47, 21.1MB/s]\u001b[A\n",
      " 20%|        | 247M/1.24G [00:14<00:45, 21.9MB/s]\u001b[A\n",
      " 20%|        | 250M/1.24G [00:15<00:45, 22.0MB/s]\u001b[A\n",
      " 20%|        | 252M/1.24G [00:15<00:44, 22.5MB/s]\u001b[A\n",
      " 20%|        | 254M/1.24G [00:15<00:48, 20.3MB/s]\u001b[A\n",
      " 21%|        | 257M/1.24G [00:15<00:45, 21.6MB/s]\u001b[A\n",
      " 21%|        | 259M/1.24G [00:15<00:44, 22.0MB/s]\u001b[A\n",
      " 21%|        | 262M/1.24G [00:15<00:46, 21.2MB/s]\u001b[A\n",
      " 21%|       | 265M/1.24G [00:15<00:44, 22.2MB/s]\u001b[A\n",
      " 21%|       | 267M/1.24G [00:15<00:43, 22.2MB/s]\u001b[A\n",
      " 22%|       | 270M/1.24G [00:15<00:40, 24.2MB/s]\u001b[A\n",
      " 22%|       | 273M/1.24G [00:16<00:48, 19.9MB/s]\u001b[A\n",
      " 22%|       | 276M/1.24G [00:16<00:49, 19.7MB/s]\u001b[A\n",
      " 22%|       | 280M/1.24G [00:16<00:47, 20.4MB/s]\u001b[A\n",
      " 23%|       | 284M/1.24G [00:16<00:45, 20.9MB/s]\u001b[A\n",
      " 23%|       | 287M/1.24G [00:16<00:46, 20.3MB/s]\u001b[A\n",
      " 23%|       | 290M/1.24G [00:17<00:48, 19.6MB/s]\u001b[A\n",
      " 24%|       | 294M/1.24G [00:17<00:46, 20.4MB/s]\u001b[A\n",
      " 24%|       | 298M/1.24G [00:17<00:45, 20.9MB/s]\u001b[A\n",
      " 24%|       | 302M/1.24G [00:17<00:44, 21.4MB/s]\u001b[A\n",
      " 25%|       | 306M/1.24G [00:17<00:43, 21.6MB/s]\u001b[A\n",
      " 25%|       | 310M/1.24G [00:17<00:42, 21.9MB/s]\u001b[A\n",
      " 25%|       | 314M/1.24G [00:18<00:42, 22.0MB/s]\u001b[A\n",
      " 26%|       | 318M/1.24G [00:18<00:41, 22.2MB/s]\u001b[A\n",
      " 26%|       | 322M/1.24G [00:18<00:41, 22.3MB/s]\u001b[A\n",
      " 26%|       | 326M/1.24G [00:18<00:41, 22.1MB/s]\u001b[A\n",
      " 27%|       | 330M/1.24G [00:18<00:41, 22.1MB/s]\u001b[A\n",
      " 27%|       | 334M/1.24G [00:18<00:41, 22.1MB/s]\u001b[A\n",
      " 27%|       | 338M/1.24G [00:19<00:40, 22.2MB/s]\u001b[A\n",
      " 28%|       | 342M/1.24G [00:19<00:41, 22.0MB/s]\u001b[A\n",
      " 28%|       | 346M/1.24G [00:19<00:40, 22.1MB/s]\u001b[A\n",
      " 28%|       | 350M/1.24G [00:19<00:40, 22.1MB/s]\u001b[A\n",
      " 28%|       | 354M/1.24G [00:19<00:40, 22.1MB/s]\u001b[A\n",
      " 29%|       | 358M/1.24G [00:20<00:40, 22.1MB/s]\u001b[A\n",
      " 29%|       | 362M/1.24G [00:20<00:39, 22.2MB/s]\u001b[A\n",
      " 29%|       | 366M/1.24G [00:20<00:39, 22.3MB/s]\u001b[A\n",
      " 30%|       | 370M/1.24G [00:20<00:39, 22.3MB/s]\u001b[A\n",
      " 30%|       | 373M/1.24G [00:20<00:34, 25.3MB/s]\u001b[A\n",
      " 30%|       | 376M/1.24G [00:20<00:39, 22.1MB/s]\u001b[A\n",
      " 30%|       | 379M/1.24G [00:20<00:40, 21.6MB/s]\u001b[A\n",
      " 31%|       | 381M/1.24G [00:21<00:42, 20.4MB/s]\u001b[A\n",
      " 31%|       | 385M/1.24G [00:21<00:41, 20.5MB/s]\u001b[A\n",
      " 31%|      | 389M/1.24G [00:21<00:40, 21.1MB/s]\u001b[A\n",
      " 32%|      | 393M/1.24G [00:21<00:39, 21.4MB/s]\u001b[A\n",
      " 32%|      | 397M/1.24G [00:21<00:39, 21.7MB/s]\u001b[A\n",
      " 32%|      | 401M/1.24G [00:22<00:38, 21.7MB/s]\u001b[A\n",
      " 33%|      | 405M/1.24G [00:22<00:34, 24.6MB/s]\u001b[A\n",
      " 33%|      | 407M/1.24G [00:22<00:39, 21.2MB/s]\u001b[A\n",
      " 33%|      | 409M/1.24G [00:22<00:44, 18.6MB/s]\u001b[A\n",
      " 33%|      | 412M/1.24G [00:22<00:45, 18.3MB/s]\u001b[A\n",
      " 33%|      | 416M/1.24G [00:22<00:42, 19.3MB/s]\u001b[A\n",
      " 34%|      | 420M/1.24G [00:22<00:40, 20.1MB/s]\u001b[A\n",
      " 34%|      | 424M/1.24G [00:23<00:39, 20.8MB/s]\u001b[A\n",
      " 34%|      | 428M/1.24G [00:23<00:38, 21.3MB/s]\u001b[A\n",
      " 35%|      | 432M/1.24G [00:23<00:37, 21.6MB/s]\u001b[A\n",
      " 35%|      | 436M/1.24G [00:23<00:36, 21.9MB/s]\u001b[A\n",
      " 35%|      | 440M/1.24G [00:23<00:36, 22.1MB/s]\u001b[A\n",
      " 36%|      | 444M/1.24G [00:24<00:36, 21.7MB/s]\u001b[A\n",
      " 36%|      | 448M/1.24G [00:24<00:36, 22.0MB/s]\u001b[A\n",
      " 36%|      | 451M/1.24G [00:24<00:37, 21.2MB/s]\u001b[A\n",
      " 37%|      | 454M/1.24G [00:24<00:38, 20.3MB/s]\u001b[A\n",
      " 37%|      | 458M/1.24G [00:24<00:37, 20.8MB/s]\u001b[A\n",
      " 37%|      | 462M/1.24G [00:24<00:36, 21.2MB/s]\u001b[A\n",
      " 37%|      | 465M/1.24G [00:24<00:32, 23.6MB/s]\u001b[A\n",
      " 38%|      | 468M/1.24G [00:25<00:33, 23.3MB/s]\u001b[A\n",
      " 38%|      | 470M/1.24G [00:25<00:37, 20.4MB/s]\u001b[A\n",
      " 38%|      | 474M/1.24G [00:25<00:33, 23.1MB/s]\u001b[A\n",
      " 38%|      | 476M/1.24G [00:25<00:32, 23.4MB/s]\u001b[A\n",
      " 38%|      | 479M/1.24G [00:25<00:36, 20.8MB/s]\u001b[A\n",
      " 39%|      | 482M/1.24G [00:25<00:32, 23.1MB/s]\u001b[A\n",
      " 39%|      | 484M/1.24G [00:25<00:36, 20.7MB/s]\u001b[A\n",
      " 39%|      | 486M/1.24G [00:25<00:36, 20.8MB/s]\u001b[A\n",
      " 39%|      | 490M/1.24G [00:26<00:36, 20.9MB/s]\u001b[A\n",
      " 40%|      | 493M/1.24G [00:26<00:33, 22.4MB/s]\u001b[A\n",
      " 40%|      | 495M/1.24G [00:26<00:35, 20.9MB/s]\u001b[A\n",
      " 40%|      | 498M/1.24G [00:26<00:36, 20.3MB/s]\u001b[A\n",
      " 40%|      | 502M/1.24G [00:26<00:35, 20.9MB/s]\u001b[A\n",
      " 41%|      | 506M/1.24G [00:26<00:35, 21.0MB/s]\u001b[A\n",
      " 41%|      | 509M/1.24G [00:27<00:36, 20.0MB/s]\u001b[A\n",
      " 41%|      | 513M/1.24G [00:27<00:35, 20.7MB/s]\u001b[A\n",
      " 42%|     | 517M/1.24G [00:27<00:34, 21.1MB/s]\u001b[A\n",
      " 42%|     | 520M/1.24G [00:27<00:33, 21.6MB/s]\u001b[A\n",
      " 42%|     | 524M/1.24G [00:27<00:32, 22.0MB/s]\u001b[A\n",
      " 42%|     | 528M/1.24G [00:27<00:29, 24.6MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 531M/1.24G [00:27<00:31, 22.5MB/s]\u001b[A\n",
      " 43%|     | 533M/1.24G [00:28<00:33, 21.3MB/s]\u001b[A\n",
      " 43%|     | 536M/1.24G [00:28<00:34, 20.6MB/s]\u001b[A\n",
      " 43%|     | 540M/1.24G [00:28<00:33, 21.2MB/s]\u001b[A\n",
      " 44%|     | 544M/1.24G [00:28<00:32, 21.6MB/s]\u001b[A\n",
      " 44%|     | 548M/1.24G [00:28<00:32, 21.6MB/s]\u001b[A\n",
      " 44%|     | 552M/1.24G [00:28<00:31, 21.8MB/s]\u001b[A\n",
      " 45%|     | 556M/1.24G [00:29<00:31, 21.9MB/s]\u001b[A\n",
      " 45%|     | 560M/1.24G [00:29<00:31, 22.0MB/s]\u001b[A\n",
      " 45%|     | 564M/1.24G [00:29<00:30, 22.3MB/s]\u001b[A\n",
      " 46%|     | 568M/1.24G [00:29<00:29, 22.6MB/s]\u001b[A\n",
      " 46%|     | 572M/1.24G [00:29<00:29, 22.7MB/s]\u001b[A\n",
      " 46%|     | 575M/1.24G [00:29<00:26, 25.3MB/s]\u001b[A\n",
      " 46%|     | 578M/1.24G [00:30<00:26, 24.8MB/s]\u001b[A\n",
      " 47%|     | 580M/1.24G [00:30<00:30, 21.4MB/s]\u001b[A\n",
      " 47%|     | 584M/1.24G [00:30<00:31, 21.2MB/s]\u001b[A\n",
      " 47%|     | 586M/1.24G [00:30<00:29, 22.1MB/s]\u001b[A\n",
      " 47%|     | 589M/1.24G [00:30<00:28, 23.3MB/s]\u001b[A\n",
      " 48%|     | 591M/1.24G [00:30<00:26, 24.2MB/s]\u001b[A\n",
      " 48%|     | 594M/1.24G [00:30<00:31, 20.6MB/s]\u001b[A\n",
      " 48%|     | 598M/1.24G [00:30<00:30, 21.3MB/s]\u001b[A\n",
      " 48%|     | 601M/1.24G [00:31<00:26, 24.5MB/s]\u001b[A\n",
      " 49%|     | 604M/1.24G [00:31<00:29, 21.4MB/s]\u001b[A\n",
      " 49%|     | 607M/1.24G [00:31<00:29, 21.6MB/s]\u001b[A\n",
      " 49%|     | 610M/1.24G [00:31<00:29, 21.2MB/s]\u001b[A\n",
      " 49%|     | 612M/1.24G [00:31<00:31, 20.0MB/s]\u001b[A\n",
      " 49%|     | 615M/1.24G [00:31<00:31, 20.1MB/s]\u001b[A\n",
      " 50%|     | 619M/1.24G [00:31<00:30, 20.8MB/s]\u001b[A\n",
      " 50%|     | 623M/1.24G [00:32<00:30, 20.0MB/s]\u001b[A\n",
      " 50%|     | 627M/1.24G [00:32<00:29, 20.9MB/s]\u001b[A\n",
      " 51%|     | 631M/1.24G [00:32<00:28, 21.5MB/s]\u001b[A\n",
      " 51%|     | 635M/1.24G [00:32<00:27, 21.8MB/s]\u001b[A\n",
      " 51%|    | 639M/1.24G [00:32<00:27, 22.1MB/s]\u001b[A\n",
      " 52%|    | 643M/1.24G [00:33<00:26, 22.3MB/s]\u001b[A\n",
      " 52%|    | 647M/1.24G [00:33<00:26, 22.4MB/s]\u001b[A\n",
      " 52%|    | 651M/1.24G [00:33<00:26, 22.4MB/s]\u001b[A\n",
      " 53%|    | 655M/1.24G [00:33<00:25, 22.6MB/s]\u001b[A\n",
      " 53%|    | 659M/1.24G [00:33<00:25, 22.8MB/s]\u001b[A\n",
      " 53%|    | 663M/1.24G [00:33<00:25, 22.8MB/s]\u001b[A\n",
      " 54%|    | 667M/1.24G [00:34<00:25, 22.9MB/s]\u001b[A\n",
      " 54%|    | 670M/1.24G [00:34<00:26, 21.8MB/s]\u001b[A\n",
      " 54%|    | 673M/1.24G [00:34<00:28, 19.8MB/s]\u001b[A\n",
      " 54%|    | 677M/1.24G [00:34<00:27, 20.6MB/s]\u001b[A\n",
      " 55%|    | 681M/1.24G [00:34<00:26, 21.3MB/s]\u001b[A\n",
      " 55%|    | 685M/1.24G [00:34<00:25, 21.6MB/s]\u001b[A\n",
      " 55%|    | 687M/1.24G [00:35<00:26, 20.7MB/s]\u001b[A\n",
      " 56%|    | 690M/1.24G [00:35<00:23, 23.2MB/s]\u001b[A\n",
      " 56%|    | 693M/1.24G [00:35<00:26, 20.9MB/s]\u001b[A\n",
      " 56%|    | 697M/1.24G [00:35<00:25, 21.4MB/s]\u001b[A\n",
      " 56%|    | 699M/1.24G [00:35<00:27, 19.7MB/s]\u001b[A\n",
      " 57%|    | 703M/1.24G [00:35<00:23, 23.1MB/s]\u001b[A\n",
      " 57%|    | 706M/1.24G [00:35<00:24, 22.0MB/s]\u001b[A\n",
      " 57%|    | 709M/1.24G [00:36<00:24, 21.6MB/s]\u001b[A\n",
      " 57%|    | 713M/1.24G [00:36<00:24, 22.1MB/s]\u001b[A\n",
      " 58%|    | 717M/1.24G [00:36<00:23, 22.4MB/s]\u001b[A\n",
      " 58%|    | 721M/1.24G [00:36<00:23, 22.5MB/s]\u001b[A\n",
      " 58%|    | 725M/1.24G [00:36<00:23, 22.2MB/s]\u001b[A\n",
      " 59%|    | 729M/1.24G [00:36<00:23, 22.2MB/s]\u001b[A\n",
      " 59%|    | 733M/1.24G [00:37<00:23, 22.1MB/s]\u001b[A\n",
      " 59%|    | 737M/1.24G [00:37<00:22, 22.3MB/s]\u001b[A\n",
      " 60%|    | 740M/1.24G [00:37<00:22, 22.5MB/s]\u001b[A\n",
      " 60%|    | 744M/1.24G [00:37<00:22, 22.6MB/s]\u001b[A\n",
      " 60%|    | 748M/1.24G [00:37<00:21, 22.7MB/s]\u001b[A\n",
      " 61%|    | 752M/1.24G [00:37<00:21, 22.7MB/s]\u001b[A\n",
      " 61%|    | 756M/1.24G [00:38<00:21, 22.7MB/s]\u001b[A\n",
      " 61%|    | 760M/1.24G [00:38<00:21, 22.8MB/s]\u001b[A\n",
      " 61%|   | 764M/1.24G [00:38<00:21, 22.8MB/s]\u001b[A\n",
      " 62%|   | 768M/1.24G [00:38<00:20, 22.8MB/s]\u001b[A\n",
      " 62%|   | 772M/1.24G [00:38<00:20, 22.9MB/s]\u001b[A\n",
      " 62%|   | 776M/1.24G [00:39<00:20, 22.8MB/s]\u001b[A\n",
      " 63%|   | 780M/1.24G [00:39<00:20, 22.9MB/s]\u001b[A\n",
      " 63%|   | 784M/1.24G [00:39<00:20, 22.9MB/s]\u001b[A\n",
      " 63%|   | 788M/1.24G [00:39<00:19, 22.9MB/s]\u001b[A\n",
      " 64%|   | 792M/1.24G [00:39<00:19, 23.0MB/s]\u001b[A\n",
      " 64%|   | 796M/1.24G [00:39<00:19, 22.9MB/s]\u001b[A\n",
      " 64%|   | 800M/1.24G [00:40<00:19, 22.8MB/s]\u001b[A\n",
      " 65%|   | 804M/1.24G [00:40<00:19, 22.5MB/s]\u001b[A\n",
      " 65%|   | 808M/1.24G [00:40<00:19, 22.6MB/s]\u001b[A\n",
      " 65%|   | 812M/1.24G [00:40<00:19, 22.6MB/s]\u001b[A\n",
      " 66%|   | 816M/1.24G [00:40<00:19, 22.2MB/s]\u001b[A\n",
      " 66%|   | 820M/1.24G [00:40<00:18, 22.4MB/s]\u001b[A\n",
      " 66%|   | 824M/1.24G [00:41<00:18, 22.5MB/s]\u001b[A\n",
      " 67%|   | 828M/1.24G [00:41<00:18, 22.7MB/s]\u001b[A\n",
      " 67%|   | 832M/1.24G [00:41<00:18, 22.7MB/s]\u001b[A\n",
      " 67%|   | 836M/1.24G [00:41<00:17, 22.8MB/s]\u001b[A\n",
      " 68%|   | 840M/1.24G [00:41<00:17, 22.8MB/s]\u001b[A\n",
      " 68%|   | 844M/1.24G [00:41<00:17, 22.8MB/s]\u001b[A\n",
      " 68%|   | 848M/1.24G [00:42<00:17, 22.9MB/s]\u001b[A\n",
      " 68%|   | 851M/1.24G [00:42<00:28, 13.7MB/s]\u001b[A\n",
      " 69%|   | 853M/1.24G [00:42<00:29, 13.3MB/s]\u001b[A\n",
      " 69%|   | 855M/1.24G [00:42<00:28, 13.6MB/s]\u001b[A\n",
      " 69%|   | 858M/1.24G [00:43<00:27, 14.2MB/s]\u001b[A\n",
      " 69%|   | 861M/1.24G [00:43<00:25, 14.9MB/s]\u001b[A\n",
      " 69%|   | 863M/1.24G [00:43<00:24, 15.5MB/s]\u001b[A\n",
      " 70%|   | 866M/1.24G [00:43<00:23, 16.1MB/s]\u001b[A\n",
      " 70%|   | 869M/1.24G [00:43<00:21, 17.1MB/s]\u001b[A\n",
      " 70%|   | 873M/1.24G [00:43<00:20, 18.0MB/s]\u001b[A\n",
      " 70%|   | 876M/1.24G [00:44<00:19, 18.7MB/s]\u001b[A\n",
      " 71%|   | 879M/1.24G [00:44<00:18, 19.4MB/s]\u001b[A\n",
      " 71%|   | 883M/1.24G [00:44<00:18, 19.9MB/s]\u001b[A\n",
      " 71%|  | 886M/1.24G [00:44<00:17, 20.4MB/s]\u001b[A\n",
      " 72%|  | 890M/1.24G [00:44<00:17, 20.8MB/s]\u001b[A\n",
      " 72%|  | 893M/1.24G [00:44<00:15, 23.3MB/s]\u001b[A\n",
      " 72%|  | 896M/1.24G [00:44<00:17, 20.2MB/s]\u001b[A\n",
      " 72%|  | 898M/1.24G [00:45<00:19, 17.9MB/s]\u001b[A\n",
      " 72%|  | 900M/1.24G [00:45<00:19, 17.6MB/s]\u001b[A\n",
      " 73%|  | 904M/1.24G [00:45<00:18, 18.8MB/s]\u001b[A\n",
      " 73%|  | 907M/1.24G [00:45<00:17, 19.8MB/s]\u001b[A\n",
      " 73%|  | 911M/1.24G [00:45<00:16, 20.5MB/s]\u001b[A\n",
      " 74%|  | 915M/1.24G [00:45<00:15, 21.2MB/s]\u001b[A\n",
      " 74%|  | 918M/1.24G [00:46<00:17, 18.5MB/s]\u001b[A\n",
      " 74%|  | 921M/1.24G [00:46<00:16, 19.7MB/s]\u001b[A\n",
      " 74%|  | 925M/1.24G [00:46<00:15, 20.6MB/s]\u001b[A\n",
      " 75%|  | 929M/1.24G [00:46<00:13, 23.8MB/s]\u001b[A\n",
      " 75%|  | 931M/1.24G [00:46<00:14, 21.2MB/s]\u001b[A\n",
      " 75%|  | 934M/1.24G [00:46<00:16, 19.0MB/s]\u001b[A\n",
      " 75%|  | 936M/1.24G [00:46<00:16, 18.1MB/s]\u001b[A\n",
      " 76%|  | 939M/1.24G [00:47<00:14, 20.6MB/s]\u001b[A\n",
      " 76%|  | 941M/1.24G [00:47<00:14, 21.2MB/s]\u001b[A\n",
      " 76%|  | 944M/1.24G [00:47<00:14, 20.6MB/s]\u001b[A\n",
      " 76%|  | 946M/1.24G [00:47<00:15, 19.6MB/s]\u001b[A\n",
      " 76%|  | 949M/1.24G [00:47<00:13, 21.7MB/s]\u001b[A\n",
      " 77%|  | 951M/1.24G [00:47<00:12, 22.6MB/s]\u001b[A\n",
      " 77%|  | 954M/1.24G [00:47<00:14, 20.1MB/s]\u001b[A\n",
      " 77%|  | 957M/1.24G [00:47<00:12, 22.5MB/s]\u001b[A\n",
      " 77%|  | 959M/1.24G [00:48<00:13, 20.4MB/s]\u001b[A\n",
      " 77%|  | 961M/1.24G [00:48<00:13, 20.4MB/s]\u001b[A\n",
      " 78%|  | 965M/1.24G [00:48<00:11, 23.3MB/s]\u001b[A\n",
      " 78%|  | 967M/1.24G [00:48<00:13, 20.6MB/s]\u001b[A\n",
      " 78%|  | 970M/1.24G [00:48<00:12, 21.1MB/s]\u001b[A\n",
      " 78%|  | 973M/1.24G [00:48<00:11, 23.2MB/s]\u001b[A\n",
      " 78%|  | 976M/1.24G [00:48<00:12, 21.4MB/s]\u001b[A\n",
      " 79%|  | 978M/1.24G [00:48<00:12, 21.7MB/s]\u001b[A\n",
      " 79%|  | 981M/1.24G [00:48<00:12, 21.4MB/s]\u001b[A\n",
      " 79%|  | 984M/1.24G [00:49<00:11, 22.7MB/s]\u001b[A\n",
      " 79%|  | 986M/1.24G [00:49<00:11, 22.4MB/s]\u001b[A\n",
      " 80%|  | 989M/1.24G [00:49<00:12, 21.1MB/s]\u001b[A\n",
      " 80%|  | 993M/1.24G [00:49<00:11, 21.5MB/s]\u001b[A\n",
      " 80%|  | 997M/1.24G [00:49<00:09, 24.8MB/s]\u001b[A\n",
      " 80%|  | 999M/1.24G [00:49<00:11, 21.7MB/s]\u001b[A\n",
      " 81%|  | 1.00G/1.24G [00:49<00:11, 20.6MB/s]\u001b[A\n",
      " 81%|  | 1.00G/1.24G [00:50<00:11, 20.3MB/s]\u001b[A\n",
      " 81%|  | 1.01G/1.24G [00:50<00:10, 23.5MB/s]\u001b[A\n",
      " 81%| | 1.01G/1.24G [00:50<00:11, 20.6MB/s]\u001b[A\n",
      " 81%| | 1.01G/1.24G [00:50<00:10, 21.0MB/s]\u001b[A\n",
      " 82%| | 1.02G/1.24G [00:50<00:10, 20.9MB/s]\u001b[A\n",
      " 82%| | 1.02G/1.24G [00:50<00:09, 23.8MB/s]\u001b[A\n",
      " 82%| | 1.02G/1.24G [00:50<00:10, 20.5MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 1.02G/1.24G [00:50<00:10, 20.9MB/s]\u001b[A\n",
      " 83%| | 1.03G/1.24G [00:51<00:10, 21.2MB/s]\u001b[A\n",
      " 83%| | 1.03G/1.24G [00:51<00:08, 23.9MB/s]\u001b[A\n",
      " 83%| | 1.03G/1.24G [00:51<00:10, 20.9MB/s]\u001b[A\n",
      " 83%| | 1.04G/1.24G [00:51<00:09, 21.5MB/s]\u001b[A\n",
      " 84%| | 1.04G/1.24G [00:51<00:09, 21.8MB/s]\u001b[A\n",
      " 84%| | 1.04G/1.24G [00:51<00:08, 24.2MB/s]\u001b[A\n",
      " 84%| | 1.05G/1.24G [00:51<00:09, 21.4MB/s]\u001b[A\n",
      " 84%| | 1.05G/1.24G [00:51<00:08, 21.8MB/s]\u001b[A\n",
      " 85%| | 1.05G/1.24G [00:52<00:08, 22.2MB/s]\u001b[A\n",
      " 85%| | 1.06G/1.24G [00:52<00:07, 24.2MB/s]\u001b[A\n",
      " 85%| | 1.06G/1.24G [00:52<00:08, 21.3MB/s]\u001b[A\n",
      " 85%| | 1.06G/1.24G [00:52<00:08, 20.9MB/s]\u001b[A\n",
      " 86%| | 1.06G/1.24G [00:52<00:08, 21.4MB/s]\u001b[A\n",
      " 86%| | 1.07G/1.24G [00:52<00:08, 21.6MB/s]\u001b[A\n",
      " 86%| | 1.07G/1.24G [00:53<00:07, 22.0MB/s]\u001b[A\n",
      " 86%| | 1.08G/1.24G [00:53<00:07, 21.9MB/s]\u001b[A\n",
      " 87%| | 1.08G/1.24G [00:53<00:07, 22.3MB/s]\u001b[A\n",
      " 87%| | 1.08G/1.24G [00:53<00:07, 22.5MB/s]\u001b[A\n",
      " 87%| | 1.08G/1.24G [00:53<00:06, 23.9MB/s]\u001b[A\n",
      " 87%| | 1.09G/1.24G [00:53<00:06, 24.8MB/s]\u001b[A\n",
      " 88%| | 1.09G/1.24G [00:53<00:07, 21.3MB/s]\u001b[A\n",
      " 88%| | 1.09G/1.24G [00:53<00:07, 20.9MB/s]\u001b[A\n",
      " 88%| | 1.10G/1.24G [00:54<00:06, 22.2MB/s]\u001b[A\n",
      " 88%| | 1.10G/1.24G [00:54<00:06, 23.6MB/s]\u001b[A\n",
      " 89%| | 1.10G/1.24G [00:54<00:06, 21.2MB/s]\u001b[A\n",
      " 89%| | 1.10G/1.24G [00:54<00:06, 21.3MB/s]\u001b[A\n",
      " 89%| | 1.11G/1.24G [00:54<00:05, 23.8MB/s]\u001b[A\n",
      " 89%| | 1.11G/1.24G [00:54<00:06, 21.0MB/s]\u001b[A\n",
      " 89%| | 1.11G/1.24G [00:54<00:06, 21.9MB/s]\u001b[A\n",
      " 90%| | 1.11G/1.24G [00:54<00:06, 20.9MB/s]\u001b[A\n",
      " 90%| | 1.12G/1.24G [00:55<00:05, 22.0MB/s]\u001b[A\n",
      " 90%| | 1.12G/1.24G [00:55<00:05, 21.9MB/s]\u001b[A\n",
      " 90%| | 1.12G/1.24G [00:55<00:05, 21.5MB/s]\u001b[A\n",
      " 90%| | 1.12G/1.24G [00:55<00:05, 22.7MB/s]\u001b[A\n",
      " 91%| | 1.13G/1.24G [00:55<00:05, 22.8MB/s]\u001b[A\n",
      " 91%| | 1.13G/1.24G [00:55<00:05, 22.1MB/s]\u001b[A\n",
      " 91%| | 1.13G/1.24G [00:55<00:04, 23.4MB/s]\u001b[A\n",
      " 91%|| 1.14G/1.24G [00:55<00:04, 23.1MB/s]\u001b[A\n",
      " 92%|| 1.14G/1.24G [00:56<00:04, 22.0MB/s]\u001b[A\n",
      " 92%|| 1.14G/1.24G [00:56<00:04, 24.2MB/s]\u001b[A\n",
      " 92%|| 1.14G/1.24G [00:56<00:04, 23.6MB/s]\u001b[A\n",
      " 92%|| 1.15G/1.24G [00:56<00:04, 20.7MB/s]\u001b[A\n",
      " 92%|| 1.15G/1.24G [00:56<00:04, 21.2MB/s]\u001b[A\n",
      " 93%|| 1.15G/1.24G [00:56<00:03, 23.5MB/s]\u001b[A\n",
      " 93%|| 1.16G/1.24G [00:56<00:03, 23.3MB/s]\u001b[A\n",
      " 93%|| 1.16G/1.24G [00:56<00:04, 20.7MB/s]\u001b[A\n",
      " 93%|| 1.16G/1.24G [00:56<00:03, 23.8MB/s]\u001b[A\n",
      " 94%|| 1.16G/1.24G [00:57<00:03, 24.0MB/s]\u001b[A\n",
      " 94%|| 1.17G/1.24G [00:57<00:03, 20.8MB/s]\u001b[A\n",
      " 94%|| 1.17G/1.24G [00:57<00:03, 20.6MB/s]\u001b[A\n",
      " 94%|| 1.17G/1.24G [00:57<00:03, 23.2MB/s]\u001b[A\n",
      " 95%|| 1.18G/1.24G [00:57<00:02, 23.1MB/s]\u001b[A\n",
      " 95%|| 1.18G/1.24G [00:57<00:03, 20.1MB/s]\u001b[A\n",
      " 95%|| 1.18G/1.24G [00:57<00:02, 20.8MB/s]\u001b[A\n",
      " 95%|| 1.19G/1.24G [00:58<00:02, 21.1MB/s]\u001b[A\n",
      " 96%|| 1.19G/1.24G [00:58<00:02, 24.0MB/s]\u001b[A\n",
      " 96%|| 1.19G/1.24G [00:58<00:02, 21.5MB/s]\u001b[A\n",
      " 96%|| 1.19G/1.24G [00:58<00:02, 21.1MB/s]\u001b[A\n",
      " 96%|| 1.20G/1.24G [00:58<00:02, 20.4MB/s]\u001b[A\n",
      " 97%|| 1.20G/1.24G [00:58<00:02, 21.0MB/s]\u001b[A\n",
      " 97%|| 1.21G/1.24G [00:58<00:01, 24.5MB/s]\u001b[A\n",
      " 97%|| 1.21G/1.24G [00:59<00:01, 21.1MB/s]\u001b[A\n",
      " 97%|| 1.21G/1.24G [00:59<00:01, 21.5MB/s]\u001b[A\n",
      " 98%|| 1.21G/1.24G [00:59<00:01, 20.4MB/s]\u001b[A\n",
      " 98%|| 1.22G/1.24G [00:59<00:01, 22.9MB/s]\u001b[A\n",
      " 98%|| 1.22G/1.24G [00:59<00:01, 23.0MB/s]\u001b[A\n",
      " 98%|| 1.22G/1.24G [00:59<00:01, 20.3MB/s]\u001b[A\n",
      " 98%|| 1.22G/1.24G [00:59<00:00, 22.7MB/s]\u001b[A\n",
      " 99%|| 1.23G/1.24G [00:59<00:00, 23.3MB/s]\u001b[A\n",
      " 99%|| 1.23G/1.24G [01:00<00:00, 20.5MB/s]\u001b[A\n",
      " 99%|| 1.23G/1.24G [01:00<00:00, 21.6MB/s]\u001b[A\n",
      " 99%|| 1.23G/1.24G [01:00<00:00, 21.1MB/s]\u001b[A\n",
      "100%|| 1.24G/1.24G [01:00<00:00, 22.7MB/s]\u001b[A\n",
      "100%|| 1.24G/1.24G [01:00<00:00, 23.5MB/s]\u001b[A\n",
      "100%|| 1.24G/1.24G [01:00<00:00, 20.5MB/s]\u001b[A\n",
      "Exception when trying to download https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/distilbert-large-nli-mean-tokens.zip. Response 404\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/distilbert-large-nli-mean-tokens.zip",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-9d216d6ce547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroberta_large_nli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'roberta-large-nli-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbert_large_nli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-nli-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdistilbert_large_nli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-large-nli-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdistilbert_large\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distilbert-base-nli-stsb-mean-tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0mzip_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                         \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                             \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, path)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exception when trying to download {}. Response {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcontent_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/distilbert-large-nli-mean-tokens.zip"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# roberta_large = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')\n",
    "# bert_large = SentenceTransformer(\"bert-large-nli-stsb-mean-tokens\")\n",
    "roberta_large_nli = SentenceTransformer('roberta-large-nli-mean-tokens')\n",
    "bert_large_nli = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "distilbert_large_nli = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "distilbert_large = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[149, 106, 359, ...,   0,   0,   0],\n",
       "        [288, 406,   0, ...,   0,   0,   0],\n",
       "        [787, 460, 755, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [132, 650,   0, ...,   0,   0,   0],\n",
       "        [369, 506,   0, ...,   0,   0,   0],\n",
       "        [755, 787, 254, ...,   0,   0,   0]],\n",
       "\n",
       "       [[245, 377,   8, ...,   0,   0,   0],\n",
       "        [ 31, 203,   0, ...,   0,   0,   0],\n",
       "        [204, 677,   0, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [539, 785,   0, ...,   0,   0,   0],\n",
       "        [519, 357, 134, ...,   0,   0,   0],\n",
       "        [ 92, 524,   0, ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
       "        [  1,   2,   3,  ..., 510, 511, 512],\n",
       "        [  2,   3,   4,  ..., 511, 512, 513],\n",
       "        ...,\n",
       "        [  7,   8,   9,  ..., 516, 517, 518],\n",
       "        [  8,   9,  10,  ..., 517, 518, 519],\n",
       "        [  9,  10,  11,  ..., 518, 519, 520]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(30, 24, 512)\n",
    "b = torch.randn(30, 24, 512)\n",
    "\n",
    "c = torch.bmm(torch.sum(b, dim=1).unsqueeze(1), a.permute(0,2,1)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.9270e-131, 3.4944e-131, 7.1421e-145,  2.9580e-54,  8.2338e-89,\n",
       "         3.9982e-186,  1.7342e-17, 8.9854e-167, 1.4923e-161, 6.5160e-152,\n",
       "         1.0486e-120, 1.0063e-183, 2.0121e-107, 1.4307e-116,  9.9897e-01,\n",
       "          4.1657e-71, 1.4005e-208,  1.0280e-03, 3.3086e-100, 5.4466e-202,\n",
       "         1.4825e-168, 1.1698e-115, 2.1451e-122, 1.1619e-146],\n",
       "        [4.0660e-114,  1.5300e-66,  2.3934e-65, 1.1469e-145,  1.0000e+00,\n",
       "          1.0844e-56,  2.4817e-64,  4.3483e-39, 1.0502e-113,  3.1929e-95,\n",
       "          3.2372e-52, 1.0226e-135, 6.1078e-122, 1.5710e-148,  4.8968e-42,\n",
       "          2.2181e-93, 8.7135e-151, 2.4445e-169, 5.3399e-126,  1.1250e-95,\n",
       "          2.9161e-55, 1.1800e-151,  5.8789e-78, 1.0597e-119],\n",
       "        [ 1.0000e+00, 1.5970e-153,  5.6147e-78, 2.3138e-101, 4.1165e-161,\n",
       "         5.4245e-163,  1.0112e-90,  3.9471e-51, 1.1739e-187, 2.9246e-147,\n",
       "          1.0554e-75,  9.7374e-29,  3.5493e-71, 4.8693e-133,  2.9032e-43,\n",
       "         1.2432e-169,  1.4704e-63, 8.1574e-107,  1.3173e-39,  1.9042e-33,\n",
       "          7.3954e-76, 1.0177e-122,  2.0830e-64, 2.2170e-130],\n",
       "        [ 1.8751e-49, 7.9516e-123,  4.7183e-60,  4.0273e-94,  6.9668e-34,\n",
       "         3.3217e-110,  1.0000e+00, 5.6154e-106, 3.8172e-122,  7.3828e-98,\n",
       "          1.6610e-72,  3.7317e-79, 4.6323e-113, 9.3526e-126,  3.8237e-06,\n",
       "          2.4609e-98, 4.6196e-107,  2.1776e-40,  3.9305e-55,  2.3169e-95,\n",
       "          6.6431e-95,  3.5328e-58,  2.9059e-40,  3.1241e-24],\n",
       "        [9.0370e-100,  1.7244e-52, 1.3339e-101,  3.4907e-35, 3.6800e-149,\n",
       "          1.7776e-98,  6.8907e-50, 1.1060e-168, 3.8924e-155, 6.0093e-118,\n",
       "         3.8295e-144, 5.7231e-141, 3.5068e-137, 3.4355e-176,  4.1055e-80,\n",
       "          4.4659e-62, 1.9130e-108,  2.3307e-79, 2.0723e-137,  7.2276e-90,\n",
       "         8.5358e-125,  1.0000e+00, 4.1375e-109, 2.9756e-118],\n",
       "        [ 3.0864e-69, 6.8633e-116,  8.1838e-62, 2.4669e-138,  3.1469e-42,\n",
       "         1.6700e-148,  1.8663e-63, 4.6432e-152, 2.1956e-115, 4.2645e-108,\n",
       "         2.5644e-145, 4.3581e-174, 1.0949e-207,  1.6382e-81, 2.0158e-119,\n",
       "         2.1242e-157, 7.0009e-118,  2.2842e-92,  7.0322e-64,  1.0000e+00,\n",
       "         1.1229e-108, 9.5237e-149,  4.7345e-76,  8.5890e-65],\n",
       "        [ 3.8095e-68,  4.2591e-24,  3.7868e-29, 1.2818e-111,  2.2205e-75,\n",
       "          1.8005e-50,  1.7222e-93, 6.9399e-104,  9.9780e-01, 2.1440e-128,\n",
       "         4.3657e-108,  2.2015e-28,  1.5947e-24, 3.7488e-183,  3.8149e-63,\n",
       "          4.6809e-10,  2.6504e-76,  1.2930e-73,  4.1233e-56, 6.7436e-116,\n",
       "          2.2025e-03,  9.2419e-54,  2.4141e-40,  1.9897e-28],\n",
       "        [2.7876e-118,  9.9755e-01, 5.3960e-160, 1.5596e-141,  1.4770e-78,\n",
       "          1.8748e-88, 5.9414e-123,  4.3673e-51,  1.5815e-56,  4.5546e-41,\n",
       "         2.4643e-109, 9.5473e-137,  5.3573e-99,  2.4401e-53,  2.4549e-03,\n",
       "          5.8700e-99,  1.1518e-68, 1.5295e-108, 3.2152e-112,  1.0624e-99,\n",
       "          2.3381e-13,  7.7485e-55, 1.2788e-201, 1.7513e-149],\n",
       "        [8.8580e-162, 1.5575e-128, 2.7853e-119, 4.6100e-116,  3.8538e-69,\n",
       "          1.9556e-48, 3.1021e-132,  1.0000e+00, 1.0862e-119,  1.0258e-56,\n",
       "         7.1416e-171, 1.2985e-130,  3.5856e-18,  4.7775e-53, 2.9563e-110,\n",
       "         3.8219e-103,  3.0461e-10, 2.7231e-159,  3.6109e-98,  2.7680e-97,\n",
       "          2.6051e-61, 5.0295e-168,  1.9906e-55,  2.5042e-91],\n",
       "        [9.6079e-101, 1.1961e-132, 2.4918e-147, 1.0446e-168, 1.4846e-173,\n",
       "          9.5084e-13,  1.9805e-87,  1.2336e-62,  1.7616e-34,  1.0000e+00,\n",
       "         8.7188e-143,  2.9797e-24,  7.9915e-94,  9.3389e-55, 4.1244e-117,\n",
       "          9.9542e-70,  2.6738e-80,  7.0307e-34,  8.9264e-80, 4.2128e-210,\n",
       "          6.9233e-12, 1.6673e-113,  7.6545e-82,  1.4577e-73],\n",
       "        [ 2.7226e-23, 3.0271e-216,  1.9645e-93, 3.2336e-153, 6.1081e-129,\n",
       "          4.0635e-71,  1.0000e+00,  1.1066e-49,  4.8069e-74,  2.8824e-06,\n",
       "          5.1042e-24,  2.7317e-68,  1.1790e-76, 3.4665e-108,  2.8994e-76,\n",
       "         2.7270e-113, 5.8572e-113,  2.3318e-80,  1.5335e-46,  1.9806e-98,\n",
       "          1.3162e-96, 7.3534e-103,  2.9497e-89, 1.0836e-103],\n",
       "        [3.6064e-134,  9.9958e-01,  7.2060e-67,  2.9966e-91,  4.2145e-04,\n",
       "          9.2371e-99, 6.1421e-116,  1.6896e-08,  2.4280e-20, 1.9376e-111,\n",
       "          1.8677e-55,  2.0153e-46,  2.6451e-68,  4.7814e-46,  1.2389e-24,\n",
       "          1.9007e-40,  1.5260e-13, 3.4931e-153,  6.1882e-42,  2.1709e-40,\n",
       "         1.5182e-156, 1.1089e-114,  9.2844e-80,  4.8864e-80],\n",
       "        [1.5918e-144, 3.3742e-153,  7.0378e-35, 1.3390e-159,  6.0708e-74,\n",
       "         6.4692e-120,  7.4859e-66,  4.6478e-71,  4.2434e-97,  4.0491e-29,\n",
       "          3.7349e-16,  2.4321e-25, 4.0894e-108, 1.5936e-118, 4.2807e-203,\n",
       "          1.0000e+00, 1.0117e-106,  5.1114e-28,  8.7515e-56, 5.2438e-115,\n",
       "          8.1475e-31,  2.2521e-97, 2.1150e-161, 1.3915e-156],\n",
       "        [ 2.3365e-58, 2.6460e-113,  1.6791e-08, 3.8333e-107,  3.1311e-39,\n",
       "          3.5325e-72,  4.1595e-94,  1.0000e+00,  6.2267e-37,  6.2330e-90,\n",
       "          6.6088e-29, 4.8627e-209, 9.0462e-102, 1.0522e-101,  1.3669e-08,\n",
       "         3.1375e-177,  2.7755e-63, 6.2974e-125,  4.2939e-86,  4.3589e-53,\n",
       "          9.9342e-38,  2.9117e-47,  6.6897e-97,  3.1415e-73],\n",
       "        [1.5187e-100, 6.5313e-134,  1.7381e-15,  8.8178e-64,  1.6048e-92,\n",
       "         7.6450e-146,  1.0850e-28,  5.6077e-56,  7.2975e-57,  3.3474e-77,\n",
       "          9.3277e-14,  2.9858e-37, 1.2351e-106,  1.6938e-53,  7.9524e-01,\n",
       "          1.4515e-04,  2.7738e-67,  4.7072e-51,  1.9823e-34, 9.5614e-107,\n",
       "          1.8950e-63,  2.1663e-90,  1.5662e-55,  2.0462e-01],\n",
       "        [ 2.0494e-73,  6.7289e-34,  1.2907e-58,  6.8525e-48,  1.0000e+00,\n",
       "          1.7999e-12,  2.7030e-62, 1.9205e-113, 3.6447e-263,  2.7373e-29,\n",
       "          1.2569e-59,  9.5651e-75,  5.5300e-69,  1.8456e-45, 1.2698e-154,\n",
       "          3.1303e-26,  3.3092e-43,  3.1639e-19,  2.3159e-38,  1.5226e-33,\n",
       "          1.9769e-84,  2.3963e-46,  7.9560e-49,  2.9707e-78],\n",
       "        [ 2.7892e-44, 6.7494e-101, 3.2690e-104, 1.1826e-103,  3.4710e-62,\n",
       "         6.8559e-167, 5.1060e-124,  2.9079e-92, 1.0043e-104,  3.8228e-12,\n",
       "         7.9158e-102, 6.8261e-126,  1.4145e-32,  2.5507e-05,  4.3743e-79,\n",
       "         5.4776e-119, 3.7930e-109, 2.9193e-174, 1.8173e-103, 3.0028e-109,\n",
       "         4.5912e-195,  9.9997e-01,  8.4246e-69,  7.3113e-66],\n",
       "        [ 9.5285e-89, 3.7023e-127,  2.4729e-17,  8.6302e-69,  8.0786e-87,\n",
       "          2.8056e-76, 2.4790e-112, 1.2801e-105,  3.1897e-99,  4.6825e-55,\n",
       "         1.9622e-146,  4.4503e-28,  2.8561e-84,  2.3782e-86,  1.1984e-89,\n",
       "          6.1278e-10, 3.7475e-102,  1.0000e+00, 4.9885e-139,  1.4293e-14,\n",
       "          5.6703e-31,  9.0134e-11,  4.7466e-88,  8.1071e-32],\n",
       "        [ 4.2686e-38,  1.1463e-61,  1.0711e-40,  5.8114e-93, 2.8441e-113,\n",
       "          1.1735e-49,  1.0551e-84,  5.3078e-75,  9.3355e-71, 1.3809e-140,\n",
       "          2.4630e-63,  1.0000e+00,  1.2547e-73,  6.1301e-68,  2.3088e-91,\n",
       "          1.7987e-91,  5.3282e-91,  3.1984e-09, 3.3610e-138, 2.1205e-104,\n",
       "          2.4939e-90,  1.8786e-45,  3.6558e-77,  1.9642e-47],\n",
       "        [ 8.7654e-49,  1.6628e-70,  9.3239e-01,  6.3593e-35, 3.4675e-109,\n",
       "         6.0988e-127,  9.6639e-55,  3.9531e-43,  2.0662e-49,  1.3007e-20,\n",
       "         3.0241e-125, 7.6654e-106,  6.7611e-02,  1.8831e-75,  3.1171e-70,\n",
       "          1.6553e-87, 4.2321e-118,  1.4875e-23, 2.4168e-161,  6.6400e-36,\n",
       "          7.3034e-84,  1.1964e-48,  2.2063e-56,  3.6125e-64],\n",
       "        [1.1196e-206,  2.6482e-66,  3.2176e-37,  4.3003e-14,  2.6442e-84,\n",
       "          5.1903e-78, 2.7026e-109, 4.2943e-139, 2.9469e-126, 1.7278e-113,\n",
       "          2.4622e-25,  1.0208e-16, 5.0761e-100, 1.8540e-124,  1.0000e+00,\n",
       "         1.3552e-142, 1.2141e-166,  4.7829e-81, 1.0313e-118,  2.5378e-07,\n",
       "          4.0204e-49,  3.6738e-53,  6.8101e-44,  7.4208e-84],\n",
       "        [ 2.5856e-67, 2.3485e-108,  1.9263e-44, 1.8547e-141,  4.8221e-70,\n",
       "          3.1437e-29,  5.5371e-01,  2.8131e-64,  3.4453e-13, 6.4021e-109,\n",
       "          8.8547e-09,  1.3926e-82,  3.9678e-83,  2.3033e-16,  4.4629e-01,\n",
       "          1.6077e-51,  4.4661e-89, 3.8514e-135,  7.4161e-38,  1.5920e-09,\n",
       "          5.9901e-72,  2.3851e-51,  2.3797e-26,  8.1064e-97],\n",
       "        [1.4193e-101, 2.1018e-144,  5.8983e-08,  1.0788e-05, 1.5489e-157,\n",
       "          9.9999e-01, 1.0993e-142, 1.0345e-126,  5.6337e-55, 6.0291e-168,\n",
       "          4.4535e-30,  8.5732e-73,  8.9697e-56,  1.0913e-19,  2.2351e-84,\n",
       "         1.2789e-106, 4.2680e-123,  1.4057e-63, 6.2772e-120, 1.2513e-101,\n",
       "         6.2668e-107, 2.7691e-103,  3.8569e-69,  4.2540e-48],\n",
       "        [1.2696e-172, 9.4573e-157, 1.4814e-135, 1.2927e-117, 3.3593e-106,\n",
       "          2.1538e-51, 2.6983e-103, 1.7447e-208, 9.4006e-117,  2.3562e-65,\n",
       "         3.0274e-122, 2.1728e-194, 1.6284e-215, 3.5981e-123,  1.0000e+00,\n",
       "         2.6617e-157,  1.1745e-71,  1.1741e-46, 8.3479e-144, 3.1245e-102,\n",
       "         6.9950e-145, 5.0624e-147, 3.1139e-141, 7.1068e-120],\n",
       "        [ 3.3094e-95, 1.5640e-124, 7.5142e-112,  2.9228e-97,  1.3817e-51,\n",
       "          7.2360e-11,  1.0000e+00,  2.0725e-90, 2.9451e-202, 7.9542e-118,\n",
       "         1.0313e-113,  5.1976e-11, 8.2940e-107, 3.0915e-151,  1.1520e-88,\n",
       "         4.1548e-106, 3.0785e-123,  5.7144e-99, 1.2247e-129, 5.6528e-150,\n",
       "         3.8282e-139, 2.8310e-115, 1.9944e-135, 1.8315e-123],\n",
       "        [ 8.1983e-56,  2.7695e-52, 3.5184e-145, 2.9529e-152,  3.6942e-81,\n",
       "          3.4015e-95, 2.3318e-118, 3.7037e-163,  1.4238e-67,  2.5455e-93,\n",
       "          2.3050e-16,  7.6462e-26,  3.2721e-28,  1.2308e-81,  4.0813e-28,\n",
       "          7.5259e-61,  1.5479e-55,  4.9002e-75,  9.7542e-89, 2.4112e-140,\n",
       "          1.0000e+00, 1.1840e-127,  2.3935e-51,  2.2047e-40],\n",
       "        [1.6970e-101, 6.6645e-118, 3.3627e-166, 1.3814e-129, 1.2124e-225,\n",
       "         1.9538e-175, 2.9593e-154,  2.3423e-61, 9.6298e-171, 1.7238e-102,\n",
       "          1.1138e-25, 1.6109e-128, 1.7614e-128, 1.5313e-125, 8.2919e-160,\n",
       "         1.4835e-190,  1.6418e-89, 6.4389e-159, 9.1833e-137,  3.6656e-51,\n",
       "         9.2921e-129, 5.1035e-146, 2.9100e-109,  1.0000e+00],\n",
       "        [3.4696e-158, 1.2053e-193,  1.9546e-67, 1.5220e-167, 2.0786e-146,\n",
       "         1.2097e-199, 7.5515e-165, 3.5705e-173, 4.7725e-130, 2.1957e-198,\n",
       "         1.7528e-137, 6.7172e-164, 1.1043e-125, 1.2524e-184,  2.1371e-43,\n",
       "         2.7333e-149, 3.9330e-240, 3.9007e-223, 1.9027e-219,  1.0000e+00,\n",
       "         1.2372e-183, 2.4691e-226, 7.1139e-198, 7.5074e-162],\n",
       "        [1.5669e-130,  8.6973e-92, 3.9556e-161, 5.2078e-223,  1.0000e+00,\n",
       "          1.0312e-52, 9.9947e-103,  8.1342e-08,  3.3637e-81, 2.3107e-115,\n",
       "         1.3498e-147,  2.0153e-69,  6.2601e-75, 6.8623e-108,  2.8127e-56,\n",
       "         9.4051e-108, 2.3517e-179, 3.2901e-118, 9.2074e-168, 9.9600e-197,\n",
       "         1.1258e-162, 5.4994e-115, 4.3781e-135,  3.8195e-85],\n",
       "        [ 1.0000e+00,  8.1131e-58, 1.9789e-191, 6.2758e-119, 2.7647e-140,\n",
       "          1.5547e-99, 1.8228e-124, 6.8910e-143,  2.7687e-60,  5.9108e-81,\n",
       "         9.1627e-125, 1.7747e-148, 1.2219e-133,  4.7933e-83, 1.0718e-175,\n",
       "         2.0975e-113,  4.9711e-56,  2.2209e-33,  5.8776e-73, 3.4369e-245,\n",
       "         5.0826e-107,  5.0384e-82, 2.8458e-148, 1.0762e-166]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_softmax(inp):\n",
    "    inp = inp.double()\n",
    "    mask = ((inp != 0).double() - 1) * 9999  # for -inf\n",
    "    return (inp + mask).softmax(dim=-1)\n",
    "\n",
    "masked_softmax(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(30, 24, 512)\n",
    "b = torch.randn(30, 24, 512)\n",
    "\n",
    "result = (a.unsqueeze(1) * b.unsqueeze(2)).sum(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1367],\n",
      "         [ 0.4712],\n",
      "         [-1.0098],\n",
      "         ...,\n",
      "         [ 0.3564],\n",
      "         [ 0.4959],\n",
      "         [-0.5302]],\n",
      "\n",
      "        [[-0.5156],\n",
      "         [-2.1806],\n",
      "         [-1.0502],\n",
      "         ...,\n",
      "         [-0.2044],\n",
      "         [ 0.5750],\n",
      "         [-1.1287]],\n",
      "\n",
      "        [[ 1.5069],\n",
      "         [ 0.7505],\n",
      "         [-1.8575],\n",
      "         ...,\n",
      "         [ 0.5256],\n",
      "         [ 0.5765],\n",
      "         [-0.1208]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3807],\n",
      "         [ 0.2224],\n",
      "         [ 1.4568],\n",
      "         ...,\n",
      "         [-1.8325],\n",
      "         [-0.8720],\n",
      "         [-0.7922]],\n",
      "\n",
      "        [[ 0.9426],\n",
      "         [ 0.6242],\n",
      "         [-0.5395],\n",
      "         ...,\n",
      "         [ 0.7824],\n",
      "         [-1.6038],\n",
      "         [ 0.3325]],\n",
      "\n",
      "        [[ 0.9734],\n",
      "         [ 0.0363],\n",
      "         [-0.0815],\n",
      "         ...,\n",
      "         [ 0.8168],\n",
      "         [-0.2826],\n",
      "         [ 0.3225]]]) tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randn(3993, 9, 1)\n",
    "print (t, masked_softmax(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.35313728e-01, -3.98441866e+00,  4.83618786e+00, -8.96162044e-01,\n",
       "        6.93504260e-01, -2.40044428e+00, -3.37686708e+00, -2.81878735e+00,\n",
       "       -3.90242832e+00,  1.86741772e+00, -1.69376359e+00,  2.46347982e+00,\n",
       "       -2.19717695e+00, -5.03819966e-01,  1.53739391e-02, -3.81705850e+00,\n",
       "        7.12020371e+00, -9.91619450e-01, -1.19323884e+01, -2.02825630e+00,\n",
       "        9.53331606e-02, -1.43964033e-01, -2.59777649e-01,  1.59757490e+00,\n",
       "       -6.77884832e+00,  5.33016878e+00,  1.30698192e+00, -2.35665532e-01,\n",
       "       -1.01886989e+00, -1.89639585e+00,  4.42655160e+00,  3.01185643e+00,\n",
       "        1.21648539e+00, -3.22416581e+00, -3.48676405e+00, -2.78747781e+00,\n",
       "        2.56421665e+00, -2.46496803e-01,  2.30988111e+00,  6.03988253e+00,\n",
       "       -4.36566272e-01,  2.67983028e+00, -3.90873991e+00, -1.80390903e+00,\n",
       "       -4.97648965e+00, -1.20563486e+00, -6.58429221e-01, -3.60586970e+00,\n",
       "        2.68783845e+00, -7.84170619e-01,  3.42336524e+00, -8.30507887e+00,\n",
       "        9.02814358e+00,  8.47231298e+00,  8.01010633e-01, -4.55801165e+00,\n",
       "        6.99302118e-01,  1.34368698e+01,  4.96135599e-01,  1.85232793e-02,\n",
       "       -1.60119348e-01,  1.59252500e+00,  1.73127259e+01, -2.56405649e-02,\n",
       "       -4.34867992e-01, -3.34929036e-01,  7.85935684e-02,  6.35937301e-01,\n",
       "        3.14641201e-01, -4.74086346e+00, -5.85273050e-01, -1.73332898e+00,\n",
       "       -5.97454990e-01,  2.06791724e+00,  1.99178189e+00, -1.77186278e+00,\n",
       "        8.88335930e-01, -7.62058580e-01, -1.08680301e+00, -1.05701546e+00,\n",
       "        5.81972520e-01, -6.04576255e+00,  3.42724235e-01, -1.32338430e+00,\n",
       "       -7.08525112e+00,  3.57033954e+00,  5.02733557e-01, -1.23318146e+00,\n",
       "        3.05400789e+00,  2.56294461e+00, -1.51375052e+00, -1.04813888e+01,\n",
       "        1.31892453e+00, -1.73770642e+00,  1.06580446e+00, -1.47700989e-01,\n",
       "        1.74765374e+00, -1.44692727e-01,  9.10539136e-01, -1.04706307e-01,\n",
       "        9.84572250e-02,  5.10108600e-01, -2.22689887e+00,  2.32128270e+00,\n",
       "       -6.58781308e-01, -1.38304817e-01, -9.65608742e+00,  7.90026754e-01,\n",
       "       -1.67958922e+00, -1.01546245e+01, -3.59460940e+00,  2.62837776e+00,\n",
       "        8.34587256e-01,  2.61072618e+00, -1.63485345e+00,  4.49923974e+00,\n",
       "       -4.11701180e-01,  2.31948701e+00, -1.75097221e-01, -4.21642691e+00,\n",
       "       -1.20457955e+00, -4.83266417e-02,  1.25453997e+01,  2.67230170e-01,\n",
       "        1.41774106e+00, -6.95002950e-02, -7.88169656e+00,  5.67111614e-03,\n",
       "        3.20720602e+00,  5.82675222e+00, -3.86946935e+00,  2.93811716e-01,\n",
       "        1.03774429e+00,  3.14528580e+00, -4.82784930e+00, -2.09571659e+00,\n",
       "        6.28254143e+00,  2.99693858e-01, -6.55821070e+00, -2.85966244e-01,\n",
       "        1.74564037e+00, -3.72980671e-01,  1.33452313e+00,  8.90611369e-01,\n",
       "       -9.10224720e-01,  2.43192384e+01, -8.48190923e-01,  2.32823068e+00,\n",
       "       -5.70184711e+00,  2.49267723e+01, -2.69295869e+00,  4.78997794e-02,\n",
       "       -4.62414055e-01,  5.59928174e-01,  3.45497209e-01, -3.68011628e+00,\n",
       "        2.83369973e-01, -4.03665953e-01,  6.22961148e-03,  1.03616226e+00,\n",
       "       -6.22132167e-01,  1.51026568e+01,  4.81185392e+00, -5.56613123e-01,\n",
       "       -2.38198453e+00, -2.65683497e+00,  2.37064752e+00, -4.50020355e+00,\n",
       "       -3.17751382e+00,  1.93606394e+00, -2.08676952e+00,  4.81310003e+00,\n",
       "       -5.20541680e-01, -2.86738719e+00, -8.21705673e+00, -2.51714835e+00,\n",
       "        8.23707038e-01,  2.02724314e-01,  4.08407433e+00,  6.56304656e-01,\n",
       "       -1.48804036e+00, -1.15187485e+01,  2.56252510e+00, -1.80545366e+00,\n",
       "        1.47383292e+00,  1.37383277e+01,  8.50114628e+00,  1.08451564e-01,\n",
       "        4.72471601e+00, -3.32698973e+00,  3.80371264e+00,  4.00317563e+00,\n",
       "       -1.85093677e+00, -3.73784185e+00,  3.11986043e+00, -5.66049685e+00,\n",
       "        5.36154891e+00,  1.42611181e+01,  1.56976987e+00, -5.55131932e+00,\n",
       "        6.78043586e-01, -2.18493097e+00, -2.05988911e+00, -4.16704625e-02,\n",
       "       -9.26675127e-01, -8.79319350e+00,  2.25875060e+00, -2.97456117e+00,\n",
       "       -2.83055957e+00,  6.99574558e+00, -3.41893731e-03, -8.62948143e-01,\n",
       "        1.69803433e+00,  1.30768073e+00, -1.01868763e+00, -1.86732030e-02,\n",
       "        1.15284883e+00, -2.45073773e+01, -1.55200673e+00,  9.50867702e-01,\n",
       "       -1.47493834e+00,  1.46919462e+00,  1.67762860e+00, -2.15029159e+00,\n",
       "        3.92786278e+00, -7.31567633e-01,  9.82575005e+00, -1.17505553e+00,\n",
       "        8.70306113e+00,  5.84650773e-01,  4.16402590e+00,  7.29466332e-01,\n",
       "        6.68688803e-01,  2.39127562e+00,  8.92695193e-01, -5.60669203e+00,\n",
       "       -8.46246781e+00, -8.39815692e-01,  4.10593485e+00,  2.66928484e-02,\n",
       "       -5.53169430e+00,  1.39853007e+00, -1.96979355e+00, -4.65312873e+00,\n",
       "       -2.73121611e+00,  2.75959820e+00, -1.29788502e-02, -2.48259721e-01,\n",
       "       -2.27616241e+00,  5.03221697e+00,  1.59272486e-01, -8.31817260e-01,\n",
       "       -1.53537773e+00, -6.88554036e-01, -2.02236408e+00, -3.10548171e+00,\n",
       "       -3.59666995e+00,  3.05395486e-01,  3.58837768e-02, -1.05302964e+01,\n",
       "       -1.13857836e+01,  5.49777159e+00, -4.29128260e-01, -4.31711661e+00,\n",
       "        3.80194286e+00, -4.19837264e+00, -1.24981638e+00, -2.13378788e-02,\n",
       "       -4.70230589e-02,  1.93034990e+01,  1.73796958e+00,  1.58420314e+00,\n",
       "        4.19086448e-01,  5.29478513e-01,  1.51794502e+01, -4.17092923e+00,\n",
       "       -5.82571677e-01, -7.34660966e-01,  7.42226722e-01, -8.72550478e-01,\n",
       "       -1.47446340e+00,  2.27944948e+00, -9.50726539e-01,  1.16961414e+00,\n",
       "        2.06026120e+00, -4.53058227e+00, -7.91249160e-01, -3.36894868e+00,\n",
       "        3.09022974e+00, -1.74903061e+00, -6.60724194e+00,  1.00299285e-01,\n",
       "        6.09967381e+00,  5.39023145e+00,  3.33231815e+00,  2.99743327e-01,\n",
       "       -1.28625236e+00, -5.10765992e+00, -1.04197988e+01,  1.55874085e-01,\n",
       "        4.50965422e-02,  4.33972359e+00,  3.89631621e+00,  4.31525718e+00,\n",
       "        2.63935610e+00,  4.63446684e+00, -3.75026149e-01, -4.97994536e-02,\n",
       "       -1.62274058e+00, -4.30900577e+00, -1.29358774e+00,  1.13587752e+01,\n",
       "        3.86936350e-01,  1.84221138e-01, -1.44213595e+00,  7.56622178e+00,\n",
       "        1.99229493e+00,  1.03145416e-01,  8.10167628e-01,  5.19788763e-01,\n",
       "       -4.54690364e+00, -3.94813645e+00, -4.07890741e+00, -6.04086487e-01,\n",
       "        3.40610466e-02,  2.95706401e+00,  4.58157446e-01, -2.01674298e+00,\n",
       "        4.30836797e+00,  3.44890043e+00,  1.53390271e+00,  5.02160998e-01,\n",
       "       -5.34178529e-01,  1.39795080e+00, -2.96855256e+00,  1.05516265e+01,\n",
       "       -4.02441327e+00, -3.22312536e+00,  2.01751106e+00, -4.71107384e-02,\n",
       "        6.25819188e-01, -1.55198678e+00,  3.08184795e+00,  8.68246545e+00,\n",
       "       -6.38865348e+00,  7.74498128e-02, -1.39525955e+01,  5.97892643e-01,\n",
       "       -7.95882525e-01,  4.67929447e+00, -1.46681854e+01,  1.35076090e+00,\n",
       "       -3.34630462e-01,  1.91394162e+00,  6.90105371e+00, -1.10383267e-01,\n",
       "        4.28322094e+00,  7.48898317e-01, -3.41243854e+00,  6.21817121e-01,\n",
       "       -3.40645371e+00, -8.59072953e+00,  9.20888911e+00, -2.53217862e+00,\n",
       "       -8.12547764e+00, -1.43395322e+00,  3.50881513e+00, -3.60113621e+00,\n",
       "       -3.96218115e+00, -6.04855126e-03, -7.39171870e+00, -6.81387968e-02,\n",
       "        1.45031207e+00,  4.08653552e+00,  4.78727141e+00, -1.04874806e+00,\n",
       "       -2.43946570e+00, -3.03007005e+00, -1.93115569e-01, -9.43866363e-01,\n",
       "       -6.84800468e+00,  2.49421272e+00,  1.46481557e+01,  2.98289778e+00,\n",
       "        7.10414754e+00, -1.27704456e+00, -1.48923132e+01, -1.57551597e-02,\n",
       "        4.59299186e+00,  6.97311928e-01, -4.32530488e-02,  6.59947550e+00,\n",
       "        1.23400748e+00,  1.65261068e-01, -6.37499313e+00,  8.15540942e-01,\n",
       "        1.44290081e+00,  7.65739020e+00,  1.01027416e+00, -2.37806452e+00,\n",
       "        4.78947831e+00,  2.74498337e+00,  1.22506505e-01, -1.33766629e+00,\n",
       "       -2.84731824e-01,  6.86165484e-01, -3.74446407e+00, -4.49073899e+00,\n",
       "        2.07465971e+00,  2.14575972e+00, -9.41908988e-01,  5.24366763e+00,\n",
       "       -5.99436687e+00,  1.30874217e+00,  2.59748717e+00, -6.15428378e+00,\n",
       "        2.76328191e-01,  2.54653046e+00,  4.84074508e+00, -4.12276473e+00,\n",
       "       -9.72956213e+00, -1.47806784e+01,  4.72762993e+00,  3.82367631e+00,\n",
       "       -1.52793568e+01,  7.63622551e-01, -1.00010439e+00,  1.11179401e-01,\n",
       "       -1.64563428e+01,  1.59833810e-02, -9.65737886e-01, -4.67035948e+00,\n",
       "       -1.43292017e+00,  6.43999639e+00, -4.72049485e-01, -9.35110118e+00,\n",
       "       -6.47424777e-01, -2.32019224e+00,  1.04404269e+01,  2.54238291e+00,\n",
       "        1.46852242e-01,  8.17704943e-01, -1.68582072e+01, -9.82849107e+00,\n",
       "       -8.29981790e-01, -2.29325398e+00, -4.12220308e+00,  1.37137696e-01,\n",
       "       -1.66653581e+01, -1.14081768e-01,  2.93393829e+00,  3.20210830e+00,\n",
       "        7.56170502e-02,  5.22981402e+00, -2.86954118e+00,  6.22166930e-01,\n",
       "       -1.01860626e+00,  9.34444669e-01, -2.62202245e+00,  1.21150172e+00,\n",
       "        1.36440903e+01,  4.25056732e+00, -1.82110754e+00, -2.97892157e+00,\n",
       "       -1.62322064e+00, -6.74701055e-01,  1.63470719e+00, -2.62376974e+00,\n",
       "        2.62440460e-02,  8.31031687e-01,  1.41939127e+01,  9.62459931e+00,\n",
       "        3.78754297e+00,  2.89951892e+00,  1.44575247e+00,  2.99084201e-01,\n",
       "        1.91808580e+00,  1.08959147e+00,  3.46539913e+00, -1.99477098e+00,\n",
       "        8.17431016e-01,  1.63267951e+00,  1.11282450e+00,  5.85716581e+00,\n",
       "        2.19772652e-01,  9.14552917e+00,  1.52037387e+00,  7.54890800e-01,\n",
       "       -1.71130986e+00,  8.26158915e-01,  1.94283290e+00, -5.43493098e-01,\n",
       "        8.25952316e+00, -1.93168856e-01,  6.74556101e-01,  2.45229788e+00,\n",
       "       -2.24869720e+00,  1.59855249e+00,  1.73109699e+00, -1.41097495e+01,\n",
       "        4.83647219e-01,  2.43459575e+00, -2.86573382e+00,  3.11955809e+00,\n",
       "       -3.29611358e+00, -2.70493802e+00, -1.13306550e+00, -2.50993117e+00,\n",
       "        6.07050950e-02, -2.72118968e+00, -1.27964735e-02,  1.53664383e-01])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([(a[0][0] * b[0][i]).numpy() for i in range(len(b[0]))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conference#Information_for_participants', 'ekaw#Programme_Brochure'),\n",
       " ('conference#Person', 'ekaw#Person'),\n",
       " ('conference#Tutorial', 'ekaw#Tutorial'),\n",
       " ('conference#Review', 'ekaw#Review'),\n",
       " ('conference#has_a_review', 'ekaw#hasReview'),\n",
       " ('conference#Workshop', 'ekaw#Workshop'),\n",
       " ('conference#Late_paid_applicant', 'ekaw#Late-Registered_Participant'),\n",
       " ('conference#Early_paid_applicant', 'ekaw#Early-Registered_Participant'),\n",
       " ('conference#Organization', 'ekaw#Organisation'),\n",
       " ('conference#Track-workshop_chair', 'ekaw#Workshop_Chair'),\n",
       " ('conference#Abstract', 'ekaw#Abstract'),\n",
       " ('conference#Conference_proceedings', 'ekaw#Conference_Proceedings'),\n",
       " ('conference#Conference_volume', 'ekaw#Conference'),\n",
       " ('conference#Rejected_contribution', 'ekaw#Rejected_Paper'),\n",
       " ('conference#Poster', 'ekaw#Poster_Paper'),\n",
       " ('conference#Track', 'ekaw#Track'),\n",
       " ('conference#Topic', 'ekaw#Research_Topic'),\n",
       " ('conference#Conference_www', 'ekaw#Web_Site'),\n",
       " ('conference#Invited_speaker', 'ekaw#Invited_Speaker'),\n",
       " ('conference#contributes', 'ekaw#authorOf'),\n",
       " ('conference#Accepted_contribution', 'ekaw#Accepted_Paper'),\n",
       " ('conference#Conference_document', 'ekaw#Document'),\n",
       " ('conference#Reviewed_contribution', 'ekaw#Evaluated_Paper'),\n",
       " ('conference#Submitted_contribution', 'ekaw#Submitted_Paper'),\n",
       " ('conference#Regular_author', 'ekaw#Paper_Author'),\n",
       " ('confOf#Tutorial', 'ekaw#Tutorial'),\n",
       " ('confOf#Poster', 'ekaw#Poster_Paper'),\n",
       " ('confOf#Social_event', 'ekaw#Social_Event'),\n",
       " ('confOf#Person', 'ekaw#Person'),\n",
       " ('confOf#Working_event', 'ekaw#Scientific_Event'),\n",
       " ('confOf#Conference', 'ekaw#Conference'),\n",
       " ('confOf#Author', 'ekaw#Paper_Author'),\n",
       " ('confOf#Banquet', 'ekaw#Conference_Banquet'),\n",
       " ('confOf#Workshop', 'ekaw#Workshop'),\n",
       " ('confOf#Topic', 'ekaw#Research_Topic'),\n",
       " ('confOf#Contribution', 'ekaw#Paper'),\n",
       " ('confOf#Participant', 'ekaw#Conference_Participant'),\n",
       " ('confOf#Chair_PC', 'ekaw#PC_Chair'),\n",
       " ('confOf#Organization', 'ekaw#Organisation'),\n",
       " ('confOf#Student', 'ekaw#Student'),\n",
       " ('confOf#University', 'ekaw#University'),\n",
       " ('confOf#Trip', 'ekaw#Conference_Trip'),\n",
       " ('confOf#Member_PC', 'ekaw#PC_Member'),\n",
       " ('confOf#Scholar', 'ekaw#Student'),\n",
       " ('confOf#Event', 'ekaw#Event'),\n",
       " ('ekaw#Conference', 'sigkdd#Conference'),\n",
       " ('ekaw#Person', 'sigkdd#Person'),\n",
       " ('ekaw#Paper', 'sigkdd#Paper'),\n",
       " ('ekaw#Review', 'sigkdd#Review'),\n",
       " ('ekaw#Invited_Speaker', 'sigkdd#Invited_Speaker'),\n",
       " ('ekaw#OC_Member', 'sigkdd#Organizing_Committee_member'),\n",
       " ('ekaw#Abstract', 'sigkdd#Abstract'),\n",
       " ('ekaw#PC_Chair', 'sigkdd#Program_Chair'),\n",
       " ('ekaw#Paper_Author', 'sigkdd#Author'),\n",
       " ('ekaw#Document', 'sigkdd#Document'),\n",
       " ('ekaw#Location', 'sigkdd#Place'),\n",
       " ('edas#Place', 'sigkdd#Place'),\n",
       " ('edas#hasCostAmount', 'sigkdd#Price'),\n",
       " ('edas#Person', 'sigkdd#Person'),\n",
       " ('edas#hasName', 'sigkdd#Name_of_conference'),\n",
       " ('edas#ConferenceVenuePlace', 'sigkdd#Conference_hall'),\n",
       " ('edas#Author', 'sigkdd#Author'),\n",
       " ('edas#AccommodationPlace', 'sigkdd#Hotel'),\n",
       " ('edas#startDate', 'sigkdd#Start_of_conference'),\n",
       " ('edas#ConferenceChair', 'sigkdd#General_Chair'),\n",
       " ('edas#Conference', 'sigkdd#Conference'),\n",
       " ('edas#endDate', 'sigkdd#End_of_conference'),\n",
       " ('edas#Review', 'sigkdd#Review'),\n",
       " ('edas#Document', 'sigkdd#Document'),\n",
       " ('edas#Paper', 'sigkdd#Paper'),\n",
       " ('edas#Attendee', 'sigkdd#Listener'),\n",
       " ('confOf#Person', 'sigkdd#Person'),\n",
       " ('confOf#Member_PC', 'sigkdd#Program_Committee_member'),\n",
       " ('confOf#hasEmail', 'sigkdd#E-mail'),\n",
       " ('confOf#Author', 'sigkdd#Author'),\n",
       " ('confOf#Conference', 'sigkdd#Conference'),\n",
       " ('confOf#Chair_PC', 'sigkdd#Program_Chair'),\n",
       " ('confOf#Paper', 'sigkdd#Paper'),\n",
       " ('iasted#Place', 'sigkdd#Place'),\n",
       " ('iasted#Review', 'sigkdd#Review'),\n",
       " ('iasted#Student_registration_fee', 'sigkdd#Registration_Student'),\n",
       " ('iasted#Fee', 'sigkdd#Fee'),\n",
       " ('iasted#Registration_fee', 'sigkdd#Registration_fee'),\n",
       " ('iasted#Sponsor', 'sigkdd#Sponzor'),\n",
       " ('iasted#Deadline_for_notification_of_acceptance',\n",
       "  'sigkdd#Deadline_Author_notification'),\n",
       " ('iasted#Nonmember_registration_fee', 'sigkdd#Registration_Non-Member'),\n",
       " ('iasted#Author', 'sigkdd#Author'),\n",
       " ('iasted#Listener', 'sigkdd#Listener'),\n",
       " ('iasted#Main_office', 'sigkdd#Main_office'),\n",
       " ('iasted#Conference_hall', 'sigkdd#Conference_hall'),\n",
       " ('iasted#Person', 'sigkdd#Person'),\n",
       " ('iasted#Deadline', 'sigkdd#Deadline'),\n",
       " ('iasted#Speaker', 'sigkdd#Speaker'),\n",
       " ('confOf#Event', 'iasted#Activity'),\n",
       " ('confOf#Author', 'iasted#Author'),\n",
       " ('confOf#Person', 'iasted#Person'),\n",
       " ('confOf#Banquet', 'iasted#Dinner_banquet'),\n",
       " ('confOf#Administrative_event', 'iasted#Activity_before_conference'),\n",
       " ('confOf#Reception', 'iasted#Coctail_reception'),\n",
       " ('confOf#City', 'iasted#City'),\n",
       " ('confOf#Tutorial', 'iasted#Tutorial'),\n",
       " ('confOf#Country', 'iasted#State'),\n",
       " ('conference#Passive_conference_participant', 'iasted#Listener'),\n",
       " ('conference#Active_conference_participant', 'iasted#Speaker'),\n",
       " ('conference#Reviewer', 'iasted#Reviewer'),\n",
       " ('conference#Person', 'iasted#Person'),\n",
       " ('conference#Regular_author', 'iasted#Author'),\n",
       " ('conference#Conference_fees', 'iasted#Fee'),\n",
       " ('conference#Tutorial', 'iasted#Tutorial'),\n",
       " ('conference#contributes', 'iasted#write'),\n",
       " ('conference#Review', 'iasted#Review'),\n",
       " ('conference#Conference_document', 'iasted#Document'),\n",
       " ('conference#Conference_part', 'iasted#Conference_activity'),\n",
       " ('conference#Submitted_contribution', 'iasted#Submission'),\n",
       " ('conference#Camera_ready_contribution', 'iasted#Final_manuscript'),\n",
       " ('conference#Conference_proceedings', 'iasted#Publication'),\n",
       " ('confOf#Trip', 'edas#Excursion'),\n",
       " ('confOf#Social_event', 'edas#SocialEvent'),\n",
       " ('confOf#reviewes', 'edas#isReviewing'),\n",
       " ('confOf#Organization', 'edas#Organization'),\n",
       " ('confOf#writtenBy', 'edas#isWrittenBy'),\n",
       " ('confOf#Working_event', 'edas#AcademicEvent'),\n",
       " ('confOf#Reception', 'edas#Reception'),\n",
       " ('confOf#hasSurname', 'edas#hasLastName'),\n",
       " ('confOf#Workshop', 'edas#Workshop'),\n",
       " ('confOf#Author', 'edas#Author'),\n",
       " ('confOf#hasFirstName', 'edas#hasFirstName'),\n",
       " ('confOf#Event', 'edas#ConferenceEvent'),\n",
       " ('confOf#Topic', 'edas#Topic'),\n",
       " ('confOf#Country', 'edas#Country'),\n",
       " ('confOf#Participant', 'edas#Attendee'),\n",
       " ('confOf#Person', 'edas#Person'),\n",
       " ('confOf#Member_PC', 'edas#TPCMember'),\n",
       " ('confOf#Paper', 'edas#Paper'),\n",
       " ('confOf#writes', 'edas#hasRelatedPaper'),\n",
       " ('edas#Place', 'iasted#Place'),\n",
       " ('edas#SessionChair', 'iasted#Session_chair'),\n",
       " ('edas#Author', 'iasted#Author'),\n",
       " ('edas#Document', 'iasted#Document'),\n",
       " ('edas#Country', 'iasted#State'),\n",
       " ('edas#WelcomeTalk', 'iasted#Welcome_address'),\n",
       " ('edas#Sponsorship', 'iasted#Sponzorship'),\n",
       " ('edas#Reviewer', 'iasted#Reviewer'),\n",
       " ('edas#Attendee', 'iasted#Delegate'),\n",
       " ('edas#ConferenceDinner', 'iasted#Dinner_banquet'),\n",
       " ('edas#SocialEvent', 'iasted#Social_program'),\n",
       " ('edas#CoffeeBreak', 'iasted#Coffee_break'),\n",
       " ('edas#Review', 'iasted#Review'),\n",
       " ('edas#Reception', 'iasted#Coctail_reception'),\n",
       " ('edas#ConferenceEvent', 'iasted#Conference_activity'),\n",
       " ('edas#SlideSet', 'iasted#Transparency'),\n",
       " ('edas#Paper', 'iasted#Submission'),\n",
       " ('edas#ConferenceVenuePlace', 'iasted#Conference_building'),\n",
       " ('edas#DiningPlace', 'iasted#Conference_restaurant'),\n",
       " ('conference#Person', 'edas#Person'),\n",
       " ('conference#Conference_participant', 'edas#Attendee'),\n",
       " ('conference#Organization', 'edas#Organization'),\n",
       " ('conference#Reviewer', 'edas#Reviewer'),\n",
       " ('conference#has_the_first_name', 'edas#hasFirstName'),\n",
       " ('conference#Conference_part', 'edas#ConferenceEvent'),\n",
       " ('conference#Workshop', 'edas#Workshop'),\n",
       " ('conference#Conference_document', 'edas#Document'),\n",
       " ('conference#Paper', 'edas#Paper'),\n",
       " ('conference#has_a_review_expertise', 'edas#hasRating'),\n",
       " ('conference#has_the_last_name', 'edas#hasLastName'),\n",
       " ('conference#Review', 'edas#Review'),\n",
       " ('conference#Conference_volume', 'edas#Conference'),\n",
       " ('conference#Rejected_contribution', 'edas#RejectedPaper'),\n",
       " ('conference#Topic', 'edas#Topic'),\n",
       " ('conference#Accepted_contribution', 'edas#AcceptedPaper'),\n",
       " ('conference#Regular_author', 'edas#Author'),\n",
       " ('cmt#Document', 'ekaw#Document'),\n",
       " ('cmt#ConferenceMember', 'ekaw#Conference_Participant'),\n",
       " ('cmt#Author', 'ekaw#Paper_Author'),\n",
       " ('cmt#writtenBy', 'ekaw#reviewWrittenBy'),\n",
       " ('cmt#hasBeenAssigned', 'ekaw#reviewerOfPaper'),\n",
       " ('cmt#Person', 'ekaw#Person'),\n",
       " ('cmt#Conference', 'ekaw#Conference'),\n",
       " ('cmt#assignedTo', 'ekaw#hasReviewer'),\n",
       " ('cmt#Review', 'ekaw#Review'),\n",
       " ('cmt#Paper', 'ekaw#Paper'),\n",
       " ('cmt#PaperFullVersion', 'ekaw#Regular_Paper'),\n",
       " ('cmt#ProgramCommitteeChair', 'confOf#Chair_PC'),\n",
       " ('cmt#writePaper', 'confOf#writes'),\n",
       " ('cmt#Author', 'confOf#Author'),\n",
       " ('cmt#ConferenceMember', 'confOf#Member'),\n",
       " ('cmt#Administrator', 'confOf#Administrator'),\n",
       " ('cmt#title', 'confOf#hasTitle'),\n",
       " ('cmt#SubjectArea', 'confOf#Topic'),\n",
       " ('cmt#PaperFullVersion', 'confOf#Paper'),\n",
       " ('cmt#hasBeenAssigned', 'confOf#reviewes'),\n",
       " ('cmt#hasAuthor', 'confOf#writtenBy'),\n",
       " ('cmt#Conference', 'confOf#Conference'),\n",
       " ('cmt#ProgramCommitteeMember', 'confOf#Member_PC'),\n",
       " ('cmt#hasSubjectArea', 'confOf#dealsWith'),\n",
       " ('cmt#Person', 'confOf#Person'),\n",
       " ('cmt#Paper', 'confOf#Contribution'),\n",
       " ('cmt#email', 'confOf#hasEmail'),\n",
       " ('cmt#Person', 'edas#Person'),\n",
       " ('cmt#Conference', 'edas#Conference'),\n",
       " ('cmt#Author', 'edas#Author'),\n",
       " ('cmt#Reviewer', 'edas#Reviewer'),\n",
       " ('cmt#hasConferenceMember', 'edas#hasMember'),\n",
       " ('cmt#memberOfConference', 'edas#isMemberOf'),\n",
       " ('cmt#ConferenceChair', 'edas#ConferenceChair'),\n",
       " ('cmt#Review', 'edas#Review'),\n",
       " ('cmt#Document', 'edas#Document'),\n",
       " ('cmt#Paper', 'edas#Paper'),\n",
       " ('cmt#hasAuthor', 'edas#isWrittenBy'),\n",
       " ('cmt#hasBeenAssigned', 'edas#isReviewing'),\n",
       " ('cmt#assignedTo', 'edas#isReviewedBy'),\n",
       " ('conference#Abstract', 'sigkdd#Abstract'),\n",
       " ('conference#Invited_speaker', 'sigkdd#Invited_Speaker'),\n",
       " ('conference#Regular_author', 'sigkdd#Author'),\n",
       " ('conference#Review', 'sigkdd#Review'),\n",
       " ('conference#Program_committee', 'sigkdd#Program_Committee'),\n",
       " ('conference#Conference_volume', 'sigkdd#Conference'),\n",
       " ('conference#Conference_fees', 'sigkdd#Fee'),\n",
       " ('conference#has_an_email', 'sigkdd#E-mail'),\n",
       " ('conference#Paper', 'sigkdd#Paper'),\n",
       " ('conference#Organizing_committee', 'sigkdd#Organizing_Committee'),\n",
       " ('conference#Person', 'sigkdd#Person'),\n",
       " ('conference#Committee', 'sigkdd#Committee'),\n",
       " ('conference#is_given_by', 'sigkdd#presentationed_by'),\n",
       " ('conference#gives_presentations', 'sigkdd#presentation'),\n",
       " ('conference#Conference_document', 'sigkdd#Document'),\n",
       " ('cmt#Conference', 'sigkdd#Conference'),\n",
       " ('cmt#Paper', 'sigkdd#Paper'),\n",
       " ('cmt#ProgramCommitteeMember', 'sigkdd#Program_Committee_member'),\n",
       " ('cmt#Document', 'sigkdd#Document'),\n",
       " ('cmt#ConferenceChair', 'sigkdd#General_Chair'),\n",
       " ('cmt#email', 'sigkdd#E-mail'),\n",
       " ('cmt#Review', 'sigkdd#Review'),\n",
       " ('cmt#ProgramCommittee', 'sigkdd#Program_Committee'),\n",
       " ('cmt#ProgramCommitteeChair', 'sigkdd#Program_Chair'),\n",
       " ('cmt#Author', 'sigkdd#Author'),\n",
       " ('cmt#submitPaper', 'sigkdd#submit'),\n",
       " ('cmt#Person', 'sigkdd#Person'),\n",
       " ('conference#Conference_participant', 'confOf#Participant'),\n",
       " ('conference#has_an_email', 'confOf#hasEmail'),\n",
       " ('conference#Poster', 'confOf#Poster'),\n",
       " ('conference#Organization', 'confOf#Organization'),\n",
       " ('conference#Topic', 'confOf#Topic'),\n",
       " ('conference#Workshop', 'confOf#Workshop'),\n",
       " ('conference#Paper', 'confOf#Paper'),\n",
       " ('conference#Person', 'confOf#Person'),\n",
       " ('conference#Conference_contribution', 'confOf#Contribution'),\n",
       " ('conference#Tutorial', 'confOf#Tutorial'),\n",
       " ('conference#Conference_volume', 'confOf#Conference'),\n",
       " ('conference#has_a_track-workshop-tutorial_topic', 'confOf#hasTopic'),\n",
       " ('conference#Regular_author', 'confOf#Author'),\n",
       " ('conference#has_the_last_name', 'confOf#hasSurname'),\n",
       " ('conference#has_the_first_name', 'confOf#hasFirstName'),\n",
       " ('edas#ConferenceDinner', 'ekaw#Conference_Banquet'),\n",
       " ('edas#AcademicEvent', 'ekaw#Scientific_Event'),\n",
       " ('edas#AcceptedPaper', 'ekaw#Accepted_Paper'),\n",
       " ('edas#isReviewedBy', 'ekaw#hasReviewer'),\n",
       " ('edas#Place', 'ekaw#Location'),\n",
       " ('edas#AcademiaOrganization', 'ekaw#Academic_Institution'),\n",
       " ('edas#SocialEvent', 'ekaw#Social_Event'),\n",
       " ('edas#isReviewing', 'ekaw#reviewerOfPaper'),\n",
       " ('edas#Organization', 'ekaw#Organisation'),\n",
       " ('edas#Author', 'ekaw#Paper_Author'),\n",
       " ('edas#isLocationOf', 'ekaw#locationOf'),\n",
       " ('edas#Topic', 'ekaw#Research_Topic'),\n",
       " ('edas#Document', 'ekaw#Document'),\n",
       " ('edas#RejectedPaper', 'ekaw#Rejected_Paper'),\n",
       " ('edas#ConferenceEvent', 'ekaw#Event'),\n",
       " ('edas#SessionChair', 'ekaw#Session_Chair'),\n",
       " ('edas#Person', 'ekaw#Person'),\n",
       " ('edas#Programme', 'ekaw#Programme_Brochure'),\n",
       " ('edas#Review', 'ekaw#Review'),\n",
       " ('edas#Workshop', 'ekaw#Workshop'),\n",
       " ('edas#Paper', 'ekaw#Paper'),\n",
       " ('edas#Attendee', 'ekaw#Conference_Participant'),\n",
       " ('edas#hasLocation', 'ekaw#heldIn'),\n",
       " ('cmt#Conference', 'conference#Conference_volume'),\n",
       " ('cmt#Preference', 'conference#Review_preference'),\n",
       " ('cmt#Author', 'conference#Regular_author'),\n",
       " ('cmt#Person', 'conference#Person'),\n",
       " ('cmt#email', 'conference#has_an_email'),\n",
       " ('cmt#Co-author', 'conference#Contribution_co-author'),\n",
       " ('cmt#PaperAbstract', 'conference#Abstract'),\n",
       " ('cmt#Document', 'conference#Conference_document'),\n",
       " ('cmt#Review', 'conference#Review'),\n",
       " ('cmt#Conference', 'conference#Conference'),\n",
       " ('cmt#ProgramCommittee', 'conference#Program_committee'),\n",
       " ('cmt#Chairman', 'conference#Chair'),\n",
       " ('cmt#SubjectArea', 'conference#Topic'),\n",
       " ('cmt#assignedByReviewer', 'conference#invited_by'),\n",
       " ('cmt#assignExternalReviewer', 'conference#invites_co-reviewers'),\n",
       " ('cmt#Author', 'iasted#Author'),\n",
       " ('cmt#Review', 'iasted#Review'),\n",
       " ('cmt#Person', 'iasted#Person'),\n",
       " ('cmt#Reviewer', 'iasted#Reviewer'),\n",
       " ('ekaw#Location', 'iasted#Place'),\n",
       " ('ekaw#Document', 'iasted#Document'),\n",
       " ('ekaw#Event', 'iasted#Activity'),\n",
       " ('ekaw#Person', 'iasted#Person'),\n",
       " ('ekaw#Paper_Author', 'iasted#Author'),\n",
       " ('ekaw#Session', 'iasted#Session'),\n",
       " ('ekaw#Review', 'iasted#Review'),\n",
       " ('ekaw#Conference_Banquet', 'iasted#Dinner_banquet'),\n",
       " ('ekaw#Tutorial', 'iasted#Tutorial'),\n",
       " ('ekaw#Session_Chair', 'iasted#Session_chair')]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
