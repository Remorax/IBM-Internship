{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction of dataset\n",
    "\n",
    "import os, itertools, time, pickle, sys, glob, requests\n",
    "import subprocess\n",
    "from xml.dom import minidom\n",
    "from collections import Counter, OrderedDict\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import wordnet\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from math import ceil, exp\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "class Ontology():\n",
    "    def __init__(self, ontology):\n",
    "        self.ontology = ontology\n",
    "        self.ontology_obj = minidom.parse(ontology)\n",
    "        self.root = self.ontology_obj.documentElement\n",
    "        self.construct_mapping_dict()\n",
    "        \n",
    "        self.parents_dict = {}\n",
    "        self.subclasses = self.parse_subclasses()\n",
    "        self.object_properties = self.parse_object_properties()\n",
    "        self.data_properties = self.parse_data_properties()\n",
    "        self.triples = self.parse_triples()\n",
    "        self.classes = self.parse_classes()        \n",
    "    \n",
    "    def construct_mapping_dict(self):\n",
    "        all_classes = self.root.getElementsByTagName(\"owl:Class\") + self.root.getElementsByTagName(\"rdf:Description\") + self.root.getElementsByTagName(\"Class\") + self.root.getElementsByTagName(\"owl:ObjectProperty\") + self.root.getElementsByTagName(\"ObjectProperty\")\n",
    "        self.mapping_dict = {self.extract_ID(el, False): self.get_child_node(el, \"rdfs:label\")[0].firstChild.nodeValue for el in all_classes if self.get_child_node(el, \"rdfs:label\")}\n",
    "        self.mapping_dict_inv = {self.mapping_dict[key]: key for key in self.mapping_dict}\n",
    "        return\n",
    "        \n",
    "    def get_child_node(self, element, tag):\n",
    "        return [e for e in element._get_childNodes() if type(e)==minidom.Element and e._get_tagName() == tag]\n",
    "        \n",
    "    def has_attribute_value(self, element, attribute, value):\n",
    "        return True if element.getAttribute(attribute).split(\"#\")[-1] == value else False\n",
    "    \n",
    "    def get_subclass_triples(self):\n",
    "        subclasses = self.get_subclasses()\n",
    "        for (a,b,c) in subclasses:\n",
    "            if c == \"subclass_of\" and a!=\"Thing\" and b!=\"Thing\":\n",
    "                if b not in self.parents_dict:\n",
    "                    self.parents_dict[b] = [a]\n",
    "                else:\n",
    "                    self.parents_dict[b].append(a)\n",
    "        return [(b,a,c) for (a,b,c) in subclasses]\n",
    "    \n",
    "    def parse_triples(self, union_flag=0, subclass_of=True, data_prop=True):\n",
    "        obj_props = self.object_properties\n",
    "        if data_prop:\n",
    "            data_props = self.data_properties\n",
    "            props = obj_props + data_props\n",
    "        else:\n",
    "            props = obj_props\n",
    "        all_triples = []\n",
    "        for prop in props:\n",
    "            domain_children = self.get_child_node(prop, \"rdfs:domain\")\n",
    "            range_children = self.get_child_node(prop, \"rdfs:range\")\n",
    "            domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children])\n",
    "            range_prop = self.filter_null([self.extract_ID(el) for el in range_children])\n",
    "            if not domain_children or not range_children:\n",
    "                continue\n",
    "            if not domain_prop:\n",
    "                domain_prop = self.filter_null([self.extract_ID(el) for el in domain_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if not range_prop:\n",
    "                range_prop = self.filter_null([self.extract_ID(el) for el in range_children[0].getElementsByTagName(\"owl:Class\")])\n",
    "            if domain_prop and range_prop:\n",
    "                if union_flag == 0:\n",
    "                    all_triples.extend([(el[0], el[1], self.extract_ID(prop)) for el in list(itertools.product(domain_prop, range_prop))])\n",
    "                else:\n",
    "                    all_triples.append((\"###\".join(domain_prop), \"###\".join(range_prop), self.extract_ID(prop)))\n",
    "        if subclass_of:\n",
    "            all_triples.extend(self.get_subclass_triples())\n",
    "        return list(set(all_triples))\n",
    "    \n",
    "    def get_triples(self, union_flag=0, subclass_of=True):\n",
    "        return self.parse_triples(union_flag, subclass_of)\n",
    "\n",
    "    def parse_subclasses(self, union_flag=0):\n",
    "        subclasses = self.root.getElementsByTagName(\"rdfs:subClassOf\")\n",
    "        subclass_pairs = []\n",
    "        for el in subclasses:\n",
    "            inline_subclasses = self.extract_ID(el)\n",
    "            if inline_subclasses:\n",
    "                subclass_pairs.append((el, el.parentNode, \"subclass_of\"))\n",
    "            else:\n",
    "                level1_class = self.get_child_node(el, \"owl:Class\")\n",
    "                if not level1_class:\n",
    "                    restriction = el.getElementsByTagName(\"owl:Restriction\")\n",
    "                    if not restriction:\n",
    "                        continue\n",
    "                    prop = self.get_child_node(restriction[0], \"owl:onProperty\")\n",
    "                    some_vals = self.get_child_node(restriction[0], \"owl:someValuesFrom\")\n",
    "                    \n",
    "                    if not prop or not some_vals:\n",
    "                        continue\n",
    "#                     print(self.extract_ID(el), \"**\", self.extract_ID(some_vals[0]), \"**\", self.extract_ID(prop[0]))\n",
    "                    try:\n",
    "                        if self.extract_ID(prop[0]) and self.extract_ID(some_vals[0]):\n",
    "                            subclass_pairs.append((el.parentNode, some_vals[0], self.extract_ID(prop[0])))\n",
    "                        elif self.extract_ID(prop[0]) and not self.extract_ID(some_vals[0]):\n",
    "                            class_vals = self.get_child_node(some_vals[0], \"owl:Class\")\n",
    "                            subclass_pairs.append((el.parentNode, class_vals[0], self.extract_ID(prop[0])))\n",
    "                        elif not self.extract_ID(prop[0]) and self.extract_ID(some_vals[0]):\n",
    "                            prop_vals = self.get_child_node(prop[0], \"owl:ObjectProperty\")\n",
    "                            subclass_pairs.append((el.parentNode, some_vals[0], self.extract_ID(prop_vals[0])))\n",
    "                        else:\n",
    "                            prop_vals = self.get_child_node(prop[0], \"owl:ObjectProperty\")\n",
    "                            class_vals = self.get_child_node(some_vals[0], \"owl:Class\")\n",
    "                            subclass_pairs.append((el.parentNode, class_vals[0], self.extract_ID(prop_vals[0])))\n",
    "                    except Exception as e:\n",
    "                        print (\"error\", e)\n",
    "                        continue\n",
    "                else:\n",
    "                    if self.extract_ID(level1_class[0]):\n",
    "                        subclass_pairs.append((level1_class[0], el.parentNode, \"subclass_of\"))\n",
    "                    else:\n",
    "#                         level2classes = level1_class[0].getElementsByTagName(\"owl:Class\")\n",
    "#                         subclass_pairs.extend([(elem, el.parentNode, \"subclass_of\") for elem in level2classes if self.extract_ID(elem)])\n",
    "                        continue\n",
    "        return subclass_pairs\n",
    "        \n",
    "    def get_subclasses(self):\n",
    "        subclasses = [(self.extract_ID(a), self.extract_ID(b), c) for (a,b,c) in self.subclasses]\n",
    "        return [el for el in subclasses if el[0] and el[1] and el[2] and el[0]!=\"Thing\" and el[1]!=\"Thing\"]\n",
    "    \n",
    "    def filter_null(self, data):\n",
    "        return [el for el in data if el]\n",
    "    \n",
    "    def extract_ID(self, element, check_coded = True):\n",
    "        element_id = element.getAttribute(\"rdf:ID\") or element.getAttribute(\"rdf:resource\") or element.getAttribute(\"rdf:about\")\n",
    "        element_id = element_id.split(\"#\")[-1]\n",
    "        if len(list(filter(str.isdigit, element_id))) >= 3 and \"_\" in element_id and check_coded:\n",
    "            return self.mapping_dict[element_id]\n",
    "        return element_id.replace(\"UNDEFINED_\", \"\").replace(\"DO_\", \"\")\n",
    "    \n",
    "    def parse_classes(self):\n",
    "        class_elems = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        subclass_classes = list(set(flatten([el[:-1] for el in self.triples])))\n",
    "        return list(set(self.filter_null(class_elems + subclass_classes)))\n",
    "    \n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    def get_entities(self):\n",
    "        entities = [self.extract_ID(el) for el in self.root.getElementsByTagName(\"owl:Class\")]\n",
    "        return list(set(self.filter_null(entities)))\n",
    "\n",
    "    def parse_data_properties(self):\n",
    "        data_properties = [el for el in self.get_child_node(self.root, 'owl:DatatypeProperty')]\n",
    "        fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_data_properties = [el for el in fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        inv_fn_data_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_data_properties = [el for el in inv_fn_data_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"DatatypeProperty\")]]\n",
    "        return data_properties + fn_data_properties + inv_fn_data_properties\n",
    "        \n",
    "    def parse_object_properties(self):\n",
    "        obj_properties = [el for el in self.get_child_node(self.root, 'owl:ObjectProperty')]\n",
    "        fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:FunctionalProperty') if el]\n",
    "        fn_obj_properties = [el for el in fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        inv_fn_obj_properties = [el for el in self.get_child_node(self.root, 'owl:InverseFunctionalProperty') if el]\n",
    "        inv_fn_obj_properties = [el for el in inv_fn_obj_properties if type(el)==minidom.Element and \n",
    "            [el for el in self.get_child_node(el, \"rdf:type\") if \n",
    "             self.has_attribute_value(el, \"rdf:resource\", \"ObjectProperty\")]]\n",
    "        return obj_properties + fn_obj_properties + inv_fn_obj_properties\n",
    "    \n",
    "    def get_object_properties(self):\n",
    "        obj_props = [self.extract_ID(el) for el in self.object_properties]\n",
    "        return list(set(self.filter_null(obj_props)))\n",
    "    \n",
    "    def get_data_properties(self):\n",
    "        data_props = [self.extract_ID(el) for el in self.data_properties]\n",
    "        return list(set(self.filter_null(data_props)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adaxial stomatal frequency',\n",
       " 'ear color',\n",
       " 'oxidative stress',\n",
       " 'metabolized energy of stover',\n",
       " 'sulfur sensitivity',\n",
       " 'radicleless',\n",
       " 'seed texture',\n",
       " 'groat percentage',\n",
       " 'vascular tissue morphology trait',\n",
       " 'cell cycle trait',\n",
       " 'root cortex cross-sectional area',\n",
       " 'violaxanthin content',\n",
       " 'ear circumference',\n",
       " 'stem morphology trait',\n",
       " 'panicle to tiller ratio',\n",
       " 'panicle compactness and shape',\n",
       " 'panicleless',\n",
       " 'root system cadmium content',\n",
       " 'nitrogen recycling',\n",
       " 'phosphoglycerate mutase content',\n",
       " 'trichome hirsute',\n",
       " 'floral bract development trait',\n",
       " 'shoot system zinc content',\n",
       " 'cyanide content',\n",
       " 'penetrated root thickness',\n",
       " 'tassel inflorescence morphology trait',\n",
       " 'plant cell shape',\n",
       " 'ligule margin pubescence',\n",
       " 'days to ear shoot emergence',\n",
       " 'leaf senescence duration',\n",
       " 'seed coat texture',\n",
       " 'genic male sterility-thermo sensitive',\n",
       " 'cyclic carotene content',\n",
       " 'cutworm resistance',\n",
       " 'tuberous root tuber morphology trait',\n",
       " 'root system silicon content',\n",
       " 'photosynthetic rate',\n",
       " 'seed viability',\n",
       " 'floury endosperm',\n",
       " 'leaf width',\n",
       " 'dry matter digestibility',\n",
       " 'fruit attachment',\n",
       " 'aborted bi-nucleate stage',\n",
       " '100-dehulled grain weight',\n",
       " 'organ margin morphology trait',\n",
       " 'red light sensitivity',\n",
       " 'fruit quality trait',\n",
       " 'zeaxanthin content',\n",
       " 'female flowering',\n",
       " 'phyllochron',\n",
       " 'leaf morphology trait',\n",
       " 'leaf sheath morphology trait',\n",
       " 'canopy temperature',\n",
       " 'inflorescence axis color',\n",
       " 'callus induction',\n",
       " 'lithium content',\n",
       " 'gametophytic incompatibility',\n",
       " 'plant volume',\n",
       " 'lateral root length',\n",
       " 'percent root mass density',\n",
       " 'iron content trait',\n",
       " 'leaf trichome density',\n",
       " 'leaf size',\n",
       " 'grain shattering',\n",
       " 'spikelet fertility',\n",
       " 'relative root length',\n",
       " 'microsporocyte number',\n",
       " 'seed length',\n",
       " 'relative total dry weight',\n",
       " 'starch yield',\n",
       " 'cardinal organ part morphology trait',\n",
       " 'shoot system manganese content',\n",
       " 'aroma',\n",
       " 'leaf margin serrated',\n",
       " 'mimic response',\n",
       " 'pyruvate orthophosphate dikinase activity trait',\n",
       " 'chalky endosperm',\n",
       " 'root system depth',\n",
       " 'root system iodine content',\n",
       " 'weed damage',\n",
       " 'relative leaf dry weight',\n",
       " 'lateral root number',\n",
       " 'oligosaccharide content',\n",
       " 'leaf sheath color',\n",
       " 'stem color',\n",
       " 'wheat common root rot resistance',\n",
       " 'petal size',\n",
       " 'grain tenderness',\n",
       " 'rhizome internode length',\n",
       " 'leaf temperature',\n",
       " 'sorghum downy mildew resistance',\n",
       " 'iron sensitivity',\n",
       " 'leaf adherence',\n",
       " 'fruit diameter',\n",
       " 'malt-extract percentage',\n",
       " 'relative water content',\n",
       " 'leaf sheath auricle morphology trait',\n",
       " 'lignin monomer content',\n",
       " 'inflorescence circumference',\n",
       " 'glucosamine content',\n",
       " 'ovary development trait',\n",
       " 'shoot system growth and development trait',\n",
       " 'magnesium to potassium content ratio',\n",
       " 'relative harvest index',\n",
       " 'rice hispa resistance',\n",
       " 'plant phenological trait',\n",
       " 'fungal disease resistance',\n",
       " 'stem cortex color',\n",
       " 'potassium chlorate resistance',\n",
       " 'leaf lamina joint bending',\n",
       " 'panicle number',\n",
       " 'green plantlet differentiation frequency',\n",
       " 'fruit distal end shape',\n",
       " 'fascicled ear',\n",
       " 'flour color',\n",
       " 'cuperic ion concentration',\n",
       " 'lodicule morphology trait',\n",
       " 'ear aspect',\n",
       " 'osmotic response sensitivity',\n",
       " 'panicle weight',\n",
       " 'sterility related trait',\n",
       " 'seed hardness',\n",
       " 'grain quality trait',\n",
       " 'viral disease resistance',\n",
       " 'phyllome margin morphology trait',\n",
       " 'pistil size',\n",
       " 'raffinose content',\n",
       " 'subterranean shoot axis tuber mass',\n",
       " 'sepal color',\n",
       " 'phenotypic acceptability',\n",
       " 'protein content',\n",
       " 'phyllotaxy',\n",
       " 'fertility restoration trait',\n",
       " 'polished grain width',\n",
       " 'root nodule number',\n",
       " 'leaf stomatal complex frequency',\n",
       " 'cob angle',\n",
       " 'wheat leaf rust disease resistance',\n",
       " 'sterile lemma length',\n",
       " 'penetrated to total root ratio',\n",
       " 'abaxial stomatal frequency',\n",
       " 'germination rate',\n",
       " 'branch angle',\n",
       " 'radiation response trait',\n",
       " 'percent root mass density 0-15',\n",
       " 'petal number',\n",
       " 'amylose content',\n",
       " 'fat and essential oil content',\n",
       " 'spikelet floret size',\n",
       " 'trichome capillary',\n",
       " 'chromium content trait',\n",
       " 'glume cover',\n",
       " 'leaf sheath length',\n",
       " 'phosphorus toxicity',\n",
       " 'days to tassel',\n",
       " 'gynoecium development trait',\n",
       " 'sogatodes resistance',\n",
       " 'sulfur content',\n",
       " 'rootworm resistance',\n",
       " 'root system boron content',\n",
       " 'leaf lamina margin pubescence length',\n",
       " 'rhizome branching number',\n",
       " 'spikelet number',\n",
       " 'iodine sensitivity',\n",
       " 'inflorescence bract number',\n",
       " 'tassel branch zone length',\n",
       " 'leaf lamina length',\n",
       " 'seed morphology trait',\n",
       " 'stem epidermis color',\n",
       " 'popping expansion volume',\n",
       " 'microbial damage resistance',\n",
       " 'root system strontium content',\n",
       " 'grass weed',\n",
       " 'days to maturity',\n",
       " 'surface area of grain with hull',\n",
       " 'adventitious root thickness',\n",
       " 'mannose content',\n",
       " 'stomatal opening',\n",
       " 'rice bacterial leaf streak disease resistance',\n",
       " 'secondary macronutrient sensitivity',\n",
       " 'root system nickel content',\n",
       " 'rhizome length',\n",
       " 'sporophytic incompatibility',\n",
       " 'tiller number',\n",
       " 'acid sensitivity',\n",
       " 'crop damage resistance',\n",
       " 'calcium content trait',\n",
       " 'kernel weight per ear',\n",
       " 'lemma and palea color',\n",
       " 'leaf lamina morphology trait',\n",
       " 'biochemical trait',\n",
       " 'inflorescence development trait',\n",
       " 'manganese content',\n",
       " 'grain thickness',\n",
       " 'acyclic carotene content',\n",
       " 'UV-B light sensitivity',\n",
       " 'aleurone layer morphology trait',\n",
       " 'ufra damage',\n",
       " 'leaf lamina splitting',\n",
       " 'other miscellaneous trait',\n",
       " 'insecticide sensitivity',\n",
       " 'brown rice yield',\n",
       " 'albumin content',\n",
       " 'node shattering',\n",
       " 'seed size',\n",
       " 'total fat content',\n",
       " 'barley wort protein concentration',\n",
       " 'cellulose content',\n",
       " 'spikelet sterility',\n",
       " 'hybrid incompatibility',\n",
       " 'microsporocyte development trait',\n",
       " 'leaf shape',\n",
       " 'seed coat spotted',\n",
       " 'barley stripe rust disease resistance',\n",
       " 'basal axillary primary branch number',\n",
       " 'cytokinin sensitivity',\n",
       " 'petiolule length',\n",
       " 'spine leaf morphology trait',\n",
       " 'European corn borer resistance',\n",
       " 'nitrate transport',\n",
       " 'alkali sensitivity',\n",
       " 'beta-cryptoxanthin content',\n",
       " 'endosperm storage protein-1 content',\n",
       " 'amylase activity trait',\n",
       " 'f2-generation sterility',\n",
       " 'Zea mays northern leaf blight disease resistance',\n",
       " 'apical axillary tertiary branch number',\n",
       " 'panicle exsertion',\n",
       " 'ear infructescence position ratio',\n",
       " 'fruit color uniformity',\n",
       " 'glume persistence',\n",
       " 'root cracking',\n",
       " 'tepal number',\n",
       " 'root system iron content',\n",
       " 'shoot-borne shoot system morphology trait',\n",
       " 'root system sulfur content',\n",
       " 'collective plant organ structure morphology trait',\n",
       " 'peduncle type',\n",
       " 'root system arsenic content',\n",
       " 'seedling hypocotyl length',\n",
       " 'etched endosperm',\n",
       " 'fruit type',\n",
       " 'chickpea pod borer',\n",
       " 'axillary bud size',\n",
       " 'malt tenderness',\n",
       " 'seedling cotyledon number',\n",
       " 'relative yield',\n",
       " 'root nodule morphology trait',\n",
       " 'floral bract number',\n",
       " 'leaf margin color',\n",
       " 'fluorine sensitivity',\n",
       " 'alkali soil sensitivity',\n",
       " 'anthesis silking interval',\n",
       " 'leaf necrosis tolerance',\n",
       " 'stem strength',\n",
       " 'root system calcium content',\n",
       " 'flowering time trait',\n",
       " 'shoot habit',\n",
       " 'shoot system iodine content',\n",
       " 'vascular bundle development trait',\n",
       " 'petiolule morphology trait',\n",
       " 'plant embryo morphology trait',\n",
       " 'inflorescence presence',\n",
       " 'lemma length',\n",
       " 'rank number per ear',\n",
       " 'grain curved length',\n",
       " 'white rice protein content',\n",
       " 'percent root mass density 30-45',\n",
       " 'drought recovery',\n",
       " 'endosperm storage protein-2 content',\n",
       " 'leaf shattering',\n",
       " 'root system molybdenum content',\n",
       " 'peduncle morphology trait',\n",
       " 'vigor related trait',\n",
       " 'starch mobilization',\n",
       " 'grain size',\n",
       " 'broad-leaved weed',\n",
       " 'aluminum sensitivity',\n",
       " 'soluble protein content',\n",
       " 'lutein content',\n",
       " 'beta-glucanase thermostability',\n",
       " 'nodal rooting',\n",
       " 'inflorescence hairiness',\n",
       " 'awn color',\n",
       " 'ethylene sensitivity',\n",
       " 'starch digestibility',\n",
       " 'glume pubescence density',\n",
       " 'sorghum leaf blight resistance',\n",
       " 'tuberous root tuber diameter',\n",
       " 'plant ovary morphology',\n",
       " 'cell organelle development trait',\n",
       " 'shoot system yield trait',\n",
       " 'root to shoot ratio',\n",
       " 'incompatibility trait',\n",
       " 'flag leaf lamina width',\n",
       " 'photoperiod sensitivity trait',\n",
       " 'cooked grain elongation',\n",
       " 'seed shattering',\n",
       " 'tillering ability',\n",
       " 'tassel inflorescence length',\n",
       " 'hilum morphology trait',\n",
       " 'vivipary',\n",
       " 'endocarp morphology trait',\n",
       " 'starchiness',\n",
       " 'glutinous endosperm',\n",
       " 'root meristem development',\n",
       " 'fruit hairiness',\n",
       " 'pericarp texture',\n",
       " 'starch grain shape',\n",
       " 'flag leaf angle: late stage',\n",
       " 'spikelet floret diameter',\n",
       " 'fruit morphology trait',\n",
       " 'meiotic cell cycle trait',\n",
       " 'leaf midvein morphology trait',\n",
       " 'penetrated root length',\n",
       " 'peduncle length',\n",
       " 'tepal morphology trait',\n",
       " 'floral organ development trait',\n",
       " 'ethanol yield from biomass',\n",
       " 'momilactone B content',\n",
       " 'grain length to width ratio',\n",
       " 'root weight',\n",
       " 'root mass density',\n",
       " 'NCLB area under disease progress curve',\n",
       " 'seedling height',\n",
       " 'axillary bud shape',\n",
       " 'lycopene content',\n",
       " 'stipule length',\n",
       " 'watery lesion percentage',\n",
       " 'tassel inflorescence color',\n",
       " 'shoot system boron content',\n",
       " 'shoot axis weight',\n",
       " 'iodine content trait',\n",
       " 'axillary bud dormancy',\n",
       " 'seedling growth and development trait',\n",
       " 'bud morphology trait',\n",
       " 'spikelet morphology trait',\n",
       " 'rhizome formation',\n",
       " 'root number',\n",
       " '2,4-dichlorophenoxyacetic acid sensitivity',\n",
       " 'secondary shoot branch number',\n",
       " 'rice cytoplasmic male sterility',\n",
       " 'brown rice shape',\n",
       " 'water use efficiency',\n",
       " 'male fertility restoration trait',\n",
       " 'globular embryo',\n",
       " 'starch grain size',\n",
       " 'female sterility',\n",
       " 'carbohydrate content',\n",
       " 'root yield',\n",
       " 'seed longevity',\n",
       " 'petiole morphology trait',\n",
       " 'inflorescence bract length',\n",
       " 'plant survival percentage under submergence',\n",
       " 'inflorescence axis angle',\n",
       " 'wild abortive CMS',\n",
       " 'leaf erect',\n",
       " 'chinsurah boro CMS',\n",
       " 'tassel spike length',\n",
       " 'humidity related trait',\n",
       " 'water stress trait',\n",
       " 'glume number',\n",
       " 'leaf yield trait',\n",
       " 'barley septoria disease resistance',\n",
       " 'inflorescence length',\n",
       " 'kneeing ability',\n",
       " 'deoxynivalenol content',\n",
       " 'leaf length to width ratio',\n",
       " 'megasporocyte development trait',\n",
       " 'flavonoid content',\n",
       " 'panicle color',\n",
       " 'relative shoot elongation under submergence',\n",
       " 'apical axillary secondary branch number',\n",
       " 'deep root number',\n",
       " 'carotenoid content',\n",
       " 'days to flowering trait',\n",
       " 'apical axillary branch number',\n",
       " 'Indole-3-acetic acid content',\n",
       " 'jasmonic acid content',\n",
       " 'dry fruit color',\n",
       " 'leaf area duration',\n",
       " 'carotene content',\n",
       " 'colored grain percentage',\n",
       " 'DSDS50',\n",
       " 'reproductive homeotic development trait',\n",
       " 'manganese sensitivity',\n",
       " 'cooking or brewing quality',\n",
       " 'glyphosate sensitivity',\n",
       " 'panicle shape',\n",
       " 'ear inflorescence morphology trait',\n",
       " 'leaf lamina lobe width',\n",
       " 'stamen morphology trait',\n",
       " 'shoot system nickel content',\n",
       " 'neoxanthin content',\n",
       " 'heterosis',\n",
       " 'plant color',\n",
       " 'invertase activity trait',\n",
       " 'stomatal process related trait',\n",
       " 'shoot system barium content',\n",
       " 'anthocyanin content',\n",
       " 'leaf drying',\n",
       " 'leaf sheath width',\n",
       " 'embryo sac abortion',\n",
       " 'liguleless',\n",
       " 'chickpea botrytis grey mold resistance',\n",
       " 'shoot phototropism',\n",
       " 'silicon content trait',\n",
       " 'osmotic adjustment capacity',\n",
       " 'total shoot elongation under submergence',\n",
       " 'leaf foliage rating',\n",
       " 'tertiary branch number',\n",
       " 'sucrose synthase activity trait',\n",
       " 'ash content',\n",
       " 'molybdenum sensitivity',\n",
       " 'ligule color',\n",
       " 'tassel branch number',\n",
       " 'stem internode morphology trait',\n",
       " 'plant embryo cotyledon morphology trait',\n",
       " 'inflorescence diameter',\n",
       " 'two-spotted spider mite resistance',\n",
       " 'embryoless',\n",
       " 'leaf area index',\n",
       " 'chickpea ascochyta blight resistance',\n",
       " 'fruit harvest index',\n",
       " 'cms-hl type',\n",
       " 'carbon isotope discrimination',\n",
       " 'tassel branch morphology trait',\n",
       " 'seed coat luster',\n",
       " 'relative spikelet number',\n",
       " 'root system potassium content',\n",
       " 'shoot system potassium content',\n",
       " 'basal tiller length',\n",
       " 'chickpea fusarium wild resistance',\n",
       " 'vascular leaf morphology trait',\n",
       " 'apiculus color',\n",
       " 'armyworm resistance',\n",
       " 'leaf prostrate',\n",
       " 'oxygen sensitivity',\n",
       " 'palea morphology trait',\n",
       " 'trichome morphology trait',\n",
       " 'auxin sensitivity',\n",
       " 'chlorophyll-b content',\n",
       " 'mesocarp morphology trait',\n",
       " 'hypocotyl morphology trait',\n",
       " 'leaf-roller resistance',\n",
       " 'pollen abortion type',\n",
       " 'sodium content',\n",
       " 'shoot system calcium content',\n",
       " 'selenium sensitivity',\n",
       " 'aborted tri-nucleate stage',\n",
       " 'fruit hollowness',\n",
       " 'floral organ size',\n",
       " 'fruit senescing quality trait',\n",
       " 'infructescence weight',\n",
       " 'salt sensitivity',\n",
       " 'plant axis morphology trait',\n",
       " 'ear infructescence number',\n",
       " 'root system sodium content',\n",
       " 'ear infructescence morphology trait',\n",
       " 'floret number',\n",
       " 'root system lithium content',\n",
       " 'rhizome number',\n",
       " 'root activity',\n",
       " 'maysin content',\n",
       " 'plant tissue development trait',\n",
       " 'inflorescence color',\n",
       " 'seminal root length',\n",
       " 'fruit columella color',\n",
       " 'seed coat morphology trait',\n",
       " 'sporogenesis',\n",
       " 'light intensity sensitivity',\n",
       " 'leaf thickness',\n",
       " 'fruit ripening trait',\n",
       " 'sodium concentration',\n",
       " 'momilactone A content',\n",
       " 'plant embryo cotyledon color',\n",
       " 'ligule shape',\n",
       " 'rice ragged stunt virus resistance',\n",
       " 'sepal morphology trait',\n",
       " 'root dry weight',\n",
       " 'brassinosteroid content',\n",
       " 'glume pubescence',\n",
       " 'days to inflorescence exsertion',\n",
       " 'head drop',\n",
       " 'adventitious root length',\n",
       " 'subterranean shoot axis tuber morphology trait',\n",
       " 'phloem color',\n",
       " 'mycotoxin content',\n",
       " 'total soluble sugar content',\n",
       " 'plant fresh weight',\n",
       " 'soluble to total protein ratio',\n",
       " 'inflorescence weight',\n",
       " 'infructescence morphology trait',\n",
       " 'root system width to depth ratio',\n",
       " 'rolled leaf',\n",
       " 'small vascular bundle number',\n",
       " 'curved length of grain with hull',\n",
       " 'phosphorus concentration',\n",
       " 'pistillate flower number trait',\n",
       " 'spine leaf color',\n",
       " 'length of grain with hull',\n",
       " 'amino acid content',\n",
       " 'fruit size',\n",
       " 'growth hormone content',\n",
       " 'flower shape',\n",
       " 'wrinkled seed',\n",
       " 'tassel inflorescence type',\n",
       " 'panicle size',\n",
       " 'root shape',\n",
       " 'pseudostem shape',\n",
       " 'ear diameter',\n",
       " 'shoot meristem development',\n",
       " 'relative acid phosphatase activity',\n",
       " 'grain number',\n",
       " 'copper concentration',\n",
       " 'seedling hypocotyl green',\n",
       " 'inflorescence type',\n",
       " 'peak viscosity',\n",
       " 'ligule margin shape',\n",
       " 'cracked grain percentage',\n",
       " 'sodium to potassium content ratio',\n",
       " 'root penetration index',\n",
       " 'petiole color',\n",
       " 'reproductive growth time',\n",
       " 'xanthophyll content',\n",
       " 'inflorescence size',\n",
       " 'stem internode bent',\n",
       " 'linoleic acid content',\n",
       " 'shoot system cadmium content',\n",
       " '1000-seed weight',\n",
       " 'stem weight',\n",
       " 'awn morphology trait',\n",
       " 'lemma and palea pubescence',\n",
       " 'space per culm',\n",
       " 'leaf elongation rate',\n",
       " 'ADP glucose pyrophosphorylase activity trait',\n",
       " 'herbicide sensitivity',\n",
       " 'kernel row length',\n",
       " 'bacterial disease resistance',\n",
       " 'leaf penduloum',\n",
       " 'leaf vein color',\n",
       " 'shoot system arsenic content',\n",
       " 'stem borer resistance',\n",
       " 'pedicel length',\n",
       " 'inflorescence primary branch length',\n",
       " 'seed dormancy',\n",
       " 'pungency',\n",
       " 'seedling mesocotyl morphology trait',\n",
       " 'protist disease resistance',\n",
       " 'inflorescence primary branch attitude',\n",
       " 'petiole size',\n",
       " 'grain shape',\n",
       " 'grain number per plant',\n",
       " 'chlorophyll-a content',\n",
       " 'flag leaf morphology trait',\n",
       " 'spikelet weight',\n",
       " 'sterile lemma color',\n",
       " 'chromium sensitivity',\n",
       " 'potassium content',\n",
       " 'volume of grain with hull',\n",
       " 'plant cell morphology trait',\n",
       " 'osmotic adjustment break point',\n",
       " 'glume length',\n",
       " 'nitrate sensitivity',\n",
       " 'potassium uptake',\n",
       " 'sterile lemma shape',\n",
       " 'barley leaf streak resistance',\n",
       " 'pearl millet downy mildew resistance',\n",
       " 'stem node number',\n",
       " 'floral organ length',\n",
       " 'zigzag leafhopper resistance',\n",
       " 'green leafhopper resistance',\n",
       " 'apiculus hair length',\n",
       " 'proline content',\n",
       " 'leaf area to spikelet number ratio',\n",
       " 'dull endosperm',\n",
       " 'tassel inflorescence diameter',\n",
       " 'leaf wet weight',\n",
       " 'stem thickness',\n",
       " 'rubisco to chlorophyll ratio',\n",
       " 'total root number',\n",
       " 'lignin content',\n",
       " 'shrunken endosperm',\n",
       " 'barley leaf scald disease resistance',\n",
       " 'tassel inflorescence circumference',\n",
       " 'leaf lamina pubescence density',\n",
       " 'stigma exsertion',\n",
       " 'spikelet rachilla shape',\n",
       " 'seed composition quality trait',\n",
       " 'hydrogen peroxide content',\n",
       " 'alpha carotene content',\n",
       " 'deepwater stress',\n",
       " 'phosphate content',\n",
       " 'spikelet density',\n",
       " 'pistil morphology trait',\n",
       " 'spikelet floret color',\n",
       " 'peduncle waxiness',\n",
       " 'leaf-folder resistance',\n",
       " 'vegetative vigor',\n",
       " 'days to flag leaf emergence',\n",
       " 'shoot system chromium content',\n",
       " 'root pulling force',\n",
       " 'plant embryo development trait',\n",
       " 'root development trait',\n",
       " 'growth media pH sensitivity',\n",
       " 'leaf lamina pubescence',\n",
       " 'aluminum content trait',\n",
       " 'shoot system sodium content',\n",
       " 'plant dry weight',\n",
       " 'selenium content',\n",
       " 'internode length',\n",
       " 'leaf phosphorus content',\n",
       " 'water absorption by seed',\n",
       " 'anther morphology trait',\n",
       " 'ligule morphology trait',\n",
       " 'tiller bud dormancy',\n",
       " 'leaf flexibility',\n",
       " 'carpel morphology trait',\n",
       " 'leaf blast disease resistance',\n",
       " 'bran percentage',\n",
       " 'nitrate uptake',\n",
       " 'albino plantlet differentiation frequency',\n",
       " 'panicle threshability',\n",
       " 'iron concentration',\n",
       " 'ligule length',\n",
       " 'beta-carotene content',\n",
       " 'shoot branching',\n",
       " 'grain core percent white',\n",
       " 'animal damage resistance',\n",
       " 'lead content trait',\n",
       " 'fruit shape',\n",
       " 'macronutrient sensitivity',\n",
       " 'molybdenum content',\n",
       " 'black streak dwarf virus resistance',\n",
       " 'seed length to width ratio',\n",
       " 'rubisco to soluble protein ratio',\n",
       " 'leaf lamina color',\n",
       " 'CW-cytoplasmic male sterility',\n",
       " 'pistil number',\n",
       " 'whole plant size',\n",
       " 'shoot fresh weight',\n",
       " 'spikelet rachilla hair type',\n",
       " 'stem elongation',\n",
       " 'non-mineral nutrient sensitivity',\n",
       " 'shoot system rubidium content',\n",
       " 'fungal blight disease resistance',\n",
       " 'stem rot disease resistance',\n",
       " 'collective plant structure morphology trait',\n",
       " 'plant width',\n",
       " 'organ identity',\n",
       " 'sugar content',\n",
       " 'barley yellow dwarf virus disease resistance',\n",
       " 'carpel number',\n",
       " 'manganese concentration',\n",
       " 'leaf weight',\n",
       " 'diterpenoid phytoalexin content',\n",
       " 'pollen sterility',\n",
       " 'leaf rolling tolerance',\n",
       " 'seed coat pattern',\n",
       " 'relative biomass',\n",
       " 'rice grassy stunt 1 and 2 virus resistance',\n",
       " 'exocarp texture',\n",
       " 'quantum yield',\n",
       " 'abscisic acid content',\n",
       " 'leaf rolling time',\n",
       " 'shoot axis morphology trait',\n",
       " 'relative chlorophyll content',\n",
       " 'phytochemical compound content',\n",
       " 'cell membrane stability',\n",
       " 'leaf sheath diameter',\n",
       " 'caruncle color',\n",
       " 'silicon sensitivity',\n",
       " 'dehulled grain weight',\n",
       " 'leaf lamina margin pubescence density',\n",
       " 'multi-tissue plant structure growth and development trait',\n",
       " 'seed coat hardness',\n",
       " 'giant embryo',\n",
       " 'false smut disease resistance',\n",
       " 'inflorescence bristle length',\n",
       " 'Meloidogyne javanica resistance',\n",
       " 'bacterial blight disease resistance',\n",
       " 'axillary bud prominence',\n",
       " 'leaf gloss',\n",
       " 'fruit weight',\n",
       " 'flooding related trait',\n",
       " 'plant trait',\n",
       " 'leaf length',\n",
       " 'zinc sensitivity',\n",
       " 'cold tolerance',\n",
       " 'rhizome dry weight',\n",
       " 'basal axillary branch number',\n",
       " 'flour particle size',\n",
       " 'panicle base to lowest branch',\n",
       " 'fruit crispness',\n",
       " 'filled grain percentage',\n",
       " 'culm color',\n",
       " 'multi-tissue plant structure morphology trait',\n",
       " 'primary shoot branch number',\n",
       " 'shoot system silicon content',\n",
       " 'leaf composition trait',\n",
       " 'tiller angle',\n",
       " 'arachnid damage resistance',\n",
       " 'perodidase-71 content',\n",
       " 'chemical stress sensitivity',\n",
       " 'in vitro plant structure morphology trait',\n",
       " 'large vascular bundle number',\n",
       " 'corolla color',\n",
       " 'inflorescence texture',\n",
       " 'endocarp color',\n",
       " 'fruit abscission zone size',\n",
       " 'anther number',\n",
       " 'stem senescence',\n",
       " '100-seed weight',\n",
       " 'germination ratio',\n",
       " 'photochemical quenching',\n",
       " 'chlorophyll content in an extract',\n",
       " 'floral organ morphology trait',\n",
       " 'diastatic power',\n",
       " 'seed yield trait',\n",
       " 'panicle axis angle',\n",
       " 'plant cell length',\n",
       " 'root cortical cell length',\n",
       " 'stearic acid content',\n",
       " 'chlorophyll ratio',\n",
       " 'acid phosphatase activity trait',\n",
       " 'ear infructescence position',\n",
       " 'salt tolerance',\n",
       " 'inflorescence bract color',\n",
       " 'root system copper content',\n",
       " 'lodicule length',\n",
       " 'vegetative growth time',\n",
       " 'inflorescence primary branch morphology trait',\n",
       " 'large vascular bundle number to spikelet number ratio',\n",
       " 'panicle density',\n",
       " 'inflorescenceless',\n",
       " 'non photochemical quenching',\n",
       " 'leaf sheath auricle pubescence',\n",
       " 'hydrogen sensitivity',\n",
       " 'perianth morphology trait',\n",
       " 'lodicule number',\n",
       " 'plant organ growth and development trait',\n",
       " 'grain yield per panicle',\n",
       " 'polished rice protein content',\n",
       " 'relative shoot dry weight',\n",
       " 'brassinosteroid sensitivity',\n",
       " 'total amylase activity trait',\n",
       " 'auxin content',\n",
       " 'endosperm storage protein content',\n",
       " 'spikelets per panicle length',\n",
       " 'width of grain with hull',\n",
       " 'cauline axillary branch number',\n",
       " 'lodicule type',\n",
       " 'grain yield trait',\n",
       " 'pseudostem diameter',\n",
       " 'embryo shape',\n",
       " 'female fertility restoration trait',\n",
       " 'number of metaxylem vessels',\n",
       " 'fruit yield trait',\n",
       " 'rice grassy stunt virus-1 resistance',\n",
       " 'deep root weight ratio',\n",
       " 'neck leaf presence',\n",
       " 'fertility related trait',\n",
       " 'unfilled grain number',\n",
       " 'petiole shape',\n",
       " 'whole plant morphology trait',\n",
       " 'root system lead content',\n",
       " 'kernel weight',\n",
       " 'drought susceptibility index',\n",
       " 'infructescence yield trait',\n",
       " 'stay green trait',\n",
       " 'bakanae disease resistance',\n",
       " 'starch grain synthesis',\n",
       " 'sepal size',\n",
       " 'shoot system lithium content',\n",
       " 'seed phosphorus content',\n",
       " 'root nodule weight',\n",
       " 'awn length',\n",
       " 'gibberellin biosynthesis trait',\n",
       " 'leaf cover',\n",
       " 'white-backed planthopper egg mortality',\n",
       " 'cool paste viscosity',\n",
       " 'arsenic content trait',\n",
       " 'glume pubescence length',\n",
       " 'exocarp thickness',\n",
       " '1000-dehulled grain weight',\n",
       " 'lodicule shape',\n",
       " 'tetraploid wheat fusarium head blight resistance',\n",
       " 'total water soluble content',\n",
       " 'basic vegetative phase',\n",
       " 'phosphorus uptake',\n",
       " 'rice delphacid resistance',\n",
       " 'turgor pressure',\n",
       " 'quantum yield at a given wavelength',\n",
       " 'root system cobalt content',\n",
       " 'leaf water potential',\n",
       " 'self-incompatibility',\n",
       " 'root dry weight to tiller number ratio',\n",
       " 'plant structure morphology trait',\n",
       " 'seed shape',\n",
       " 'corolla morphology trait',\n",
       " 'seed fertility',\n",
       " 'hot paste viscosity',\n",
       " 'biological process trait',\n",
       " 'secondary xylem volumetric density',\n",
       " 'polished grain length',\n",
       " 'gel consistency',\n",
       " 'exocarp color',\n",
       " 'metabolite content trait',\n",
       " 'shoot system aluminum content',\n",
       " 'shoot system iron content',\n",
       " 'deep root dry weight',\n",
       " 'pseudostem morphology trait',\n",
       " 'subterranean shoot axis tuber appearance',\n",
       " 'fruit proximal end shape',\n",
       " 'rooting depth',\n",
       " 'fructose content',\n",
       " '1000-polished grain weight',\n",
       " 'mesocarp color',\n",
       " 'inflorescence branch arrangement',\n",
       " 'flag leaf angle: early stage',\n",
       " 'senesced leaf number',\n",
       " 'leaf lamina area',\n",
       " 'root mass density 30-45',\n",
       " 'rice seedling blight disease resistance',\n",
       " 'polished grain weight',\n",
       " 'quantum yield determined by the light curve',\n",
       " 'respiration rate',\n",
       " 'male sterility type',\n",
       " 'biotic stress trait',\n",
       " 'fruit length',\n",
       " 'cercospora leaf spot resistance',\n",
       " 'aphid resistance',\n",
       " 'plant ovary color',\n",
       " 'UV light sensitivity',\n",
       " 'spikelet rachilla morphology trait',\n",
       " 'microsporophyll morphology trait',\n",
       " 'spikelet rachilla length',\n",
       " 'palea number',\n",
       " 'brown planthopper resistance',\n",
       " 'root system zinc content',\n",
       " 'aleurone layer appearance',\n",
       " 'leaf rolling',\n",
       " 'fruit flavor trait',\n",
       " 'potassium concentration',\n",
       " 'panicle blast disease resistance',\n",
       " 'milled rice yield',\n",
       " 'spikelet width',\n",
       " 'mineral and ion transport trait',\n",
       " 'grain yield per plant',\n",
       " 'flag leaf length',\n",
       " 'root color',\n",
       " 'homeotic development trait',\n",
       " 'rubisco to nitrogen content ratio',\n",
       " 'petal color',\n",
       " 'leaf margin morphology trait',\n",
       " 'acid detergent fiber',\n",
       " 'insect damage resistance',\n",
       " 'crushed grain percentage',\n",
       " 'involucre bristle length',\n",
       " 'male flowering',\n",
       " 'barley leaf rust disease resistance',\n",
       " 'anther color',\n",
       " 'boron content',\n",
       " 'stress trait',\n",
       " 'fruit number trait',\n",
       " 'brittle culm',\n",
       " 'f1-hybrid incompatibility',\n",
       " 'magnesium content',\n",
       " 'stem internode color',\n",
       " 'relative phosphorus distribution between shoot and root',\n",
       " 'cob diameter',\n",
       " 'flower bract morphology trait',\n",
       " 'stomatal conductance',\n",
       " 'starch concentration',\n",
       " 'leaf lamina margin pubescence',\n",
       " 'stomatal resistance',\n",
       " 'root system chromium content',\n",
       " 'wheat powdery mildew disease resistance',\n",
       " 'far red light sensitivity',\n",
       " 'stomatal closure rate',\n",
       " 'spikelet floret shape',\n",
       " 'shoot axis node color',\n",
       " 'fruit width',\n",
       " 'glufosinate sensitivity',\n",
       " 'pre-flowering flower abortion',\n",
       " 'carbohydrate composition related trait',\n",
       " 'days to tassel emergence',\n",
       " 'cob weight',\n",
       " 'floral organ identity',\n",
       " 'grain surface area',\n",
       " 'inflorescence branch color',\n",
       " 'inflorescence morphology trait',\n",
       " 'tertiary shoot branch number',\n",
       " 'inflorescence exsertion',\n",
       " 'rubisco content',\n",
       " 'copper sensitivity',\n",
       " 'flag leaf area',\n",
       " 'fruit color',\n",
       " 'basal internode diameter',\n",
       " 'root to total biomass ratio',\n",
       " 'petal width',\n",
       " 'residual beta-glucanase activity trait',\n",
       " 'trichome appressed',\n",
       " 'hull color',\n",
       " 'sepal length',\n",
       " 'ligule pubescence',\n",
       " 'chloroplast development trait',\n",
       " 'inflorescence depth',\n",
       " 'transpiration rate',\n",
       " 'pseudostem length',\n",
       " 'milled grain color',\n",
       " 'lemma number',\n",
       " 'penetrated root number',\n",
       " 'stink bug resistance',\n",
       " 'sucrose content',\n",
       " 'inflorescence waxiness',\n",
       " 'whole plant growth and development trait',\n",
       " 'leaf lamina lobe length',\n",
       " 'seedling hypocotyl color',\n",
       " 'leaf collar color',\n",
       " 'rice yellow mottle virus resistance',\n",
       " 'inflorescence branch morphology trait',\n",
       " 'leaf midrib color',\n",
       " 'relative phosphorus uptake',\n",
       " 'branch morphology trait',\n",
       " 'locular tissue trait',\n",
       " 'root system width',\n",
       " 'rice skipper resistance',\n",
       " 'rhizome morphology trait',\n",
       " 'cob width',\n",
       " 'pseudostem color',\n",
       " 'cytokinin content',\n",
       " 'axillary bud morphology trait',\n",
       " 'light quality sensitivity',\n",
       " 'primary macronutrient sensitivity',\n",
       " 'strontium content trait',\n",
       " 'micronutrient sensitivity',\n",
       " 'shootless embryo',\n",
       " 'megasporocyte number',\n",
       " 'awn thickness',\n",
       " 'petal morphology trait',\n",
       " 'glume width',\n",
       " 'nitrogen content',\n",
       " 'leaf dry weight',\n",
       " 'plant height uniformity',\n",
       " 'spike exsertion',\n",
       " 'inflorescence shape',\n",
       " 'plant structure growth and development trait',\n",
       " 'gelatinization temperature',\n",
       " 'hilum color',\n",
       " 'plant aspect',\n",
       " 'stem length',\n",
       " 'seed thickness',\n",
       " 'crown rootless',\n",
       " 'stem hairiness',\n",
       " 'spikelet floret morphology trait',\n",
       " 'inflorescence density',\n",
       " 'seedling vigor',\n",
       " 'leaf perimeter',\n",
       " 'grain length',\n",
       " 'kernel number per ear',\n",
       " 'submergence sensitivity',\n",
       " 'barley wort color',\n",
       " 'anther shape',\n",
       " 'tassel branch dry weight',\n",
       " 'leaf number',\n",
       " 'flower length',\n",
       " 'brown rice length to width ratio',\n",
       " 'fruit set trait',\n",
       " 'adventitious rootless',\n",
       " 'root system aluminum content',\n",
       " 'meristem identity',\n",
       " 'abscisic acid concentration',\n",
       " 'root phototropism',\n",
       " 'filled grain number',\n",
       " 'epicormic shoot system morphology trait',\n",
       " 'rice tungro virus resistance',\n",
       " 'net photosynthetic rate',\n",
       " 'male sterility',\n",
       " 'root epidermis cell length',\n",
       " 'leaf yellowing tolerance',\n",
       " 'infructescence position',\n",
       " 'peduncle width',\n",
       " 'shoot elongation rate',\n",
       " 'leaf lamina pubscence length',\n",
       " 'awn presence',\n",
       " 'pistil length',\n",
       " 'blast disease resistance',\n",
       " 'root system phosphorus content',\n",
       " 'variegated leaf necrosis',\n",
       " 'beta-amylase activity trait',\n",
       " 'gibberellic acid sensitivity',\n",
       " 'juiciness',\n",
       " 'brown spot disease resistance',\n",
       " 'leaf volume',\n",
       " 'root quality trait',\n",
       " 'coleoptile length',\n",
       " 'stem number',\n",
       " 'cucurbit downy mildew resistance',\n",
       " 'fruit surface area',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_folder = \"/home/vlead/USE\"\n",
    "alignment_folder = \"../BioDiversity/Alignments/\"\n",
    "\n",
    "# Load reference alignments \n",
    "def load_alignments(folder):\n",
    "    alignments = []\n",
    "    for f in os.listdir(folder):\n",
    "        doc = minidom.parse(folder + f)\n",
    "        ls = list(zip(doc.getElementsByTagName('entity1'), doc.getElementsByTagName('entity2')))\n",
    "        alignments.extend([(a.getAttribute('rdf:resource'), b.getAttribute('rdf:resource')) for (a,b) in ls])\n",
    "    return alignments\n",
    "\n",
    "# Extracting USE embeddings\n",
    "\n",
    "def extractUSEEmbeddings(words):\n",
    "    try:\n",
    "        embed = hub.KerasLayer(USE_folder)\n",
    "    except Exception as e:\n",
    "        !mkdir $USE_folder\n",
    "        !curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\" | tar -zxvC $USE_folder\n",
    "        embed = hub.KerasLayer(USE_folder)\n",
    "        pass\n",
    "    word_embeddings = embed(words)\n",
    "    return word_embeddings.numpy()\n",
    "\n",
    "# model = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "# def extractUSEEmbeddings(words):\n",
    "#     return model.encode(words)\n",
    "\n",
    "# cos_sim(*model.encode([\"My brother plays guitar\", \"The sun is shining\"]))\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "\n",
    "# reference_alignments = load_alignments(alignment_folder)\n",
    "reference_alignments = []\n",
    "doc = minidom.parse(alignment_folder + \"flopo-pto.rdf\")\n",
    "ls = list(zip(doc.getElementsByTagName('entity1'), doc.getElementsByTagName('entity2')))\n",
    "reference_alignments.extend([(a.getAttribute('rdf:resource'), b.getAttribute('rdf:resource')) for (a,b) in ls])\n",
    "\n",
    "ontologies_in_alignment = [[\"../BioDiversity/Ontologies/flopo.owl\", \"../BioDiversity/Ontologies/pto.owl\"]]\n",
    "# ra_anatomy_coded = load_alignments(\"../Anatomy/Alignments/\")\n",
    "# ra_anatomy = []\n",
    "# ont1 = Ontology(\"../Anatomy/Ontologies/mouse.owl\")\n",
    "# ont2 = Ontology(\"../Anatomy/Ontologies/human.owl\")\n",
    "# for elem in ra_anatomy_coded:\n",
    "#     pre1, pre2 = elem[0].split(\"#\")[0].split(\".\")[0].split(\"/\")[-1], elem[1].split(\"#\")[0].split(\".\")[0].split(\"/\")[-1]\n",
    "#     elem1, elem2 = elem[0].split(\"#\")[-1], elem[1].split(\"#\")[-1]\n",
    "#     ra_anatomy.append(( pre1 + \"#\" + ont1.mapping_dict[elem1], pre2 + \"#\" + ont2.mapping_dict[elem2]))\n",
    "# ontologies_in_alignment = [[\"../Anatomy/Ontologies/mouse.owl\", \"../Anatomy/Ontologies/human.owl\"]]\n",
    "\n",
    "gt_mappings = []\n",
    "\n",
    "for (ont1_name, ont2_name) in ontologies_in_alignment:\n",
    "    ont1 = Ontology(ont1_name)\n",
    "    ont2 = Ontology(ont2_name)\n",
    "    for elem in reference_alignments:\n",
    "        pre1, pre2 = ont1_name.split(\"#\")[0].split(\"/\")[-1].split(\".\")[0], ont2_name.split(\"#\")[0].split(\"/\")[-1].split(\".\")[0]\n",
    "        elem1, elem2 = elem[0].split(\"#\")[-1], elem[1].split(\"#\")[-1]\n",
    "        gt_mappings.append(( pre1 + \"#\" + ont1.mapping_dict[elem1], pre2 + \"#\" + ont2.mapping_dict[elem2]))\n",
    "\n",
    "\n",
    "# gt_mappings = [tuple([elem.split(\"/\")[-1] for elem in el]) for el in reference_alignments]\n",
    "# gt_mappings.extend(ra_anatomy)\n",
    "\n",
    "\n",
    "# ontologies_in_alignment = pickle.load(open(\"../data_generic.pkl\", \"rb\"))[-1][:-1]\n",
    "# ontologies_in_alignment += [[\"../Anatomy/Ontologies/human.owl\", \"../Anatomy/Ontologies/mouse.owl\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el for el in Ontology(\"../BioDiversity/Ontologies/pto.owl\").mapping_dict if el.startswith(\"http://purl.obolibrary.org/obo/BFO_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinatorial mapping generation\n",
    "all_mappings = []\n",
    "for l in ontologies_in_alignment:\n",
    "    ont1 = Ontology(l[0])\n",
    "    ont2 = Ontology(l[1])\n",
    "    \n",
    "    ent1 = ont1.get_entities()\n",
    "    ent2 = ont2.get_entities()\n",
    "    \n",
    "    mappings = list(itertools.product(ent1, ent2))\n",
    "\n",
    "    \n",
    "    all_mappings.extend([(l[0] + \"#\" + el[0], l[1] + \"#\" + el[1]) for el in mappings])\n",
    "    \n",
    "\n",
    "data = {mapping: False for mapping in all_mappings}\n",
    "for mapping in set(gt_mappings):\n",
    "    data[mapping] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left ('Chair_PC', 'Program_Chair') PC Program_Chair\n",
      "left ('Chair_PC', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('Chair_PC', 'Program_Committee') PC Program_Committee\n",
      "left ('Member_PC', 'Program_Chair') PC Program_Chair\n",
      "left ('Member_PC', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('Member_PC', 'Program_Committee') PC Program_Committee\n",
      "left ('Chair_PC', 'Presenter_city') PC Presenter_city\n",
      "left ('Member_PC', 'Presenter_city') PC Presenter_city\n",
      "left ('PC_Chair', 'Program_Chair') PC Program_Chair\n",
      "left ('PC_Chair', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('PC_Chair', 'Program_Committee') PC Program_Committee\n",
      "left ('OC_Chair', 'Organizing_Committee_member') OCM Organizing_Committee\n",
      "left ('OC_Chair', 'Organizing_Committee') OC Organizing_Committee\n",
      "left ('PC_Member', 'Program_Chair') PC Program_Chair\n",
      "left ('PC_Member', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('PC_Member', 'Program_Committee') PC Program_Committee\n",
      "left ('OC_Member', 'Organizing_Committee_member') OCM Organizing_Committee\n",
      "left ('OC_Member', 'Organizing_Committee') OC Organizing_Committee\n",
      "right ('Program_committee', 'Chair_PC') PC Program_committee\n",
      "right ('Program_committee', 'Member_PC') PC Program_committee\n",
      "right ('Passive_conference_participant', 'Chair_PC') PCP Passive_conference\n",
      "right ('Passive_conference_participant', 'Member_PC') PCP Passive_conference\n",
      "left ('PC_Chair', 'Presenter_city') PC Presenter_city\n",
      "left ('OC_Chair', 'One_conference_day') OCD One_conference\n",
      "left ('PC_Member', 'Presenter_city') PC Presenter_city\n",
      "left ('SC_Member', 'Session_chair') SC Session_chair\n",
      "left ('SC_Member', 'Sponsor_city') SC Sponsor_city\n",
      "left ('SC_Member', 'Brief_introduction_for_Session_chair') BIFSC Session_chair\n",
      "left ('SC_Member', 'Sponsor_company_house') SCH Sponsor_company\n",
      "left ('OC_Member', 'One_conference_day') OCD One_conference\n",
      "left ('Chair_PC', 'PC_Chair') PC PC_Chair\n",
      "left ('Member_PC', 'PC_Chair') PC PC_Chair\n",
      "right ('Program_committee', 'PC_Chair') PC Program_committee\n",
      "right ('Program_committee', 'PC_Member') PC Program_committee\n",
      "right ('Passive_conference_participant', 'PC_Chair') PCP Passive_conference\n",
      "right ('Passive_conference_participant', 'PC_Member') PCP Passive_conference\n",
      "right ('Submitted_contribution', 'SC_Member') SC Submitted_contribution\n",
      "right ('Organizing_committee', 'OC_Chair') OC Organizing_committee\n",
      "right ('Organizing_committee', 'OC_Member') OC Organizing_committee\n",
      "right ('Steering_committee', 'SC_Member') SC Steering_committee\n",
      "left ('paperID', 'is_dated_on') IDO is_dated\n"
     ]
    }
   ],
   "source": [
    "# Abbrevation resolution preprocessing\n",
    "\n",
    "abbreviations_dict = {}\n",
    "final_dict = {}\n",
    "\n",
    "for mapping in all_mappings:\n",
    "    mapping = tuple([el.split(\"#\")[1] for el in mapping])\n",
    "    is_abb = re.search(\"[A-Z][A-Z]+\", mapping[0])\n",
    "    if is_abb:\n",
    "        abbreviation = \"\".join([el[0].upper() for el in mapping[1].split(\"_\")])\n",
    "        if is_abb.group() in abbreviation:\n",
    "            \n",
    "            start = abbreviation.find(is_abb.group())\n",
    "            end = start + len(is_abb.group())\n",
    "            fullform = \"_\".join(mapping[1].split(\"_\")[start:end])\n",
    "            print (\"left\", mapping, abbreviation, fullform)\n",
    "            \n",
    "            rest_first = \" \".join([el for el in mapping[0].replace(is_abb.group(), \"\").split(\"_\") if el]).lower()\n",
    "            rest_second = \" \".join(mapping[1].split(\"_\")[:start] + mapping[1].split(\"_\")[end:])\n",
    "            if is_abb.group() not in final_dict:\n",
    "                final_dict[is_abb.group()] = [(fullform, rest_first, rest_second)]\n",
    "            else:\n",
    "                final_dict[is_abb.group()].append((fullform, rest_first, rest_second))\n",
    "\n",
    "    is_abb = re.search(\"[A-Z][A-Z]+\", mapping[1])\n",
    "    if is_abb:\n",
    "        abbreviation = \"\".join([el[0].upper() for el in mapping[0].split(\"_\")])\n",
    "        \n",
    "        if is_abb.group() in abbreviation:\n",
    "            start = abbreviation.find(is_abb.group())\n",
    "            end = start + len(is_abb.group())\n",
    "            fullform = \"_\".join(mapping[0].split(\"_\")[start:end])\n",
    "            print (\"right\", mapping, abbreviation, fullform)\n",
    "\n",
    "            rest_first = \" \".join([el for el in mapping[1].replace(is_abb.group(), \"\").split(\"_\") if el]).lower()\n",
    "            rest_second = \" \".join(mapping[0].split(\"_\")[:start] + mapping[0].split(\"_\")[end:])\n",
    "            if is_abb.group() not in final_dict:\n",
    "                final_dict[is_abb.group()] = [(fullform, rest_first, rest_second)]\n",
    "            else:\n",
    "                final_dict[is_abb.group()].append((fullform, rest_first, rest_second))\n",
    "\n",
    "keys = [el for el in list(set(flatten([flatten([tup[1:] for tup in final_dict[key]]) for key in final_dict]))) if el]\n",
    "abb_embeds = dict(zip(keys, extractUSEEmbeddings(keys)))\n",
    "\n",
    "scored_dict = {}\n",
    "for abbr in final_dict:\n",
    "    sim_list = [(tup[0], tup[1], tup[2], cos_sim(abb_embeds[tup[1]], abb_embeds[tup[2]])) if tup[1] and tup[2]\n",
    "                else (tup[0], tup[1], tup[2], 0) for tup in final_dict[abbr]]\n",
    "    scored_dict[abbr] = sorted(list(set(sim_list)), key=lambda x:x[-1], reverse=True)\n",
    "\n",
    "resolved_dict = {key: scored_dict[key][0] for key in scored_dict}\n",
    "filtered_dict = {key: \" \".join(resolved_dict[key][0].split(\"_\")) for key in resolved_dict if resolved_dict[key][-1] > 0.9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error list index out of range\n",
      "registration SIGMOD member registration SIGMOD member\n",
      "flyer flayer\n",
      "is a topis of conference parts is a tops of conference parts\n",
      "powerline transmission topic power line transmission topic\n",
      "presentationed by presentation ed by\n",
      "any URI any URI\n",
      "accpet if room rating accept if room rating\n",
      "contribution 1th-author contribution th-author\n",
      "technically organises technically organists\n",
      "organises organists\n",
      "logo URL logo URL\n",
      "is writen by is write by\n",
      "organised by organized by\n",
      "programme brochure programmer brochure\n",
      "paper ID paper ID\n",
      "registation deadline registration deadline\n",
      "holded by holed by\n",
      "author cd proceedings included author cd proceedings included\n",
      "sponzor sponsor\n",
      "IASTED member IASTED member\n",
      "LCD projector LCD projector\n",
      "conference www conference www\n",
      "TProgram committee member TProgram committee member\n",
      "scientifically organises scientifically organists\n",
      "registeered applicant registered applicant\n",
      "technically organised by technically organized by\n",
      "IASTED non member IASTED non member\n",
      "webmaster web master\n",
      "has an ISBN has an ISBN\n",
      "site URL site URL\n",
      "CAD topic CAD topic\n",
      "memeber registration fee member registration fee\n",
      "NGO NGO\n",
      "technic activity technical activity\n",
      "scientifically organised by scientifically organized by\n",
      "viza viz\n",
      "has a URL has a URL\n",
      "registration SIGKDD member registration SIGKDD member\n",
      "print hardcopy mailing manifests print hard copy mailing manifests\n",
      "nonauthor registration fee non author registration fee\n",
      "initial manuscipt initial manuscript\n",
      "organizator organization\n",
      "sponzor fee sponsor fee\n",
      "has a commtitee has a committee\n",
      "sponzorship sponsorship\n",
      "author attendee cd registration fee author attendee cd registration fee\n",
      "cd proceening cd proceeding\n",
      "organisation organization\n",
      "has programme has programmer\n",
      "SC member SC member\n",
      "accepts hardcopy submissions accepts hard copy submissions\n",
      "computer networks aapplications topic computer networks applications topic\n",
      "technical commitee technical committee\n",
      "operating topicsystems operating topic systems\n",
      "cheque exchequer\n",
      "is the 1th part of is the th part of\n",
      "ACM SIGKDD ACM SIGKDD\n",
      "coctail reception cocktail reception\n",
      "has VAT has VAT\n",
      "programme programmer\n",
      "was a committe co-chair of was a committee co-chair of\n",
      "reviewes reviewed\n",
      "modelling modeling\n",
      "organising agency organizing agency\n",
      "hardcopy mailing manifests printed by hard copy mailing manifests printed by\n",
      "Total number of extracted unique classes and properties from entire RA set:  829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def camel_case_split(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]\n",
    "\n",
    "def parse(word):\n",
    "    return flatten([el.split(\"_\") for el in camel_case_split(word)])\n",
    "    \n",
    "\n",
    "extracted_elems = []\n",
    "\n",
    "for ont_name in list(set(flatten(ontologies_in_alignment))):\n",
    "    ont = Ontology(\"conference_ontologies/\" + ont_name + \".owl\")\n",
    "    entities = ont.get_entities()\n",
    "    props = ont.get_object_properties() + ont.get_data_properties()\n",
    "    triples = list(set(flatten(ont.get_triples())))\n",
    "    extracted_elems.extend([ont_name + \"#\" + elem for elem in entities + props + triples])\n",
    "\n",
    "extracted_elems = list(set(extracted_elems))\n",
    "inp = [\" \".join(parse(word.split(\"#\")[1])) for word in extracted_elems]\n",
    "\n",
    "# Resolving abbreviations to full forms\n",
    "inp_resolved = []\n",
    "for concept in inp:\n",
    "    for key in filtered_dict:\n",
    "        concept = concept.replace(key, filtered_dict[key])\n",
    "    final_list = []\n",
    "    # Lowering case except in abbreviations\n",
    "    for word in concept.split(\" \"):\n",
    "        if not re.search(\"[A-Z][A-Z]+\", word):\n",
    "            final_list.append(word.lower())\n",
    "        else:\n",
    "            final_list.append(word)\n",
    "    concept = \" \".join(final_list)\n",
    "    inp_resolved.append(concept)\n",
    "\n",
    "\n",
    "url = \"https://montanaflynn-spellcheck.p.rapidapi.com/check/\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"montanaflynn-spellcheck.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"9965b01207msh06291e57d6f2c55p1a6a16jsn0fb016da4a62\"\n",
    "    }\n",
    "\n",
    "inp_spellchecked = []\n",
    "for concept in inp_resolved:\n",
    "    querystring = {\"text\": concept}\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "    if response[\"suggestion\"] != concept:\n",
    "        resolved = str(concept)\n",
    "        final_list = []\n",
    "        for word in concept.split(\" \"):\n",
    "            if not re.search(\"[A-Z][A-Z]+\", concept):\n",
    "                final_list.append(word.lower())\n",
    "            else:\n",
    "                final_list.append(word)\n",
    "        resolved = \" \".join(final_list)\n",
    "#         print (resolved, \"suggestion\", response)\n",
    "        for word in response[\"corrections\"]:\n",
    "            if not re.search(\"[A-Z][A-Z]+\", concept):\n",
    "                resolved = resolved.replace(word.lower(), response[\"corrections\"][word][0].lower())\n",
    "                \n",
    "        \n",
    "        print (concept, resolved)\n",
    "        inp_spellchecked.append(resolved)\n",
    "    else:\n",
    "        inp_spellchecked.append(concept)\n",
    "\n",
    "print (\"Total number of extracted unique classes and properties from entire RA set: \", len(extracted_elems))\n",
    "\n",
    "extracted_elems = [\"<UNK>\"] + extracted_elems\n",
    "\n",
    "# stopwords = [\"has\", \"is\", \"a\", \"an\", \"the\"]\n",
    "stopwords = [\"has\"]\n",
    "inp_stemmed = []\n",
    "for elem in inp_spellchecked:\n",
    "    words = \" \".join([word for word in elem.split() if word not in stopwords])\n",
    "    words = words.replace(\"-\", \" \")\n",
    "    inp_stemmed.append(words)\n",
    "\n",
    "\n",
    "embeds = np.array(extractUSEEmbeddings(inp_stemmed))\n",
    "embeds = np.array([np.zeros(embeds.shape[1],)] + list(embeds))\n",
    "# embeds = np.array([np.zeros(512,)] + list(extractUSEEmbeddings(inp_spellchecked)))\n",
    "embeddings = dict(zip(extracted_elems, embeds))\n",
    "\n",
    "\n",
    "emb_vals = list(embeddings.values())\n",
    "emb_indexer = {key: i for i, key in enumerate(list(embeddings.keys()))}\n",
    "emb_indexer_inv = {i: key for i, key in enumerate(list(embeddings.keys()))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Anatomy/Ontologies/mouse.owl\n",
      "../Anatomy/Ontologies/human.owl\n"
     ]
    }
   ],
   "source": [
    "def path_to_root(elem, ont_mappings):\n",
    "    if elem not in ont_mappings or not ont_mappings[elem]:\n",
    "        return []\n",
    "    output = flatten([[e] + path_to_root(e, ont_mappings) for e in ont_mappings[elem]])\n",
    "    return output\n",
    "\n",
    "def get_one_hop_neighbours(ont, K=1):\n",
    "    ont_obj = Ontology(ont)\n",
    "    triples = ont_obj.get_triples()\n",
    "    entities = [(a,b) for (a,b,c) in triples]\n",
    "    neighbours_dict = {elem: [elem] for elem in list(set(flatten(entities)))}\n",
    "    for e1, e2 in entities:\n",
    "        neighbours_dict[e1].append(e2)\n",
    "        neighbours_dict[e2].append(e1)\n",
    "    \n",
    "    rootpath_dict = ont_obj.parents_dict\n",
    "    rootpath_dict = {elem: path_to_root(elem, rootpath_dict) for elem in rootpath_dict}\n",
    "    print (ont)\n",
    "    ont = ont.split(\"/\")[-1].split(\".\")[0]\n",
    "    \n",
    "    for entity in neighbours_dict:\n",
    "        if entity in rootpath_dict and len(rootpath_dict[entity]) > 0:\n",
    "            neighbours_dict[entity].extend(rootpath_dict[entity])\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "#     prop_triples = ont_obj.get_triples(subclass_of=False)\n",
    "#     neighbours_dict_props = {c: [c] for a,b,c in prop_triples}\n",
    "#     for e1, e2, p in prop_triples:\n",
    "#         neighbours_dict_props[p].extend([e1, e2])\n",
    "\n",
    "    #neighbours_dict = {**neighbours_dict, **neighbours_dict_props}\n",
    "    \n",
    "    # for elem in ont_obj.get_entities() + ont_obj.get_object_properties() + ont_obj.get_data_properties():\n",
    "    #     if elem not in neighbours_dict:\n",
    "    #         neighbours_dict[elem] = [elem]\n",
    "\n",
    "    neighbours_dict = {el: neighbours_dict[el][:1] + sorted(list(set(neighbours_dict[el][1:])))\n",
    "                       for el in neighbours_dict}\n",
    "#     neighbours_dict = {el: neighbours_dict[el][:23] for el in neighbours_dict if len( neighbours_dict[el]) > 2}\n",
    "#     ont = ont.split(\"/\")[-1].split(\".\")[0]\n",
    "    neighbours_dict = {ont + \"#\" + el: [ont + \"#\" + e for e in neighbours_dict[el]] for el in neighbours_dict}\n",
    "    return neighbours_dict\n",
    "\n",
    "neighbours_dicts = {ont.split(\"/\")[-1].split(\".\")[0]: get_one_hop_neighbours(ont) for ont in list(set(flatten(ontologies_in_alignment)))}\n",
    "max_neighbours = np.max(flatten([[len(el[e]) for e in el] for el in neighbours_dicts.values()]))\n",
    "# neighbours_lens = {ont: {key: len(neighbours_dicts[ont][key]) for key in neighbours_dicts[ont]}\n",
    "#                    for ont in neighbours_dicts}\n",
    "# neighbours_dicts = {ont: {key: neighbours_dicts[ont][key] + [\"<UNK>\" for i in range(max_neighbours -len(neighbours_dicts[ont][key]))]\n",
    "#               for key in neighbours_dicts[ont]} for ont in neighbours_dicts}\n",
    "\n",
    "# # ontologies_in_alignment = [[el.split(\"/\")[1].split(\".\")[0] for el in ont] for ont in ontologies_in_alignment]\n",
    "# f = open(\"data_bert.pkl\", \"wb\")\n",
    "# pickle.dump([data, emb_indexer, emb_indexer_inv, emb_vals, gt_mappings, neighbours_dicts, ontologies_in_alignment], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['flopo#flora phenotype'], []]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[e for e in el if len(el[e])==258] for el in neighbours_dicts.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122893"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pickle.load(open(\"data_rootpath.pkl\", \"rb\"))[0]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontologies_in_alignment = [[\"/data/Vivek/IBM/BioDiversity/Ontologies/flopo.owl\",\"/data/Vivek/IBM/BioDiversity/Ontologies/pto.owl\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Loading source ontology\\nhttp://purl.obolibrary.org/obo/flopo.owl loaded in 7 seconds\\nClasses: 29017\\nIndividuals: 0\\nProperties: 141\\nLoading target ontology\\n/data/Vivek/IBM/BioDiversity/Ontologies/pto.owl loaded in 0 seconds\\nClasses: 1504\\nIndividuals: 0\\nProperties: 1\\nDirect Relationships: 7512\\nRunning transitive closure on RelationshipMap\\nTransitive closure finished in 0 seconds\\nExtended Relationships: 67285\\nDisjoints: 372\\nReading config.ini file\\nFinished!\\nRunning Direct Cross-Reference Matcher\\nFinished in 0 seconds\\nRunning Lexical Matcher\\nFinished in 0 seconds\\nLoading mediating ontology uberon.owl\\nhttp://purl.obolibrary.org/obo/uberon.owl loaded in 3 seconds\\nRunning Mediating Cross-Reference Matcher using http://purl.obolibrary.org/obo/uberon.owl\\nFinished in 0 seconds\\nuberon.owl discarded\\nLoading mediating ontology doid.owl\\nhttp://purl.obolibrary.org/obo/doid.owl loaded in 2 seconds\\nRunning Mediating Cross-Reference Matcher using http://purl.obolibrary.org/obo/doid.owl\\nFinished in 0 seconds\\ndoid.owl discarded\\nBuilding Word Lexicons\\nRunning Word Matcher\\nBlocks to match: 3x1\\n.\\n.\\n.\\nFinished in 1 seconds\\nExtending Alignment with String Matcher\\nMatching Children & Parents\\nMatching Siblings\\nFinished in 1 seconds\\nRunning Spaceless Lexical Matcher\\nFinished in 0 seconds\\nRunning Thesaurus Matcher\\nFinished in 9 seconds\\nPerforming Selection\\nFinished in 0 seconds\\nBuilding Repair Map\\nComputed check list in 1 seconds\\nCore fragments: 1165 classes\\nCheck list: 553 classes to check\\nComputed ancestral paths in 3 seconds\\nPaths to process: 3768\\nComputed minimal conflict sets in 0 seconds\\nSets of conflicting mappings: 6\\nRepair Map finished in 4 seconds\\nRepairing Alignment\\nFinished Repair in 0 seconds\\nRemoved 1 mappings\\n' None\n",
      "['flopo-pto.rdf']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('PATO_0001334', 'TO_0000802')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5ed3600ee16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpred_aml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_alignments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AML-test-results2/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpred_aml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_mappings\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_aml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_onto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-5ed3600ee16e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpred_aml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_alignments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AML-test-results2/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpred_aml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_mappings\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_aml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_onto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_aml\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('PATO_0001334', 'TO_0000802')"
     ]
    }
   ],
   "source": [
    "# AML test\n",
    "def is_test(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) in test_onto\n",
    "\n",
    "results = []\n",
    "# all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "ontologies_in_alignment = [tuple(pair) for pair in ontologies_in_alignment]\n",
    "for i in list(range(0, len(ontologies_in_alignment), 3)):\n",
    "    test_onto = ontologies_in_alignment[i:i+3]\n",
    "    for ont_pair in test_onto:\n",
    "        a, b, c = ont_pair[0], ont_pair[1], ont_pair[0].split(\"/\")[-1].split(\".\")[0] + \"-\" + ont_pair[1].split(\"/\")[-1].split(\".\")[0]\n",
    "        java_command = \"java -jar AML_v3.1/AgreementMakerLight.jar -s \" + a + \" -t \" + b + \" -o AML-test-results2/\" + c + \".rdf -a\"\n",
    "        process = subprocess.Popen(java_command.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "        print (output, error)\n",
    "    print (os.listdir(\"AML-test-results2/\"))\n",
    "    pred_aml = load_alignments(\"AML-test-results2/\")\n",
    "    pred_aml = [tuple([el.split(\"/\")[-1] for el in key]) for key in pred_aml]\n",
    "    tp = len([elem for elem in pred_aml if data[elem]])\n",
    "    fn = len([key for key in gt_mappings if key not in set(pred_aml) and is_test(test_onto, key)])\n",
    "    fp = len([elem for elem in pred_aml if not data[elem]])\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1score = 2 * precision * recall / (precision + recall)\n",
    "    f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "    print (precision, recall, f1score, f2score, f0_5score)\n",
    "    \n",
    "    metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "    results.append(metrics)\n",
    "    \n",
    "    _ = [os.remove(f) for f in glob.glob('AML-test-results2/*')]\n",
    "    \n",
    "print (\"Final Results:\", np.mean(results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.5454545454545454 0.631578947368421 0.5769230769230769 0.6976744186046512\n",
      "1.0 0.9166666666666666 0.9565217391304348 0.9322033898305083 0.9821428571428572\n",
      "0.7857142857142857 0.7333333333333333 0.7586206896551724 0.7432432432432431 0.7746478873239436\n",
      "0.875 0.3684210526315789 0.5185185185185185 0.41666666666666663 0.6862745098039215\n",
      "0.7 0.7 0.7 0.7 0.7\n",
      "0.8333333333333334 0.3125 0.45454545454545453 0.35714285714285715 0.625\n",
      "0.8 1.0 0.888888888888889 0.9523809523809523 0.8333333333333334\n",
      "Final Results: [0.82057823 0.65376794 0.70123918 0.66836574 0.75701043]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LogMap test\n",
    "def is_test(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) in test_onto\n",
    "\n",
    "results = []\n",
    "prefix = \"/data/Vivek/IBM/IBM-Internship/conference_ontologies/\"\n",
    "for i in list(range(0, len(ontologies_in_alignment), 3)):\n",
    "    test_onto = ontologies_in_alignment[i+2:i+3]\n",
    "    tp_tot, fn_tot, fp_tot = [], [], []\n",
    "    for ont_pair in test_onto:\n",
    "        a, b, c = prefix + ont_pair[0], prefix + ont_pair[1], ont_pair[0] + \"-\" + ont_pair[1]\n",
    "        !mkdir $c\n",
    "        java_command = \"java -jar logmap-matcher/target/logmap-matcher-4.0.jar MATCHER file:\" +  a + \".owl file:\" + b + \".owl \" + \\\n",
    "                        \"/data/Vivek/IBM/IBM-Internship/\" + c + \"/ false\"\n",
    "        process = subprocess.Popen(java_command.split(), stdout=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "        \n",
    "        pred_aml = [l.strip().split(\"\\t\")[:2] for l in open(c + \"/logmap2_mappings.tsv\", \"r\").read().split(\"\\n\")[:-1]]\n",
    "        pred_aml = [tuple([el.split(\"/\")[-1] for el in key]) for key in pred_aml]\n",
    "        tp = [elem for elem in pred_aml if data[elem]]\n",
    "        fn = [key for key in gt_mappings if key not in set(pred_aml) and is_test([tuple(ont_pair)], key)]\n",
    "        fp = [elem for elem in pred_aml if not data[elem]]\n",
    "        \n",
    "        tp_tot.extend(tp)\n",
    "        fn_tot.extend(fn)\n",
    "        fp_tot.extend(fp)\n",
    "        \n",
    "        !rm -rf $c\n",
    "   \n",
    "    precision = len(tp_tot)/(len(tp_tot)+len(fp_tot))\n",
    "    recall = len(tp_tot)/(len(tp_tot)+len(fn_tot))\n",
    "    f1score = 2 * precision * recall / (precision + recall)\n",
    "    f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "    print (precision, recall, f1score, f2score, f0_5score)\n",
    "    \n",
    "    metrics = [precision, recall, f1score, f2score, f0_5score]\n",
    "    results.append(metrics)\n",
    "    \n",
    "    \n",
    "    \n",
    "print (\"Final Results:\", np.mean(results, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ontologies_in_alignment = pickle.load(open(\"data_multi_rootpath.pkl\", \"rb\"))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best thresholds: [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print (\"Best thresholds: {}\".format([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 1240)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_non_unk(elem):\n",
    "    return len([l for l in elem if l!=\"<UNK>\"])\n",
    "neighbours_dicts = {ont: {el: neighbours_dicts[ont][el][:int(sys.argv[1])] for el in neighbours_dicts[ont]\n",
    "       if count_non_unk(neighbours_dicts[ont][el]) > int(sys.argv[2])} for ont in neighbours_dicts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['confOf', 'sigkdd'],\n",
       " ['iasted', 'sigkdd'],\n",
       " ['cmt', 'ekaw'],\n",
       " ['confOf', 'iasted'],\n",
       " ['conference', 'edas'],\n",
       " ['cmt', 'sigkdd'],\n",
       " ['ekaw', 'sigkdd'],\n",
       " ['conference', 'confOf'],\n",
       " ['conference', 'sigkdd'],\n",
       " ['confOf', 'edas'],\n",
       " ['cmt', 'conference'],\n",
       " ['edas', 'iasted'],\n",
       " ['conference', 'iasted'],\n",
       " ['edas', 'sigkdd'],\n",
       " ['ekaw', 'iasted'],\n",
       " ['cmt', 'edas'],\n",
       " ['edas', 'ekaw'],\n",
       " ['cmt', 'confOf'],\n",
       " ['confOf', 'ekaw'],\n",
       " ['conference', 'ekaw'],\n",
       " ['cmt', 'iasted']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontologies_in_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conference', 'iasted'),\n",
       " ('ekaw', 'sigkdd'),\n",
       " ('cmt', 'sigkdd'),\n",
       " ('edas', 'ekaw'),\n",
       " ('conference', 'sigkdd'),\n",
       " ('iasted', 'sigkdd'),\n",
       " ('confOf', 'sigkdd'),\n",
       " ('ekaw', 'iasted'),\n",
       " ('conference', 'ekaw'),\n",
       " ('cmt', 'ekaw'),\n",
       " ('edas', 'sigkdd'),\n",
       " ('confOf', 'iasted'),\n",
       " ('cmt', 'conference'),\n",
       " ('cmt', 'confOf'),\n",
       " ('cmt', 'iasted'),\n",
       " ('conference', 'edas'),\n",
       " ('confOf', 'edas'),\n",
       " ('edas', 'iasted'),\n",
       " ('confOf', 'ekaw'),\n",
       " ('conference', 'confOf'),\n",
       " ('cmt', 'edas')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registeered applicant registered applicant\n",
      "technically organised by technically organized by\n",
      "ngo no\n",
      "sponzorship sponsorship\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://montanaflynn-spellcheck.p.rapidapi.com/check/\"\n",
    "\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"montanaflynn-spellcheck.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"9965b01207msh06291e57d6f2c55p1a6a16jsn0fb016da4a62\"\n",
    "    }\n",
    "\n",
    "# inp_spellchecked = []\n",
    "for concept in inp[731:]:\n",
    "    querystring = {\"text\": concept}\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=querystring).json()\n",
    "    if response[\"suggestion\"] != concept:\n",
    "        resolved = str(concept)\n",
    "        for word in response[\"corrections\"]:\n",
    "            if not re.search(\"[A-Z][A-Z]+\", concept):\n",
    "                resolved = resolved.replace(word, response[\"corrections\"][word][0])\n",
    "        \n",
    "        inp_spellchecked.append(resolved)\n",
    "        print (concept, resolved)\n",
    "    else:\n",
    "        inp_spellchecked.append(concept)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emb_indexer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1f0beeec01d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memb_indexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emb_indexer' is not defined"
     ]
    }
   ],
   "source": [
    "emb_indexer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7796"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_spellchecked, fp_spellchecked = [dict(el) for el in pickle.load(open(\"test_v2.pkl\", \"rb\"))]\n",
    "fn_baseline, fp_baseline = [dict(el) for el in pickle.load(open(\"test_best.pkl\", \"rb\"))]\n",
    "fn_unhas, fp_unhas = [dict(el) for el in pickle.load(open(\"test_unhas.pkl\", \"rb\"))]\n",
    "fn_resolved, fp_resolved = [dict(el) for el in pickle.load(open(\"test_resolved.pkl\", \"rb\"))]\n",
    "\n",
    "fn_dict, fp_dict = {}, {}\n",
    "def create_comparison_file(file, idx):\n",
    "    fn, fp = [dict(el) for el in pickle.load(open(file, \"rb\"))]\n",
    "    \n",
    "    for key in fn:\n",
    "        if key in fn_dict:\n",
    "            fn_dict[key][idx] = fn[key]\n",
    "        else:\n",
    "            fn_dict[key] = [\"N/A\" for i in range(4)]\n",
    "            fn_dict[key][idx] = fn[key]\n",
    "    \n",
    "    for key in fp:\n",
    "        if key in fp_dict:\n",
    "            fp_dict[key][idx] = fp[key]\n",
    "        else:\n",
    "            fp_dict[key] = [\"N/A\" for i in range(4)]\n",
    "            fp_dict[key][idx] = fp[key]\n",
    "    \n",
    "\n",
    "create_comparison_file(\"test_best.pkl\", 0)\n",
    "create_comparison_file(\"test_unhas.pkl\", 1)\n",
    "create_comparison_file(\"test_v2.pkl\", 2)\n",
    "create_comparison_file(\"test_resolved.pkl\", 3)\n",
    "\n",
    "open(\"fn - comparison.tsv\", \"w+\").write(\"\\n\".join([\"\\t\".join([str(el) for el in flatten(el)]) for el in fn_dict.items()]))\n",
    "open(\"fp - comparison.tsv\", \"w+\").write(\"\\n\".join([\"\\t\".join([str(el) for el in flatten(el)]) for el in fp_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive string similarity\n",
    "def is_test(test_onto, key):\n",
    "    return tuple([el.split(\"#\")[0] for el in key]) in test_onto\n",
    "\n",
    "threshold_results = {}\n",
    "\n",
    "def sim(a, b):\n",
    "    return cos_sim(emb_vals[emb_indexer[a]], emb_vals[emb_indexer[b]])\n",
    "    \n",
    "def test(test_onto):\n",
    "    all_results = {mapping: (sim(mapping[0], mapping[1]), data[mapping]) for mapping in data if is_test(test_onto, mapping)}\n",
    "    return all_results, test_onto\n",
    "\n",
    "def threshold_optimize(val_onto):\n",
    "    all_results = {mapping: (sim(mapping[0], mapping[1]), data[mapping]) for mapping in data if is_test(val_onto, mapping)}\n",
    "    \n",
    "    low_threshold = np.min([el[0] for el in all_results.values()]) - 0.02\n",
    "    high_threshold = np.max([el[0] for el in all_results.values()]) + 0.02\n",
    "    threshold = low_threshold\n",
    "    step = 0.001\n",
    "\n",
    "    while threshold < high_threshold:\n",
    "        res = []\n",
    "        for i,key in enumerate(all_results):\n",
    "            if all_results[key][0] > threshold:\n",
    "                res.append(key)\n",
    "        fn_list = [(key, all_results[key][0]) for key in gt_mappings if key not in set(res) and is_test(val_onto, key)]\n",
    "        fp_list = [(elem, all_results[elem][0]) for elem in res if not all_results[elem][1]]\n",
    "        tp_list = [(elem, all_results[elem][0]) for elem in res if all_results[elem][1]]\n",
    "\n",
    "        tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "        exception = False\n",
    "\n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            exception = True\n",
    "            step = 0.001\n",
    "            threshold += step\n",
    "            continue\n",
    "        # print (\"Threshold: \", threshold, precision, recall, f1score, f2score, f0_5score)\n",
    "        if threshold in threshold_results:\n",
    "            threshold_results[threshold].append([precision, recall, f1score, f2score, f0_5score])\n",
    "        else:\n",
    "            threshold_results[threshold] = [[precision, recall, f1score, f2score, f0_5score]]\n",
    "\n",
    "        if threshold > 0.98 and not exception:\n",
    "            step = 0.0001\n",
    "        else:\n",
    "            step = 0.001\n",
    "        threshold += step \n",
    "\n",
    "def calculate_performance(test_results):\n",
    "    all_metrics = []\n",
    "    for (all_results, test_onto) in test_results:\n",
    "        res = []\n",
    "        print (all_results)\n",
    "        for i,key in enumerate(all_results):\n",
    "            if all_results[key][0] > threshold:\n",
    "                res.append(key)\n",
    "        fn_list = [(key, all_results[key][0]) for key in gt_mappings if key not in set(res) and is_test(test_onto, key)]\n",
    "        fp_list = [(elem, all_results[elem][0]) for elem in res if not all_results[elem][1]]\n",
    "        tp_list = [(elem, all_results[elem][0]) for elem in res if all_results[elem][1]]\n",
    "        tp, fn, fp = len(tp_list), len(fn_list), len(fp_list)\n",
    "        \n",
    "        try:\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1score = 2 * precision * recall / (precision + recall)\n",
    "            f2score = 5 * precision * recall / (4 * precision + recall)\n",
    "            f0_5score = 1.25 * precision * recall / (0.25 * precision + recall)\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            continue\n",
    "        print (\"Performance for\", test_onto, \"is :\", (precision, recall, f1score, f2score, f0_5score))\n",
    "        all_metrics.append((precision, recall, f1score, f2score, f0_5score))\n",
    "    return all_metrics\n",
    "\n",
    "\n",
    "results = []\n",
    "test_results = []\n",
    "# all_ont_pairs = list(set([tuple([el.split(\"#\")[0] for el in l]) for l in data.keys()]))\n",
    "ontologies_in_alignment = [tuple(pair) for pair in ontologies_in_alignment]\n",
    "for i in list(range(0, len(ontologies_in_alignment), 3)):\n",
    "    test_onto = ontologies_in_alignment[i+2:i+3]\n",
    "    val_onto = ontologies_in_alignment[i:i+2]\n",
    "    \n",
    "    threshold_optimize(val_onto)\n",
    "    \n",
    "    test_results.append(test(test_onto))\n",
    "    \n",
    "threshold_results_mean = {el: np.mean(threshold_results[el], axis=0) for el in threshold_results}\n",
    "threshold = max(threshold_results_mean.keys(), key=(lambda key: threshold_results_mean[key][2]))\n",
    "\n",
    "all_metrics = calculate_performance(test_results)\n",
    "\n",
    "print (\"Final Results: \" + str(np.mean(all_metrics, axis=0)))\n",
    "print (\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results: [0.77546898 0.60841877 0.66963193 0.62907098 0.72571895]\n",
      "Threshold:  0.8606217255044503\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Results: \" + str(np.mean(all_metrics, axis=0)))\n",
    "print (\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left ('Chair_PC', 'Program_Chair') PC Program_Chair\n",
      "left ('Chair_PC', 'Program_Committee') PC Program_Committee\n",
      "left ('Chair_PC', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('Member_PC', 'Program_Chair') PC Program_Chair\n",
      "left ('Member_PC', 'Program_Committee') PC Program_Committee\n",
      "left ('Member_PC', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('Chair_PC', 'Presenter_city') PC Presenter_city\n",
      "left ('Member_PC', 'Presenter_city') PC Presenter_city\n",
      "left ('OC_Member', 'Organizing_Committee_member') OCM Organizing_Committee\n",
      "left ('OC_Member', 'Organizing_Committee') OC Organizing_Committee\n",
      "left ('PC_Member', 'Program_Chair') PC Program_Chair\n",
      "left ('PC_Member', 'Program_Committee') PC Program_Committee\n",
      "left ('PC_Member', 'Program_Committee_member') PCM Program_Committee\n",
      "left ('OC_Chair', 'Organizing_Committee_member') OCM Organizing_Committee\n",
      "left ('OC_Chair', 'Organizing_Committee') OC Organizing_Committee\n",
      "left ('PC_Chair', 'Program_Chair') PC Program_Chair\n",
      "left ('PC_Chair', 'Program_Committee') PC Program_Committee\n",
      "left ('PC_Chair', 'Program_Committee_member') PCM Program_Committee\n",
      "right ('Passive_conference_participant', 'Chair_PC') PCP Passive_conference\n",
      "right ('Passive_conference_participant', 'Member_PC') PCP Passive_conference\n",
      "right ('Program_committee', 'Chair_PC') PC Program_committee\n",
      "right ('Program_committee', 'Member_PC') PC Program_committee\n",
      "left ('SC_Member', 'Brief_introduction_for_Session_chair') BIFSC Session_chair\n",
      "left ('SC_Member', 'Session_chair') SC Session_chair\n",
      "left ('SC_Member', 'Sponsor_city') SC Sponsor_city\n",
      "left ('SC_Member', 'Sponsor_company_house') SCH Sponsor_company\n",
      "left ('OC_Member', 'One_conference_day') OCD One_conference\n",
      "left ('PC_Member', 'Presenter_city') PC Presenter_city\n",
      "left ('OC_Chair', 'One_conference_day') OCD One_conference\n",
      "left ('PC_Chair', 'Presenter_city') PC Presenter_city\n",
      "left ('Chair_PC', 'PC_Chair') PC PC_Chair\n",
      "left ('Member_PC', 'PC_Chair') PC PC_Chair\n",
      "right ('Submitted_contribution', 'SC_Member') SC Submitted_contribution\n",
      "right ('Steering_committee', 'SC_Member') SC Steering_committee\n",
      "right ('Passive_conference_participant', 'PC_Member') PCP Passive_conference\n",
      "right ('Passive_conference_participant', 'PC_Chair') PCP Passive_conference\n",
      "right ('Program_committee', 'PC_Member') PC Program_committee\n",
      "right ('Program_committee', 'PC_Chair') PC Program_committee\n",
      "right ('Organizing_committee', 'OC_Member') OC Organizing_committee\n",
      "right ('Organizing_committee', 'OC_Chair') OC Organizing_committee\n",
      "left ('paperID', 'is_dated_on') IDO is_dated\n"
     ]
    }
   ],
   "source": [
    "abbreviations_dict = {}\n",
    "final_dict = {}\n",
    "\n",
    "for mapping in all_mappings:\n",
    "    mapping = tuple([el.split(\"#\")[1] for el in mapping])\n",
    "    is_abb = re.search(\"[A-Z][A-Z]+\", mapping[0])\n",
    "    if is_abb:\n",
    "        abbreviation = \"\".join([el[0].upper() for el in mapping[1].split(\"_\")])\n",
    "        if is_abb.group() in abbreviation:\n",
    "            \n",
    "            start = abbreviation.find(is_abb.group())\n",
    "            end = start + len(is_abb.group())\n",
    "            fullform = \"_\".join(mapping[1].split(\"_\")[start:end])\n",
    "            print (\"left\", mapping, abbreviation, fullform)\n",
    "            \n",
    "            rest_first = \" \".join([el for el in mapping[0].replace(is_abb.group(), \"\").split(\"_\") if el]).lower()\n",
    "            rest_second = \" \".join(mapping[1].split(\"_\")[:start] + mapping[1].split(\"_\")[end:])\n",
    "            if is_abb.group() not in final_dict:\n",
    "                final_dict[is_abb.group()] = [(fullform, rest_first, rest_second)]\n",
    "            else:\n",
    "                final_dict[is_abb.group()].append((fullform, rest_first, rest_second))\n",
    "\n",
    "    is_abb = re.search(\"[A-Z][A-Z]+\", mapping[1])\n",
    "    if is_abb:\n",
    "        abbreviation = \"\".join([el[0].upper() for el in mapping[0].split(\"_\")])\n",
    "        \n",
    "        if is_abb.group() in abbreviation:\n",
    "            start = abbreviation.find(is_abb.group())\n",
    "            end = start + len(is_abb.group())\n",
    "            fullform = \"_\".join(mapping[0].split(\"_\")[start:end])\n",
    "            print (\"right\", mapping, abbreviation, fullform)\n",
    "\n",
    "            rest_first = \" \".join([el for el in mapping[1].replace(is_abb.group(), \"\").split(\"_\") if el]).lower()\n",
    "            rest_second = \" \".join(mapping[0].split(\"_\")[:start] + mapping[0].split(\"_\")[end:])\n",
    "            if is_abb.group() not in final_dict:\n",
    "                final_dict[is_abb.group()] = [(fullform, rest_first, rest_second)]\n",
    "            else:\n",
    "                final_dict[is_abb.group()].append((fullform, rest_first, rest_second))\n",
    "\n",
    "keys = [el for el in list(set(flatten([flatten([tup[1:] for tup in final_dict[key]]) for key in final_dict]))) if el]\n",
    "abb_embeds = dict(zip(keys, extractUSEEmbeddings(keys)))\n",
    "\n",
    "scored_dict = {}\n",
    "for abbr in final_dict:\n",
    "    sim_list = [(tup[0], tup[1], tup[2], cos_sim(abb_embeds[tup[1]], abb_embeds[tup[2]])) if tup[1] and tup[2]\n",
    "                else (tup[0], tup[1], tup[2], 0) for tup in final_dict[abbr]]\n",
    "    scored_dict[abbr] = sorted(list(set(sim_list)), key=lambda x:x[-1], reverse=True)\n",
    "\n",
    "resolved_dict = {key: scored_dict[key][0] for key in scored_dict}\n",
    "filtered_dict = {key: \" \".join(resolved_dict[key][0].split(\"_\")) for key in resolved_dict if resolved_dict[key][-1] > 0.9}\n",
    "inp_resolved = []\n",
    "for concept in inp:\n",
    "    for key in filtered_dict:\n",
    "        concept = concept.replace(key, filtered_dict[key])\n",
    "    inp_resolved.append(concept)\n",
    "inp_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [el for el in list(set(flatten([flatten([tup[1:] for tup in final_dict[key]]) for key in final_dict]))) if el]\n",
    "abb_embeds = dict(zip(keys, extractUSEEmbeddings(keys)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085169792175293"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(*extractUSEEmbeddings([\"Conference Banquet\", \"Dinner Banquet\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('confOf#hasEmail', 'sigkdd#E-mail'), 0.9161555776735063),\n",
       " (('confOf#Chair_PC', 'sigkdd#Program_Chair'), 0.8290806880788957),\n",
       " (('iasted#Student_registration_fee', 'sigkdd#Registration_Student'),\n",
       "  0.9156892709934972),\n",
       " (('iasted#Deadline_for_notification_of_acceptance',\n",
       "   'sigkdd#Deadline_Author_notification'),\n",
       "  0.5085231269229767),\n",
       " (('iasted#Nonmember_registration_fee', 'sigkdd#Registration_Non-Member'),\n",
       "  0.8098175068174337),\n",
       " (('cmt#ConferenceMember', 'ekaw#Conference_Participant'), 0.3532655254301476),\n",
       " (('cmt#Author', 'ekaw#Paper_Author'), 0.9288647440450568),\n",
       " (('cmt#writtenBy', 'ekaw#reviewWrittenBy'), 0.7592434303979944),\n",
       " (('cmt#hasBeenAssigned', 'ekaw#reviewerOfPaper'), 0.2502871547766108),\n",
       " (('cmt#assignedTo', 'ekaw#hasReviewer'), 0.3499445900379554),\n",
       " (('cmt#PaperFullVersion', 'ekaw#Regular_Paper'), 0.8379052493933772),\n",
       " (('confOf#Administrative_event', 'iasted#Activity_before_conference'),\n",
       "  0.37740041094526244),\n",
       " (('conference#has_the_first_name', 'edas#hasFirstName'), 0.880357115623567),\n",
       " (('conference#Conference_part', 'edas#ConferenceEvent'), 0.8634459315564949),\n",
       " (('conference#has_a_review_expertise', 'edas#hasRating'), 0.3899073903898582),\n",
       " (('cmt#ConferenceChair', 'sigkdd#General_Chair'), 0.8078542602095952),\n",
       " (('cmt#submitPaper', 'sigkdd#submit'), 0.7581630948456032),\n",
       " (('ekaw#PC_Chair', 'sigkdd#Program_Chair'), 0.8432266698142893),\n",
       " (('conference#Conference_fees', 'sigkdd#Fee'), 0.6188697294990487),\n",
       " (('conference#has_an_email', 'sigkdd#E-mail'), 0.7713571936527924),\n",
       " (('conference#is_given_by', 'sigkdd#presentationed_by'), 0.3609120954885683),\n",
       " (('conference#gives_presentations', 'sigkdd#presentation'),\n",
       "  0.6056676430562652),\n",
       " (('conference#has_an_email', 'confOf#hasEmail'), 0.8262672905906706),\n",
       " (('conference#Conference_contribution', 'confOf#Contribution'),\n",
       "  0.8299805404727582),\n",
       " (('conference#has_a_track-workshop-tutorial_topic', 'confOf#hasTopic'),\n",
       "  0.2714890208534184),\n",
       " (('confOf#reviewes', 'edas#isReviewing'), 0.6861398267050898),\n",
       " (('confOf#writtenBy', 'edas#isWrittenBy'), 0.8407108246292888),\n",
       " (('confOf#Working_event', 'edas#AcademicEvent'), 0.8097133404737215),\n",
       " (('confOf#Member_PC', 'edas#TPCMember'), 0.678868106101965),\n",
       " (('confOf#writes', 'edas#hasRelatedPaper'), 0.297312720126214),\n",
       " (('edas#WelcomeTalk', 'iasted#Welcome_address'), 0.7917928042109413),\n",
       " (('edas#Attendee', 'iasted#Delegate'), 0.5473781390424541),\n",
       " (('edas#SocialEvent', 'iasted#Social_program'), 0.3743878054700725),\n",
       " (('edas#SlideSet', 'iasted#Transparency'), 0.22831568660972779),\n",
       " (('edas#Paper', 'iasted#Submission'), 0.5257373243903976),\n",
       " (('edas#ConferenceVenuePlace', 'iasted#Conference_building'),\n",
       "  0.7506334913541919),\n",
       " (('edas#DiningPlace', 'iasted#Conference_restaurant'), 0.8535001980925233),\n",
       " (('cmt#Preference', 'conference#Review_preference'), 0.783329808487203),\n",
       " (('cmt#email', 'conference#has_an_email'), 0.8262672905906706),\n",
       " (('cmt#Co-author', 'conference#Contribution_co-author'), 0.819271045480498),\n",
       " (('cmt#assignedByReviewer', 'conference#invited_by'), 0.48464419365137834),\n",
       " (('cmt#assignExternalReviewer', 'conference#invites_co-reviewers'),\n",
       "  0.4054012020450263),\n",
       " (('edas#hasCostAmount', 'sigkdd#Price'), 0.7047592167957165),\n",
       " (('edas#hasName', 'sigkdd#Name_of_conference'), 0.4805131633714943),\n",
       " (('edas#ConferenceVenuePlace', 'sigkdd#Conference_hall'), 0.6088660708614848),\n",
       " (('edas#AccommodationPlace', 'sigkdd#Hotel'), 0.5872493203395058),\n",
       " (('edas#startDate', 'sigkdd#Start_of_conference'), 0.528186177578591),\n",
       " (('edas#ConferenceChair', 'sigkdd#General_Chair'), 0.8688377867265579),\n",
       " (('edas#endDate', 'sigkdd#End_of_conference'), 0.5493031244333424),\n",
       " (('edas#Attendee', 'sigkdd#Listener'), 0.5273161396977948),\n",
       " (('conference#Passive_conference_participant', 'iasted#Listener'),\n",
       "  0.24072285668445437),\n",
       " (('conference#Active_conference_participant', 'iasted#Speaker'),\n",
       "  0.0043877585366876425),\n",
       " (('conference#Conference_fees', 'iasted#Fee'), 0.6188697294990487),\n",
       " (('conference#contributes', 'iasted#write'), 0.37880804066855067),\n",
       " (('conference#Conference_part', 'iasted#Conference_activity'),\n",
       "  0.754729668736523),\n",
       " (('conference#Submitted_contribution', 'iasted#Submission'),\n",
       "  0.6515994788116265),\n",
       " (('conference#Camera_ready_contribution', 'iasted#Final_manuscript'),\n",
       "  0.20353872337293488),\n",
       " (('conference#Conference_proceedings', 'iasted#Publication'),\n",
       "  0.1916452210219224),\n",
       " (('ekaw#Conference_Banquet', 'iasted#Dinner_banquet'), 0.9146926474654158),\n",
       " (('cmt#writePaper', 'confOf#writes'), 0.6220006428478738),\n",
       " (('cmt#ConferenceMember', 'confOf#Member'), 0.8568252252381775),\n",
       " (('cmt#PaperFullVersion', 'confOf#Paper'), 0.6356338598318733),\n",
       " (('cmt#hasBeenAssigned', 'confOf#reviewes'), 0.40867753235276827),\n",
       " (('cmt#hasAuthor', 'confOf#writtenBy'), 0.5261010208677641),\n",
       " (('cmt#hasSubjectArea', 'confOf#dealsWith'), 0.25596982134585333),\n",
       " (('cmt#hasConferenceMember', 'edas#hasMember'), 0.6716821946490479),\n",
       " (('cmt#memberOfConference', 'edas#isMemberOf'), 0.5384339627563817),\n",
       " (('cmt#hasAuthor', 'edas#isWrittenBy'), 0.3940901098620504),\n",
       " (('cmt#hasBeenAssigned', 'edas#isReviewing'), 0.4039842265275537),\n",
       " (('cmt#assignedTo', 'edas#isReviewedBy'), 0.5476728328223632),\n",
       " (('edas#isReviewedBy', 'ekaw#hasReviewer'), 0.38891106779153306),\n",
       " (('edas#AcademiaOrganization', 'ekaw#Academic_Institution'),\n",
       "  0.7638726986015515),\n",
       " (('edas#isReviewing', 'ekaw#reviewerOfPaper'), 0.4574440998156941),\n",
       " (('edas#isLocationOf', 'ekaw#locationOf'), 0.7440274368714033),\n",
       " (('edas#Programme', 'ekaw#Programme_Brochure'), 0.5409891762364093),\n",
       " (('edas#Attendee', 'ekaw#Conference_Participant'), 0.8768055189198933),\n",
       " (('edas#hasLocation', 'ekaw#heldIn'), 0.3689859558260715),\n",
       " (('conference#Information_for_participants', 'ekaw#Programme_Brochure'),\n",
       "  -0.1194315228734015),\n",
       " (('conference#has_a_review', 'ekaw#hasReview'), 0.8414144924885054),\n",
       " (('conference#Late_paid_applicant', 'ekaw#Late-Registered_Participant'),\n",
       "  0.654309404831223),\n",
       " (('conference#Early_paid_applicant', 'ekaw#Early-Registered_Participant'),\n",
       "  0.5991906447371812),\n",
       " (('conference#Poster', 'ekaw#Poster_Paper'), 0.7686016382074798),\n",
       " (('conference#Conference_www', 'ekaw#Web_Site'), 0.44282246019334814),\n",
       " (('conference#contributes', 'ekaw#authorOf'), 0.3016937274326247),\n",
       " (('conference#Accepted_contribution', 'ekaw#Accepted_Paper'),\n",
       "  0.8357883000723147),\n",
       " (('conference#Reviewed_contribution', 'ekaw#Evaluated_Paper'),\n",
       "  0.6112944103257296),\n",
       " (('conference#Submitted_contribution', 'ekaw#Submitted_Paper'),\n",
       "  0.6904896027545419),\n",
       " (('confOf#Poster', 'ekaw#Poster_Paper'), 0.7685522235623811),\n",
       " (('confOf#Contribution', 'ekaw#Paper'), 0.639392230902997),\n",
       " (('confOf#Trip', 'ekaw#Conference_Trip'), 0.8240761817569572),\n",
       " (('confOf#Scholar', 'ekaw#Student'), 0.5104832530935325)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_dict = {}\n",
    "for abbr in final_dict:\n",
    "    sim_list = [(tup[0], tup[1], tup[2], cos_sim(abb_embeds[tup[1]], abb_embeds[tup[2]])) if tup[1] and tup[2]\n",
    "                else (tup[0], tup[1], tup[2], 0) for tup in final_dict[abbr]]\n",
    "    scored_dict[abbr] = sorted(list(set(sim_list)), key=lambda x:x[-1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pay',\n",
       " 'rejected by',\n",
       " 'Registration SIGMOD Member',\n",
       " 'is connected with',\n",
       " 'NGO',\n",
       " 'overhead projector',\n",
       " 'name of conference',\n",
       " 'call for participation',\n",
       " 'coffee break',\n",
       " 'scientifically organised by',\n",
       " 'volunteer',\n",
       " 'publisher',\n",
       " 'regular',\n",
       " 'add program committee member',\n",
       " 'contact email',\n",
       " 'part of event',\n",
       " 'dinner banquet',\n",
       " 'social program',\n",
       " 'decision',\n",
       " 'is sent by',\n",
       " 'was a committee chair of',\n",
       " 'organisation',\n",
       " 'paper',\n",
       " 'assign external reviewer',\n",
       " 'was a member of',\n",
       " 'has cost amount',\n",
       " 'session chair',\n",
       " 'single level conference',\n",
       " 'hotel',\n",
       " 'deadline hotel reservation',\n",
       " 'country',\n",
       " 'important dates',\n",
       " 'paper',\n",
       " 'has parts',\n",
       " 'event',\n",
       " 'paper due on',\n",
       " 'is the 1th part of',\n",
       " 'has surname',\n",
       " 'wireless communications topic',\n",
       " 'two level conference',\n",
       " 'has first name',\n",
       " 'bid',\n",
       " 'is designed for',\n",
       " 'author',\n",
       " 'double hotel room',\n",
       " 'review form',\n",
       " 'presentation',\n",
       " 'subject area',\n",
       " 'positive integer',\n",
       " 'deadline abstract submission',\n",
       " 'has a degree',\n",
       " 'is present in',\n",
       " 'related to event',\n",
       " 'reviews',\n",
       " 'topic',\n",
       " 'e-mail',\n",
       " 'has keyword',\n",
       " 'university',\n",
       " 'has street',\n",
       " 'reviewed contribution',\n",
       " 'call',\n",
       " 'occupy',\n",
       " 'ends on',\n",
       " 'presenter university',\n",
       " 'rejected paper',\n",
       " 'obtain',\n",
       " 'invited by',\n",
       " 'paper',\n",
       " 'updated version of',\n",
       " 'company',\n",
       " 'topic',\n",
       " 'call for paper',\n",
       " 'student',\n",
       " 'has reviewer',\n",
       " 'has updated version',\n",
       " 'invited talk',\n",
       " 'free time break',\n",
       " 'non academic event',\n",
       " 'best student paper supporter',\n",
       " 'publisher of',\n",
       " 'submit paper',\n",
       " 'author',\n",
       " 'program committee',\n",
       " 'TPC Member',\n",
       " 'listener',\n",
       " 'hotel fee',\n",
       " 'int',\n",
       " 'default choice',\n",
       " 'review of paper',\n",
       " 'author',\n",
       " 'poster',\n",
       " 'has amount of',\n",
       " 'web site',\n",
       " 'has location',\n",
       " 'subclass of',\n",
       " 'conference days',\n",
       " 'has a track-workshop-tutorial topic',\n",
       " 'welcome address',\n",
       " 'sponzorship',\n",
       " 'program committee',\n",
       " 'read by meta-reviewer',\n",
       " 'conference proceedings',\n",
       " 'regular contribution',\n",
       " 'reception',\n",
       " 'abstract',\n",
       " 'print hardcopy mailing manifests',\n",
       " 'Chair PC',\n",
       " 'has co-author',\n",
       " 'card',\n",
       " 'location',\n",
       " 'conference hall',\n",
       " 'is writen by',\n",
       " 'has email',\n",
       " 'antennas topic',\n",
       " 'trip city',\n",
       " 'has contributions',\n",
       " 'review',\n",
       " 'was a committee of',\n",
       " 'call for manuscripts',\n",
       " 'worker lecturer',\n",
       " 'video presentation',\n",
       " 'has email',\n",
       " 'reception',\n",
       " 'meta-review',\n",
       " 'inverse of part of 7',\n",
       " 'computer networks topic',\n",
       " 'paper presentation',\n",
       " 'coctail reception',\n",
       " 'slide set',\n",
       " 'has biography',\n",
       " 'subclass of',\n",
       " 'has an email',\n",
       " 'location',\n",
       " 'chair',\n",
       " 'receiving manuscript',\n",
       " 'user',\n",
       " 'has menu',\n",
       " 'author of',\n",
       " 'tip',\n",
       " 'is an abstract submission date',\n",
       " 'date',\n",
       " 'session room',\n",
       " 'committee',\n",
       " 'details entered by',\n",
       " 'committee',\n",
       " 'nonauthor registration fee',\n",
       " 'workshop',\n",
       " 'personal history',\n",
       " 'has call',\n",
       " 'program committee',\n",
       " 'speak in',\n",
       " 'programme brochure',\n",
       " 'end date',\n",
       " 'accepted contribution',\n",
       " 'enable virtual meeting',\n",
       " 'topic covered by',\n",
       " 'sponzor',\n",
       " 'has city',\n",
       " 'has topic',\n",
       " 'scientific event',\n",
       " 'has phone',\n",
       " 'co-chair',\n",
       " 'written contribution',\n",
       " 'string',\n",
       " 'submit until',\n",
       " 'personal review history',\n",
       " 'location of',\n",
       " 'has an ISBN',\n",
       " 'subclass of',\n",
       " 'date',\n",
       " 'registration',\n",
       " 'remark',\n",
       " 'state',\n",
       " 'building',\n",
       " 'city of conference',\n",
       " 'possible reviewer',\n",
       " 'personal publication history',\n",
       " 'conference banquet',\n",
       " 'gives presentations',\n",
       " 'tax',\n",
       " 'email',\n",
       " 'has end date time',\n",
       " 'SC Member',\n",
       " 'conference part',\n",
       " 'date',\n",
       " 'session',\n",
       " 'contributes',\n",
       " 'assigned paper',\n",
       " 'external reviewer',\n",
       " 'Registration SIGKDD Member',\n",
       " 'submissions deadline',\n",
       " 'prepare',\n",
       " 'radio communications topic',\n",
       " 'PC Member',\n",
       " 'introduction',\n",
       " 'steering committee',\n",
       " 'security topic',\n",
       " 'has title',\n",
       " 'travel grant',\n",
       " 'submit',\n",
       " 'science worker',\n",
       " 'set max papers',\n",
       " 'invited speaker',\n",
       " 'has review',\n",
       " 'poster',\n",
       " 'author of paper student',\n",
       " 'camera ready manuscript deadline',\n",
       " 'modelling',\n",
       " 'is held after',\n",
       " 'powerline transmission topic',\n",
       " 'name',\n",
       " 'read paper',\n",
       " 'computer networks management topic',\n",
       " 'review question',\n",
       " 'presentation',\n",
       " 'negative review',\n",
       " 'communications topic',\n",
       " 'co-write paper',\n",
       " 'PC Chair',\n",
       " 'has phone',\n",
       " 'memeber registration fee',\n",
       " 'conference volume',\n",
       " 'date time',\n",
       " 'date',\n",
       " 'worker non speaker',\n",
       " 'review',\n",
       " 'invitation letter',\n",
       " 'conference venue place',\n",
       " 'has related document',\n",
       " 'presenter city',\n",
       " 'delegate',\n",
       " 'workshop session',\n",
       " 'research institute',\n",
       " 'has a location',\n",
       " 'multi-author volume',\n",
       " 'industrial session',\n",
       " 'currency',\n",
       " 'lists event',\n",
       " 'car',\n",
       " 'held in',\n",
       " 'has gender',\n",
       " 'has member',\n",
       " 'conference trip',\n",
       " 'presentationed by',\n",
       " 'one day presenter',\n",
       " 'city',\n",
       " 'follows',\n",
       " 'hotel room',\n",
       " 'satellite and space communications topic',\n",
       " 'conference session',\n",
       " 'computer networks enterprise topic',\n",
       " 'referenced in',\n",
       " 'associated chair',\n",
       " 'contribution co-author',\n",
       " 'coffee break',\n",
       " 'obtain',\n",
       " 'has attendee',\n",
       " 'is paid with',\n",
       " 'covers topic',\n",
       " 'document',\n",
       " 'organizing committee member',\n",
       " 'plenary lecture speaker',\n",
       " 'conference participant',\n",
       " 'can stay in',\n",
       " 'has a review reference or expertise',\n",
       " 'conference hall',\n",
       " 'track',\n",
       " 'has a program committee',\n",
       " 'start date',\n",
       " 'working event',\n",
       " 'student non speaker',\n",
       " 'academia organization',\n",
       " 'invited speaker',\n",
       " 'workshop',\n",
       " 'is a date of camera ready paper submission',\n",
       " 'registration of participants event',\n",
       " 'has subject area',\n",
       " 'contribution',\n",
       " 'reviewing event',\n",
       " 'paper assignment tools run by',\n",
       " 'sponsor state',\n",
       " 'evaluated paper',\n",
       " 'sponsor',\n",
       " 'technic activity',\n",
       " 'accepted paper',\n",
       " 'conference',\n",
       " 'parallel with',\n",
       " 'unsigned long',\n",
       " 'IASTED non member',\n",
       " 'review rating',\n",
       " 'conference document',\n",
       " 'has author',\n",
       " 'workshop',\n",
       " 'document',\n",
       " 'program committee chair',\n",
       " 'registration fee',\n",
       " 'organizational meeting',\n",
       " 'assigned by administrator',\n",
       " 'book proceeding',\n",
       " 'has part',\n",
       " 'has conflict of interest',\n",
       " 'sponsor company house',\n",
       " 'string',\n",
       " 'has short title',\n",
       " 'enter review criteria',\n",
       " 'int',\n",
       " 'boolean',\n",
       " 'is needed for',\n",
       " 'author',\n",
       " 'name',\n",
       " 'payed by',\n",
       " 'int',\n",
       " 'has street',\n",
       " 'write',\n",
       " 'tutorial speaker',\n",
       " 'invited talk abstract',\n",
       " 'has rating',\n",
       " 'paper abstract',\n",
       " 'presenter state',\n",
       " 'has tracks',\n",
       " 'member of program committee',\n",
       " 'has last name',\n",
       " 'author information form',\n",
       " 'max papers',\n",
       " 'one conference day',\n",
       " 'is reviewing',\n",
       " 'social event',\n",
       " 'logo URL',\n",
       " 'has a volume',\n",
       " 'invites co-reviewers',\n",
       " 'session chair',\n",
       " 'communication theory topic',\n",
       " 'has review history',\n",
       " 'conference applicant',\n",
       " 'operating topicsystems',\n",
       " 'has a topic or a submission contribution',\n",
       " 'welcome talk',\n",
       " 'webmaster',\n",
       " 'cryptography topic',\n",
       " 'sponsorship',\n",
       " 'person',\n",
       " 'has submission instructions',\n",
       " 'paid applicant',\n",
       " 'workshop chair',\n",
       " 'activity after conference',\n",
       " 'organizing committee',\n",
       " 'conference',\n",
       " 'bank transfer',\n",
       " 'assigned by reviewer',\n",
       " 'has city',\n",
       " 'assistant',\n",
       " 'Member PC',\n",
       " 'banquet',\n",
       " 'poster session',\n",
       " 'technically organised by',\n",
       " 'computer networks sensor topic',\n",
       " 'is member of',\n",
       " 'is given by',\n",
       " 'done till',\n",
       " 'review written by',\n",
       " 'belongs to event',\n",
       " 'provided by',\n",
       " 'late-registered participant',\n",
       " 'study at',\n",
       " 'administrator',\n",
       " 'starts on',\n",
       " 'has important dates',\n",
       " 'sponzor fee',\n",
       " 'conference chair',\n",
       " 'audiovisual equipment',\n",
       " 'assign reviewer',\n",
       " 'has start date time',\n",
       " 'has a steering committee',\n",
       " 'reject rating',\n",
       " 'lecture',\n",
       " 'person',\n",
       " 'is visited by',\n",
       " 'demo paper',\n",
       " 'gold supporter',\n",
       " 'conference contributor',\n",
       " 'attendee',\n",
       " 'has country',\n",
       " 'is submitted at',\n",
       " 'credit card',\n",
       " 'deals with',\n",
       " 'textual review question',\n",
       " 'best research paper award',\n",
       " 'dining place',\n",
       " 'neutral review',\n",
       " 'nation',\n",
       " 'abstract',\n",
       " 'accepted by',\n",
       " 'is topic of',\n",
       " 'best paper awards committee',\n",
       " 'has a publisher',\n",
       " 'tutorial abstract',\n",
       " 'author',\n",
       " 'deadline paper submission',\n",
       " 'meal event',\n",
       " 'committee member',\n",
       " 'conference airport',\n",
       " 'registration due on',\n",
       " 'exhibitor',\n",
       " 'CAD Topic',\n",
       " 'review preference',\n",
       " 'volume contains paper',\n",
       " 'has a submitted contribution',\n",
       " 'reviewer',\n",
       " 'camera ready contribution',\n",
       " 'place',\n",
       " 'is prepared by',\n",
       " 'has a date of issue',\n",
       " 'trip day',\n",
       " 'conference fees',\n",
       " 'is signed by',\n",
       " 'demo session',\n",
       " 'string',\n",
       " 'platinum supporter',\n",
       " 'pay',\n",
       " 'administrative event',\n",
       " 'is held in',\n",
       " 'computer networks optical topic',\n",
       " 'final manuscript',\n",
       " 'accepted paper',\n",
       " 'author of paper',\n",
       " 'has postal code',\n",
       " 'contribution 1th-author',\n",
       " 'is present',\n",
       " 'was a program committee of',\n",
       " 'author cd proceedings included',\n",
       " 'multimedia topic',\n",
       " 'sponsor city',\n",
       " 'speaker',\n",
       " 'write paper',\n",
       " 'numerical review question',\n",
       " 'research topic',\n",
       " 'co-author',\n",
       " 'fee for extra trip',\n",
       " 'was a track-workshop chair of',\n",
       " 'subclass of',\n",
       " 'contributed talk',\n",
       " 'hold',\n",
       " 'has title',\n",
       " 'van',\n",
       " 'acceptance',\n",
       " 'abstract',\n",
       " 'scholar',\n",
       " 'conference activity',\n",
       " 'adjust bid',\n",
       " 'hotel registration form',\n",
       " 'conference city',\n",
       " 'read by reviewer',\n",
       " 'government organization',\n",
       " 'reviewing results event',\n",
       " 'active paper',\n",
       " 'workshop',\n",
       " 'mobile computing topic',\n",
       " 'int',\n",
       " 'document',\n",
       " 'publication',\n",
       " 'excursion',\n",
       " 'student registration fee',\n",
       " 'reviewer',\n",
       " 'has a URL',\n",
       " 'written by',\n",
       " 'for event',\n",
       " 'finalize paper assignment',\n",
       " 'has been assigned',\n",
       " 'cd proceening',\n",
       " 'paper',\n",
       " 'registration student',\n",
       " 'deadline for notification of acceptance',\n",
       " 'has authors',\n",
       " 'computer architecture topic',\n",
       " 'is reviewed by',\n",
       " 'agency staff member',\n",
       " 'paper full version',\n",
       " 'introduction of speaker',\n",
       " 'registration form',\n",
       " 'person',\n",
       " 'computer networks switching topic',\n",
       " 'reviewer',\n",
       " 'has submission deadline',\n",
       " 'organization',\n",
       " 'accept rating',\n",
       " 'hotel presenter',\n",
       " 'subclass of',\n",
       " 'programme',\n",
       " 'conference',\n",
       " 'listener',\n",
       " 'related to paper',\n",
       " 'has members',\n",
       " 'submission event',\n",
       " 'event',\n",
       " 'award',\n",
       " 'conference',\n",
       " 'country',\n",
       " 'conference contribution',\n",
       " 'is sent after',\n",
       " 'go through',\n",
       " 'is given by',\n",
       " 'organising agency',\n",
       " 'closing talk',\n",
       " 'is dated on',\n",
       " 'start reviewer bidding',\n",
       " 'title',\n",
       " 'cheque',\n",
       " 'camera ready paper',\n",
       " 'end of conference',\n",
       " 'form',\n",
       " 'is made from',\n",
       " 'paper ID',\n",
       " 'is paid by',\n",
       " 'holded by',\n",
       " 'extended abstract',\n",
       " 'write review',\n",
       " 'is provider of',\n",
       " 'silver supporter',\n",
       " 'meta-reviewer',\n",
       " 'paper',\n",
       " 'end review',\n",
       " 'conference hiker',\n",
       " 'is occupied by',\n",
       " 'paper',\n",
       " 'member',\n",
       " 'is paid in',\n",
       " 'conference proceedings',\n",
       " 'is review history of',\n",
       " 'industry organization',\n",
       " 'time zone',\n",
       " 'has been assigned a review reference',\n",
       " 'call for papers',\n",
       " 'trip',\n",
       " 'single hotel room',\n",
       " 'boolean',\n",
       " 'meal break',\n",
       " 'information for participants',\n",
       " 'conference dinner',\n",
       " 'review expertise',\n",
       " 'organizer',\n",
       " 'string',\n",
       " 'is written by',\n",
       " 'poster paper',\n",
       " 'is a topis of conference parts',\n",
       " 'early paid applicant',\n",
       " 'belongs to reviewers',\n",
       " 'simulating',\n",
       " 'conference event',\n",
       " 'topic',\n",
       " 'tutorial chair',\n",
       " 'sign',\n",
       " 'has event',\n",
       " 'week reject rating',\n",
       " 'regular paper',\n",
       " 'power point presentation',\n",
       " 'industrial paper',\n",
       " 'award',\n",
       " 'search',\n",
       " 'has home page',\n",
       " 'has an abstract',\n",
       " 'departure tax',\n",
       " 'early registration',\n",
       " 'presenter',\n",
       " 'invited speaker',\n",
       " 'hardcopy mailing manifests printed by',\n",
       " 'written by',\n",
       " 'has the last name',\n",
       " 'talk event',\n",
       " 'camera ready event',\n",
       " 'has country',\n",
       " 'person',\n",
       " 'is used by',\n",
       " 'social event',\n",
       " 'enter conference details',\n",
       " 'is a full paper submission date',\n",
       " 'notification until',\n",
       " 'session',\n",
       " 'is sent before',\n",
       " 'is a date of acceptance announcement',\n",
       " 'was a steering committee of',\n",
       " 'conference hotel',\n",
       " 'expert on',\n",
       " 'person',\n",
       " 'meal menu',\n",
       " 'shuttle bus',\n",
       " 'taxi',\n",
       " 'rejection',\n",
       " 'initiates',\n",
       " 'academic institution',\n",
       " 'has topic',\n",
       " 'is given to',\n",
       " 'paper assignment finalized by',\n",
       " 'main office',\n",
       " 'has the first name',\n",
       " 'is initiated by',\n",
       " 'student lecturer',\n",
       " 'has bid',\n",
       " 'presenter',\n",
       " 'passive conference participant',\n",
       " 'belong to a conference volume',\n",
       " 'bronze supporter',\n",
       " 'site URL',\n",
       " 'ACM SIGKDD',\n",
       " 'conference member',\n",
       " 'accept paper',\n",
       " 'conference announcement',\n",
       " 'author attendee book registration fee',\n",
       " 'active conference participant',\n",
       " 'invited talk',\n",
       " 'individual presentation',\n",
       " 'part of',\n",
       " 'meeting room place',\n",
       " 'registration non-member',\n",
       " 'withdrawn paper',\n",
       " 'medicine topic',\n",
       " 'registation deadline',\n",
       " 'start of conference',\n",
       " 'date time',\n",
       " 'is a starting date',\n",
       " 'relates to',\n",
       " 'conference www',\n",
       " 'departure',\n",
       " 'full day tour',\n",
       " 'any URI',\n",
       " 'microelectronics topic',\n",
       " 'issues',\n",
       " 'attendee at',\n",
       " 'is an ending date',\n",
       " 'run paper assignment tools',\n",
       " 'mailing list',\n",
       " 'signal processing topic',\n",
       " 'value added tax',\n",
       " 'academic event',\n",
       " 'event on list',\n",
       " 'reject paper',\n",
       " 'review',\n",
       " 'is location of',\n",
       " 'record of attendance',\n",
       " 'registration fee',\n",
       " 'presenter house',\n",
       " 'late paid applicant',\n",
       " 'is held before',\n",
       " 'tutorial',\n",
       " 'computer networks measurements topic',\n",
       " 'conference',\n",
       " 'track-workshop chair',\n",
       " 'conference session',\n",
       " 'participant',\n",
       " 'is situated in',\n",
       " 'track',\n",
       " 'technically organises',\n",
       " 'adjusted by',\n",
       " 'nonmember registration fee',\n",
       " 'is equipped by',\n",
       " 'conference chair',\n",
       " 'technical commitee',\n",
       " 'fee',\n",
       " 'lecturer',\n",
       " 'video cassette player',\n",
       " 'program committee member',\n",
       " 'OC Chair',\n",
       " 'item',\n",
       " 'organises',\n",
       " 'research',\n",
       " 'best student paper award',\n",
       " 'organization',\n",
       " 'price',\n",
       " 'accepts hardcopy submissions',\n",
       " 'conference',\n",
       " 'author not reviewer',\n",
       " 'student',\n",
       " 'design',\n",
       " 'general chair',\n",
       " 'organization',\n",
       " 'has first name',\n",
       " 'organised by',\n",
       " 'has program committee member',\n",
       " 'manuscript due on',\n",
       " 'conference restaurant',\n",
       " 'paper in volume',\n",
       " 'review criteria entered by',\n",
       " 'tutorial',\n",
       " 'money',\n",
       " 'positive review',\n",
       " 'computer',\n",
       " 'parallel and distributed computing topic',\n",
       " 'has related paper',\n",
       " 'assigned to',\n",
       " 'non speaker',\n",
       " 'pending paper',\n",
       " 'proceedings',\n",
       " 'has decision',\n",
       " 'has an expertise',\n",
       " 'city',\n",
       " 'has a review',\n",
       " 'organizing committee',\n",
       " 'added by',\n",
       " 'activity before conference',\n",
       " 'employed by',\n",
       " 'main office',\n",
       " 'contact information',\n",
       " 'was an organizing committee of',\n",
       " 'scientifically organises',\n",
       " 'max choice',\n",
       " 'has workshops',\n",
       " 'is paid for',\n",
       " 'computer networks security topic',\n",
       " 'published paper',\n",
       " 'social event',\n",
       " 'author attendee cd registration fee',\n",
       " 'date time',\n",
       " 'has fax',\n",
       " 'is used for',\n",
       " 'time',\n",
       " 'references',\n",
       " 'workshop paper',\n",
       " 'document',\n",
       " 'has administrative event',\n",
       " 'has cost currency',\n",
       " 'conference participant',\n",
       " 'has an organizing committee',\n",
       " 'mark conflict of interest',\n",
       " 'brief introduction for session chair',\n",
       " 'rejected paper',\n",
       " 'IASTED member',\n",
       " 'submission',\n",
       " 'has a committee co-chair',\n",
       " 'plenary lecture',\n",
       " 'give',\n",
       " 'designed by',\n",
       " 'conference paper',\n",
       " 'demo chair',\n",
       " 'person',\n",
       " 'program chair',\n",
       " 'virtual meeting enabled by',\n",
       " 'member of conference',\n",
       " 'searched by',\n",
       " 'need',\n",
       " 'author book proceedings included',\n",
       " 'best applications paper award',\n",
       " 'has name',\n",
       " 'flyer',\n",
       " 'submitted paper',\n",
       " 'place',\n",
       " 'has postal code',\n",
       " 'has programme',\n",
       " 'review',\n",
       " 'review',\n",
       " 'conference building',\n",
       " 'reviewer',\n",
       " 'reviewer of paper',\n",
       " 'has a committee chair',\n",
       " 'tutorial',\n",
       " 'deadline author notification',\n",
       " 'awarded by',\n",
       " 'conference state',\n",
       " 'initial manuscipt',\n",
       " 'is menu of',\n",
       " 'submitted contribution',\n",
       " 'activity',\n",
       " 'has conference member',\n",
       " 'fee',\n",
       " 'document',\n",
       " 'has tutorials',\n",
       " 'place',\n",
       " 'belongs to a review reference',\n",
       " 'paper presented as',\n",
       " 'written by',\n",
       " 'has a commtitee',\n",
       " 'reviews per paper',\n",
       " 'review',\n",
       " 'presentation of paper',\n",
       " 'string',\n",
       " 'abstract',\n",
       " 'preference',\n",
       " 'reviewer bidding started by',\n",
       " 'viza',\n",
       " 'renting',\n",
       " 'transparency',\n",
       " 'payment document',\n",
       " 'tutorial',\n",
       " 'organizator',\n",
       " 'performance topic',\n",
       " 'paper author',\n",
       " 'computer networks aapplications topic',\n",
       " 'was a committe co-chair of',\n",
       " 'program committee member',\n",
       " 'break event',\n",
       " 'short paper',\n",
       " 'accepting manuscript',\n",
       " 'speaker',\n",
       " 'has a name',\n",
       " 'session chair',\n",
       " 'subclass of',\n",
       " 'regular author',\n",
       " 'reviewes',\n",
       " 'transport vehicle',\n",
       " 'int',\n",
       " 'LCD projector',\n",
       " 'writes',\n",
       " 'OC Member',\n",
       " 'chairman',\n",
       " 'test only topic',\n",
       " 'currency',\n",
       " 'rejected contribution',\n",
       " 'has VAT',\n",
       " 'has a track-workshop-tutorial chair',\n",
       " 'registeered applicant',\n",
       " 'accpet if room rating',\n",
       " 'university',\n",
       " 'refusing manuscript',\n",
       " 'proceedings publisher',\n",
       " 'send',\n",
       " 'has a review expertise',\n",
       " 'speaker lecture',\n",
       " 'call for reviews',\n",
       " 'administrator',\n",
       " 'is part of conference volumes',\n",
       " 'name of sponsor',\n",
       " 'deadline',\n",
       " 'presentation',\n",
       " 'deadline',\n",
       " 'early-registered participant',\n",
       " 'rated papers',\n",
       " 'person',\n",
       " 'regular session',\n",
       " 'accommodation place',\n",
       " 'min choice',\n",
       " 'subclass of']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_case_handled = []\n",
    "for concept in inp:\n",
    "    final_list = []\n",
    "    for word in concept.split(\" \"):\n",
    "        if not re.search(\"[A-Z][A-Z]+\", concept):\n",
    "            final_list.append(word.lower())\n",
    "        else:\n",
    "            final_list.append(word)\n",
    "    case_resolved = \" \".join(final_list)\n",
    "    inp_case_handled.append(case_resolved)\n",
    "    \n",
    "inp_case_handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['confOf', 'sigkdd'],\n",
       " ['iasted', 'sigkdd'],\n",
       " ['cmt', 'ekaw'],\n",
       " ['confOf', 'iasted'],\n",
       " ['conference', 'edas'],\n",
       " ['cmt', 'sigkdd'],\n",
       " ['ekaw', 'sigkdd'],\n",
       " ['conference', 'confOf'],\n",
       " ['conference', 'sigkdd'],\n",
       " ['confOf', 'edas'],\n",
       " ['cmt', 'conference'],\n",
       " ['edas', 'iasted'],\n",
       " ['conference', 'iasted'],\n",
       " ['edas', 'sigkdd'],\n",
       " ['ekaw', 'iasted'],\n",
       " ['cmt', 'edas'],\n",
       " ['edas', 'ekaw'],\n",
       " ['cmt', 'confOf'],\n",
       " ['confOf', 'ekaw'],\n",
       " ['conference', 'ekaw'],\n",
       " ['cmt', 'iasted']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ontologies_in_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eef59b087748c58eb55ef798baa1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a020ec334845459b0b659592f901d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7977b08c854e328bb05253633ce659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435778770.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14206647872924805\n"
     ]
    }
   ],
   "source": [
    "# from transformers import XLNetTokenizer, XLNetModel\n",
    "# import torch\n",
    "# import scipy\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "input_ids = torch.tensor(tokenizer.encode(\"fastigial nucleus\", add_special_tokens=True)).unsqueeze(0)\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs[0].mean(1)\n",
    "\n",
    "print (t-time.time())\n",
    "# input_ids = torch.tensor(tokenizer.encode(\"femur\", add_special_tokens=True)).unsqueeze(0) \n",
    "\n",
    "# outputs1 = model(input_ids)\n",
    "# last_hidden_states1 = outputs1[0].mean(1)\n",
    "\n",
    "# cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "# cos(last_hidden_states, last_hidden_states1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'bert-large-nli-mean-tokens'. Make sure that:\n\n- 'bert-large-nli-mean-tokens' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'bert-large-nli-mean-tokens' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-455cefa0d73d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-large-nli-mean-tokens\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mword_embedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Apply mean pooling to get one fixed sized sentence vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'bert-large-nli-mean-tokens'. Make sure that:\n\n- 'bert-large-nli-mean-tokens' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'bert-large-nli-mean-tokens' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import *\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=False,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=True)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2498054802417755"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "\n",
    "cos_sim(*model.encode([\"My brother plays guitar\", \"The sun is shining\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1406574696302414"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim(*extractUSEEmbeddings([\"My brother plays guitar\", \"The sun is shining\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
